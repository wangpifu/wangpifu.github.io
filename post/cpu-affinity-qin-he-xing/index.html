<html>
  <head>
    <meta charset="utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>cpu affinity 亲和性 | wangpifu</title>
<link rel="shortcut icon" href="https://wangpifu.github.io/favicon.ico?v=1591307059556">
<link href="https://cdn.jsdelivr.net/npm/remixicon@2.3.0/fonts/remixicon.css" rel="stylesheet">
<link rel="stylesheet" href="https://wangpifu.github.io/styles/main.css">
<link rel="alternate" type="application/atom+xml" title="cpu affinity 亲和性 | wangpifu - Atom Feed" href="https://wangpifu.github.io/atom.xml">
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Droid+Serif:400,700">


<script async src="https://www.googletagmanager.com/gtag/js?id=UA-164999139-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-164999139-1');
</script>


    <meta name="description" content="CPU Affinity
cpu affinity 就是让某个进程/线程绑定在某个cpu(core)上，使其尽量长时间的运行而不被迁移到其他core上的倾向性。 Linux kernel提供了两个api来修改或查看某个进程/线程的亲和性：
..." />
    <meta name="keywords" content="concurrency,linux" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0/katex.min.css">
    <script src="https://cdn.bootcss.com/highlight.js/9.12.0/highlight.min.js"></script>
  </head>
  <body>
    <div class="main">
      <div class="main-content">
        <div class="site-header">
  <a href="https://wangpifu.github.io">
  <img class="avatar" src="https://wangpifu.github.io/images/avatar.png?v=1591307059556" alt="">
  </a>
  <h1 class="site-title">
    wangpifu
  </h1>
  <p class="site-description">
    而今迈步从头越，去留肝胆两昆仑
  </p>
  <div class="menu-container">
    
      
        <a href="/" class="menu">
          首页
        </a>
      
    
      
        <a href="/archives" class="menu">
          博客
        </a>
      
    
      
        <a href="/tags" class="menu">
          标签
        </a>
      
    
      
        <a href="/post/about" class="menu">
          关于
        </a>
      
    
  </div>
  <div class="social-container">
    
      
    
      
    
      
    
      
    
      
    
  </div>
</div>

        <div class="post-detail">
          <article class="post">
            <h2 class="post-title">
              cpu affinity 亲和性
            </h2>
            <div class="post-info">
              <span>
                2020-04-29
              </span>
              <span>
                7 min read
              </span>
              
                <a href="https://wangpifu.github.io/tag/flVdHa741/" class="post-tag">
                  # concurrency
                </a>
              
                <a href="https://wangpifu.github.io/tag/Sw56WNWMXq/" class="post-tag">
                  # linux
                </a>
              
            </div>
            
              <img class="post-feature-image" src="https://wangpifu.github.io/post-images/cpu-affinity-qin-he-xing.jpg" alt="">
            
            <div class="post-content-wrapper">
              <div class="post-content">
                <h2 id="cpu-affinity">CPU Affinity</h2>
<p>cpu affinity 就是让某个进程/线程绑定在某个cpu(core)上，使其尽量长时间的运行而不被迁移到其他core上的倾向性。 Linux kernel提供了两个api来修改或查看某个进程/线程的亲和性：<br>
<code>int sched_setaffinity(pid_t pid, size_t cpusetsize, cpu_set_t *mask);</code><br>
<code>int sched_getaffinity(pid_t pid, size_t cpusetsize, cpu_set_t *mask);</code><br>
如果pid是0，那么默认是当前thread。<br>
cpu_set_t 是一个掩码数组，共1024位，每一位对应一个core，以下宏是对这个掩码进行操作的：</p>
<pre><code>void CPU_ZERO (cpu_set_t *set)
这个宏对 CPU 集 set 进行初始化，将其设置为空集。
void CPU_SET (int cpu, cpu_set_t *set)
这个宏将 cpu 加入 CPU 集 set 中。
void CPU_CLR (int cpu, cpu_set_t *set)
这个宏将 cpu 从 CPU 集 set 中删除。
int CPU_ISSET (int cpu, const cpu_set_t *set)
如果 cpu 是 CPU 集 set 的一员，这个宏就返回一个非零值（true），否则就返回零（false）。
</code></pre>
<p>我看到很多人说对于thread我们用pthread_setaffinity_np， 对于process我们才用sched_setafinity.于是我仔细的看了一下。首先，sched_setaffinity的man page上写的是</p>
<blockquote>
<p>A thread's CPU affinity mask determines the set of CPUs on which it is eligible to run</p>
</blockquote>
<p>当然它也写了</p>
<blockquote>
<p>(If you are using the POSIX threads API, then use pthread_setaffinity_np(3) instead of sched_setaffinity().)</p>
</blockquote>
<p>当我们使用</p>
<pre><code>int pthread_setaffinity_np(pthread_t thread, size_t cpusetsize, const cpu_set_t *cpuset);
int pthread_getaffinity_np(pthread_t thread, size_t cpusetsize, cpu_set_t *cpuset);
</code></pre>
<p>我们传入的是pthread_t. 而当我们使用<code>sched_setaffinity</code>时，我们传进去的可以是pid from <code>getpid()</code>,也可以是tid from <code>gettid()</code>.（对于单线程的进程，pid等于tid，对于多线程的进程，每个线程有不同的tid，但会有相同的pid。）pid_t 和pthread_t是不同的，pthread_t是同一个进程中各个线程之间的标识号，对于这个进程内是唯一的，而不同进程中，每个线程返回的pthread_t可能是一样的。而gettid是用来系统内各个线程间的标识符，由于linux采用轻量级进程实现的，它其实返回的应该是pid号。 还有需要注意的就是当你给一个线程设置了亲和性然后pthread_create 其他线程，其他线程会继承当前这个线程的亲和性。不过在我的工作范围内，sched_setaffinity 已经足够，因为线程的创建是固定的，我们也需要在创建后设置亲和性，所以不必担心亲和性的继承问题。</p>
<p>BTW: gettid() is not implemented in glibc, 所以我们需要用syscall去获取tid</p>
<pre><code class="language-c">pid_t getThreadId()
{
    return syscall(__NR_gettid);
}
</code></pre>
<h2 id="hyperthreading-numa">Hyperthreading &amp; NUMA</h2>
<p>现代cpu会有多个core，每个core可能会支持两个线程。可以通过<code>lscpu</code> 或者<code>lstopo</code> 查看。比如这张网上的图片。<br>
<img src="https://wangpifu.github.io/post-images/1588961186982.png" alt="" loading="lazy"><br>
在一些强大的工作站上会有不止一个scoket，比如我工作的机器有两个sockets，每个socket有8个core。如果hyperthreading(HT) enabled,那就将有32个hardware thread. 他们处在不同的numa（非统一内存访问架构）下(即某些cpu之间松散连接着,甚至不共享memory and bus)。那么hardware thread共享什么呢，又怎么关系到我们的程序呢？看上图，每个core内的两个threads会共享L1 和 L2 cache，同一个socket下的所有核会共享L3。 对于multi-socket机器，通常来讲每个socket有自己L3cache。对于NUMA，每个processor会访问自己的DRAM,不同processor之间通过一些通信机制来互相访问（QPI）. 可以看到HT仅仅是在物理核心上使用了两个物理任务描述符，却没有增加实际的物理计算能力。 他的好处在于如果两个程序被调度到了同一个core，他们可以共享cache和TLB来降低任务切换开销。但是如果两个程序需要抢夺物理执行资源，那么反而会增加延时。对于低延迟交易来讲，我认为disable这个更好，因为它会损害性能增高延迟。但是对于互联网来讲，这个可以提高吞吐量，所以在互联网业务中，可以依据具体业务决定是否enable。对于不同numa来说，他们访问彼此的cache要明显慢于访问自己的cache， 可以通过命令<code>numactl -H</code>查看，这给我们的启发是尽量让相关的任务处在同一个numa node下。</p>
<h3 id="查看cpu信息">查看cpu信息</h3>
<p>查看处理器核数：<code>cat /proc/cpuinfo | grep &quot;cpu cores&quot; | uniq</code> 即每个物理处理器的core的个数，例如Intel(R) Xeon(R) CPU E5-2690 @2.90GHz在每个socket上有8 cores<br>
查看逻辑处理器核数 ：<code>cat /proc/cpuinfo</code>， 如果siblings和cpu cores一致，则不支持超线程<br>
查看物理处理器封装id：<code>cat /proc/cpuinfo | grep &quot;physical id&quot; | sort | uniq | wc -l</code> 例如Intel(R) Xeon(R) CPU E5-2690 @2.90GHz 有两个&quot;物理处理器封装&quot;<br>
查看逻辑处理器ID: <code>cat /proc/cpuinfo | grep &quot;processor&quot; | wc -l</code> 例如Intel(R) Xeon(R) CPU E5-2690 @2.90GHz 没有开超线程，他有两个物理处理器封装。每个封装有8个core，则一共含有16个core/逻辑处理器（如果开了HT就是32）.其id从0 -15.</p>
<h2 id="线程独占">线程独占</h2>
<p>即使将线程绑定到了某个core，系统依然可能将其他任务调度到这个核，为了进一步减少其他任务对这个线程的影响，我们可以将这个core从内核调度系统中剥离。<br>
在 <code>/boot/grub2.cfg</code>中输入<code>isolcpu=11,12</code>或者你想剥离的cpu id，这样系统启动后将不会使用这两个core， 当然，通过taskset我们还是可以指定一些程序在这些核运行。<br>
或者换个思路，我们将init.d限制在core 0， 这样由它产生的所有进程都会运行在这个core上，而对于一些特定的进程，我们可以指定他们到其他core上。我们可以<code>default_affinity=0</code>或者<code>init=/usr/bin/numactl -m 0 -c 0 /sbin/init</code>。后者比前者好因为它同时绑定了core 0 并设置了numa policy 表明更偏爱node 0 的memory allocation。<code>taskset -pc 1</code>来看我们确实设置成功。需要注意如果一个进程有RT优先级的话会锁住，所以对于这样的进程要在其他核运行。</p>
<h2 id="reference">Reference</h2>
<p>https://zhuanlan.zhihu.com/p/33324549<br>
https://zhuanlan.zhihu.com/p/33621500<br>
https://eli.thegreenplace.net/2016/c11-threads-affinity-and-hyperthreading/</p>

              </div>
              <div class="toc-container">
                <ul class="markdownIt-TOC">
<li>
<ul>
<li><a href="#cpu-affinity">CPU Affinity</a></li>
<li><a href="#hyperthreading-numa">Hyperthreading &amp; NUMA</a>
<ul>
<li><a href="#%E6%9F%A5%E7%9C%8Bcpu%E4%BF%A1%E6%81%AF">查看cpu信息</a></li>
</ul>
</li>
<li><a href="#%E7%BA%BF%E7%A8%8B%E7%8B%AC%E5%8D%A0">线程独占</a></li>
<li><a href="#reference">Reference</a></li>
</ul>
</li>
</ul>

              </div>
            </div>
          </article>
        </div>

        
          <div class="next-post">
            <div class="next">下一篇</div>
            <a href="https://wangpifu.github.io/post/c-multithreading-programming-xue-xi-1/">
              <h3 class="post-title">
                c++ Multithreading programming 学习(1)
              </h3>
            </a>
          </div>
        

        
          
            <link rel="stylesheet" href="https://unpkg.com/gitalk/dist/gitalk.css">
<script src="https://unpkg.com/gitalk/dist/gitalk.min.js"></script>

<div id="gitalk-container"></div>

<script>

  var gitalk = new Gitalk({
    clientID: 'c618ca9283439df7d7b5',
    clientSecret: '9d9da4b14992b1b52b311e7f5a7ab89a9694b501',
    repo: 'wangpifu.github.io',
    owner: 'wangpifu',
    admin: ['wangpifu'],
    id: (location.pathname).substring(0, 49),      // Ensure uniqueness and length less than 50
    distractionFreeMode: false  // Facebook-like distraction free mode
  })

  gitalk.render('gitalk-container')

</script>

          

          
        

        <div class="site-footer">
  Powered by <a href="https://github.com/getgridea/gridea" target="_blank">Gridea</a>
  <a class="rss" href="https://wangpifu.github.io/atom.xml" target="_blank">
    <i class="ri-rss-line"></i> RSS
  </a>
</div>

      </div>
    </div>

    <script>
      hljs.initHighlightingOnLoad()

      let mainNavLinks = document.querySelectorAll(".markdownIt-TOC a");

      // This should probably be throttled.
      // Especially because it triggers during smooth scrolling.
      // https://lodash.com/docs/4.17.10#throttle
      // You could do like...
      // window.addEventListener("scroll", () => {
      //    _.throttle(doThatStuff, 100);
      // });
      // Only not doing it here to keep this Pen dependency-free.

      window.addEventListener("scroll", event => {
        let fromTop = window.scrollY;

        mainNavLinks.forEach((link, index) => {
          let section = document.getElementById(decodeURI(link.hash).substring(1));
          let nextSection = null
          if (mainNavLinks[index + 1]) {
            nextSection = document.getElementById(decodeURI(mainNavLinks[index + 1].hash).substring(1));
          }
          if (section.offsetTop <= fromTop) {
            if (nextSection) {
              if (nextSection.offsetTop > fromTop) {
                link.classList.add("current");
              } else {
                link.classList.remove("current");    
              }
            } else {
              link.classList.add("current");
            }
          } else {
            link.classList.remove("current");
          }
        });
      });

    </script>
  </body>
</html>
