<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://wangpifu.github.io</id>
    <title>wangpifu</title>
    <updated>2020-05-13T01:53:44.113Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://wangpifu.github.io"/>
    <link rel="self" href="https://wangpifu.github.io/atom.xml"/>
    <subtitle>而今迈步从头越</subtitle>
    <logo>https://wangpifu.github.io/images/avatar.png</logo>
    <icon>https://wangpifu.github.io/favicon.ico</icon>
    <rights>All rights reserved 2020, wangpifu</rights>
    <entry>
        <title type="html"><![CDATA[CMake 初探]]></title>
        <id>https://wangpifu.github.io/post/cmake-xue-xi-ji-yi-ci-yun-wei-shi-zhan/</id>
        <link href="https://wangpifu.github.io/post/cmake-xue-xi-ji-yi-ci-yun-wei-shi-zhan/">
        </link>
        <updated>2020-05-06T03:42:43.000Z</updated>
        <content type="html"><![CDATA[<p>今天兴致勃勃地写了一些自己的底层socket库代码，用到了uriparser<code>#include &lt;uriparser/Uri.h&gt;</code>，在<code>CmakeLists.tx</code>t里写了<code>find_package(UriParser)</code>然而在跑cmake时却说找不到这个库，我一直对cmake是怎么找链接库不太了解，刚好趁这个机会研究一下。<br>
首先我很好奇的是我以前用到了<code>boost</code>和<code>gtest</code>，都是直接<code>find_package</code>就找到了，为什么这次不行呢。原来cmake会先在自带的模块查找，这个模块路径一般是<code>/usr/share/cmake/Modules</code>。拿Gtest来说，cmake有<code>FindGtest.cmake</code>在上述路径，所以每当我们使用<code>find_package</code>时，他就会调用这个模块找到外部库。<br>
那么对于没有自带模块的外部库要如何查找呢。我们需要自己写一个<code>Findxxx.cmake</code>，或者在网上找一找看有没有人写好。我是在网上找了一份，因为自己不会</p>
<pre><code># Find the UriParser library
# Defines:

#  URIPARSER_INCLUDE_DIR - uriparser include directory
#  URIPARSER_LIBRARY     - uriparser library file
#  URIPARSER_FOUND       - TRUE if uriparser is found

if (URIPARSER_INCLUDE_DIR)
 #check cache 
  set(URIPARSER_FIND_QUIETLY TRUE)
endif ()

if (NOT URIPARSER_INCLUDE_DIR)
    find_path(URIPARSER_INCLUDE_DIR NAMES Uri.h PATH_SUFFIXES uriparser)
    set(URIPARSER_INCLUDE_DIR ${URIPARSER_INCLUDE_DIR}/uriparser CACHE PATH &quot;uriparser includes&quot;)
endif ()

find_library(URIPARSER_LIBRARY NAMES uriparser)

if (URIPARSER_INCLUDE_DIR AND URIPARSER_LIBRARY)
  set(URIPARSER_FOUND TRUE)
  set(UriParser_FOUND TRUE)
endif ()

if (URIPARSER_FOUND)
   if (NOT URIPARSER_FIND_QUIETLY)
      message(STATUS &quot;Found UriParser library: ${URIPARSER_LIBRARY}&quot;)
   endif ()
else ()
   if (NOT URIPARSER_FIND_QUIETLY)
      message(FATAL_ERROR &quot;Could NOT find UriParser library&quot;)
    else ()
      message(STATUS &quot;Could NOT find UriParser library&quot;)
    endif ()
endif ()
</code></pre>
<p>然后将这个文件放在<code>proj/cmake</code>下， 然后再CMakeLists.txt里定义</p>
<pre><code class="language-cmake">set(CMAKE_MODULE_PATH
     ${CMAKE_SOURCE_DIR}/cmake
     ${CMAKE_MODULE_PATH})
</code></pre>
<p>在需要使用uriparser的子项目CMakeLists.txt中定义<code>target_link_libraries(subproj PUBLIC ${URIPARSER_INCLUDE_DIR})</code>即可。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[c++ Multithreading programming 学习(4)]]></title>
        <id>https://wangpifu.github.io/post/c/</id>
        <link href="https://wangpifu.github.io/post/c/">
        </link>
        <updated>2020-05-03T03:25:43.000Z</updated>
        <content type="html"><![CDATA[<p>先放一张c++ 特性在不同版本的线路图：<br>
<img src="https://wangpifu.github.io/post-images/1588735714078.png" alt="" loading="lazy"></p>
<h2 id="线程创建">线程创建</h2>
<p>构造一个<code>thread</code>对象，可以传入参数，这些参数are either moved or copied by value. 如果我们要传入一个引用，需要<code>std::ref</code>。 新的线程创建之后即有可能被执行，至于是当前线程下一条语句先执行还是新线程先执行取决于操作系统的调度策略。</p>
<pre><code class="language-c++">void f1(int n)
{
    for (int i = 0; i &lt; 5; ++i) {
        std::cout &lt;&lt; &quot;Thread 1 executing\n&quot;;
        ++n;
        std::cout &lt;&lt; n &lt;&lt; std::endl;
        std::this_thread::sleep_for(std::chrono::milliseconds(10));
    }
}
int main()
{
    int n = 5
    std::thread t2(f1, n + 1); // pass by value
    t2.join();
    std::cout &lt;&lt; n &lt;&lt; std::endl;
}
</code></pre>
<h2 id="join-detach">join &amp; detach</h2>
<p><code>join</code>是等待线程完成执行，在等待过程中会阻塞当前<code>*this</code> 线程执行。  <code>detach</code>是将线程分离出去独自完成，被分配给分离线程的资源会在这个线程执行完后自动释放。我们需要在thread对象析构前决定是将它<code>join</code>还是<code>detach</code>，否则thread在析构时叫调用<code>std::terminate()</code>并导致进程异常退出. <code>joinable()</code>用来检测线程是否是活跃的线程，是则返回<code>true</code>，如果一个线程已经执行完毕但是还没有被joined，调用<code>joinable</code>也会返回<code>true</code>。</p>
<h2 id="线程管理">线程管理</h2>
<p><code>std::this_thread::get_id()</code> 返回当前线程id<br>
<code>std::this_thread::yeild()</code> 让出处理器，让其他线程可以被调用。比如说busy wait时让出。<br>
<code>std::this_thread::sleep_for()</code> 使当前线程停止一段时间。<br>
<code>std::this_thread::sleep_until()</code> 使当前线程停止到指定时间。<br>
<code>once_flag()</code> 和<code>call_once(once_flag&amp; flag, Callable&amp;&amp; f, Args&amp;&amp;... args)</code> 即便在多线程concurrent情况下，确保f只被call了一次。<br>
对于<code>get_id()</code>来说，这里返回的应该是底层所对应的thread id。 我们用<code>native_handle()</code> 来看一下， native_handle() 可以让我们直接用底层库(POSIX on Linux or Windows API on Windows)来操作线程。</p>
<pre><code class="language-c++">#include &lt;iostream&gt;
#include &lt;pthread.h&gt;
#include &lt;thread&gt;
#include &lt;mutex&gt;
int main(int argc, const char** argv) {
  std::mutex iomutex;
  std::thread t = std::thread([&amp;iomutex] {
    {
      std::lock_guard&lt;std::mutex&gt; iolock(iomutex);
      std::cout &lt;&lt; &quot;Thread: my id = &quot; &lt;&lt; std::this_thread::get_id() &lt;&lt; &quot;\n&quot;
                &lt;&lt; &quot;        my pthread id = &quot; &lt;&lt; pthread_self() &lt;&lt; &quot;\n&quot;;
    }
  });

  {
    std::lock_guard&lt;std::mutex&gt; iolock(iomutex);
    std::cout &lt;&lt; &quot;Launched t: id = &quot; &lt;&lt; t.get_id() &lt;&lt; &quot;\n&quot;
              &lt;&lt; &quot;            native_handle = &quot; &lt;&lt; t.native_handle() &lt;&lt; &quot;\n&quot;;
  }

  t.join();
  return 0;
}
</code></pre>
<p>这个程序打印出的是</p>
<pre><code>Launched t: id = 139958647310080
            native_handle = 139958647310080        
Thread: my id = 139958647310080
            my pthread id = 139958647310080
</code></pre>
<p>可以看到，在POSIX平台上，<code>native_handle()</code>所拿到的id就是<code>pthread_self()</code> 返回的<code>pthread_t</code>(注意：不是<code>pid_t</code>!!)，而<code>get_id</code>()和这个值相同。那么知道了id有什么用呢？我们可以根据thread id来设置cpu affinity。尽管我们可以通过在命令行输入 <code>taskset -c $cpuid ./program</code>来限制我们想在哪些cpu上运行程序，但是我们有时更希望可以在程序内部设定。这时我们就需要用到<code>pthread_setaffinity_np</code>了，注意这里我们不能使用<a href="https://wangpifu.github.io/post/cpu-affinity-qin-he-xing/">这篇博客</a>提到的<code>sched_setaffinity</code>因为<code>native_handle()</code>返回的是<code>pthread_t</code>而不是<code>pid_t</code>。</p>
<pre><code class="language-c++">int main(int argc, const char** argv) {
  constexpr unsigned num_threads = 4;
  // A mutex ensures orderly access to std::cout from multiple threads.
  std::mutex iomutex;
  std::vector&lt;std::thread&gt; threads(num_threads);
  for (unsigned i = 0; i &lt; num_threads; ++i) {
    threads[i] = std::thread([&amp;iomutex, i] {
      std::this_thread::sleep_for(std::chrono::milliseconds(20));
      while (1) {
        {
          // Use a lexical scope and lock_guard to safely lock the mutex only
          // for the duration of std::cout usage.
          std::lock_guard&lt;std::mutex&gt; iolock(iomutex);
          std::cout &lt;&lt; &quot;Thread #&quot; &lt;&lt; i &lt;&lt; &quot;: on CPU &quot; &lt;&lt; sched_getcpu() &lt;&lt; &quot;\n&quot;;
        }

        // Simulate important work done by the tread by sleeping for a bit...
        std::this_thread::sleep_for(std::chrono::milliseconds(900));
      }
    });

    // Create a cpu_set_t object representing a set of CPUs. Clear it and mark
    // only CPU i as set.
    cpu_set_t cpuset;
    CPU_ZERO(&amp;cpuset);
    CPU_SET(i, &amp;cpuset);
    int rc = pthread_setaffinity_np(threads[i].native_handle(),
                                    sizeof(cpu_set_t), &amp;cpuset);
    if (rc != 0) {
      std::cerr &lt;&lt; &quot;Error calling pthread_setaffinity_np: &quot; &lt;&lt; rc &lt;&lt; &quot;\n&quot;;
    }
  }

  for (auto&amp; t : threads) {
    t.join();
  }
  return 0;
}
</code></pre>
<h2 id="mutex">mutex</h2>
<p><code>mutex</code>	C++11	提供基本互斥设施<br>
<code>timed_mutex</code>	C++11	提供互斥设施，带有超时功能<br>
<code>recursive_mutex</code>	C++11	提供能被同一线程递归锁定的互斥设施<br>
<code>recursive_timed_mutex</code>	C++11	提供能被同一线程递归锁定的互斥设施，带有超时功能<br>
<code>shared_timed_mutex</code>	C++14	提供共享互斥设施并带有超时功能<br>
<code>shared_mutex</code>	C++17	提供共享互斥设施<br>
对于上面的锁，有下列方法可以操作<br>
<code>lock()</code>	锁定mutex，如果mutex不可用，则当前线程阻塞<br>
<code>try_lock()</code>	尝试锁定mutex，如果mutx不可用，直接返回<br>
<code>unlock()</code>	解锁mutex<br>
上面不同类型的锁在三个方面对基础的mutex进行了拓展</p>
<ul>
<li>超时：<code>timed_mutex</code>，<code>recursive_timed_mutex</code>，<code>shared_timed_mutex</code>的名称都带有timed，这意味着它们都支持超时功能。它们都提供了<code>try_lock_for</code>和<code>try_lock_until</code>方法，这两个方法分别可以指定超时的时间长度和时间点。如果在超时的时间范围内没有能获取到锁，则直接返回，不再继续等待。</li>
<li>可重入：<code>recursive_mutex</code>和<code>recursive_timed_mutex</code>的名称都带有recursive。可重入或者叫做可递归，是指在同一个线程中，同一把锁可以锁定多次。这就避免了一些不必要的死锁。</li>
<li>共享：<code>shared_timed_mutex</code>和<code>shared_mutex</code>提供了共享功能。对于这类互斥体，实际上是提供了两把锁：一把是共享锁，一把是互斥锁。一旦某个线程获取了互斥锁，任何其他线程都无法再获取互斥锁和共享锁；但是如果有某个线程获取到了共享锁，其他线程无法再获取到互斥锁，但是还有获取到共享锁。这里互斥锁的使用和其他的互斥体接口和功能一样。而共享锁可以同时被多个线程同时获取到（使用共享锁的接口见下面的表格）。共享锁通常用在读者写者模型上。<br>
使用共享锁的接口如下：<br>
<code>lock_shared</code>	获取互斥体的共享锁，如果无法获取则阻塞<br>
<code>try_lock_shared</code>	尝试获取共享锁，如果不可用，直接返回<br>
<code>unlock_shared</code>	解锁共享锁<br>
一个示例程序：</li>
</ul>
<pre><code class="language-c++">
void concurrent_worker(int min, int max) {
  double tmp_sum = 0;
  for (int i = min; i &lt;= max; i++) {
    tmp_sum += sqrt(i); // ①
  }
  exclusive.lock(); // ②
  sum += tmp_sum;
  exclusive.unlock();
}
void concurrent_task(int min, int max) {
  auto start_time = chrono::steady_clock::now();

  unsigned concurrent_count = thread::hardware_concurrency();
  cout &lt;&lt; &quot;hardware_concurrency: &quot; &lt;&lt; concurrent_count &lt;&lt; endl;
  vector&lt;thread&gt; threads;
  min = 0;
  sum = 0;
  for (int t = 0; t &lt; concurrent_count; t++) {
    int range = max / concurrent_count * (t + 1);
    threads.push_back(thread(concurrent_worker, min, range)); // ③
    min = range + 1;
  }
  for (int i = 0; i &lt; threads.size(); i++) {
    threads[i].join();
  }

  auto end_time = chrono::steady_clock::now();
  auto ms = chrono::duration_cast&lt;chrono::milliseconds&gt;(end_time - start_time).count();
  cout &lt;&lt; &quot;Concurrent task finish, &quot; &lt;&lt; ms &lt;&lt; &quot; ms consumed, Result: &quot; &lt;&lt; sum &lt;&lt; endl;
}
</code></pre>
<p>我们用锁的粒度（granularity）来描述锁的范围。细粒度（fine-grained）是指锁保护较小的范围，粗粒度（coarse-grained）是指锁保护较大的范围。出于性能的考虑，我们应该保证锁的粒度尽可能的细。并且，不应该在获取锁的范围内执行耗时的操作，例如执行IO。如果是耗时的运算，也应该尽可能的移到锁的外面。如上代码，如果在for loop里对每次计算都加锁，那么执行时间反而会大幅增加。</p>
<p>如过我们有多个锁，要求每个task都必须锁上全部才能执行，那就有可能陷入死锁。C++ 11标准中为我们提供了一些工具来避免因为多把锁而导致的死锁。我们只要直接调用这些接口就可以了。下面提到的两个函数，它们都支持传入多个Lockable对象。<br>
<code>template &lt;class Mutex1, class Mutex2, class... Mutexes&gt; void lock (Mutex1&amp; a, Mutex2&amp; b, Mutexes&amp;... cde);</code><br>
<code>template &lt;class Mutex1, class Mutex2, class... Mutexes&gt; int try_lock (Mutex1&amp; a, Mutex2&amp; b, Mutexes&amp;... cde);</code><br>
我们同时来获取多把锁，标准库的实现保证了不会发生死锁。</p>
<h2 id="mutex-管理">Mutex 管理</h2>
<table>
<thead>
<tr>
<th>API</th>
<th>C++标准</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>lock_guard</code></td>
<td>C++11</td>
<td>实现严格基于作用域的互斥体所有权包装器</td>
</tr>
<tr>
<td><code>unique_lock</code></td>
<td>C++11</td>
<td>实现可移动的互斥体所有权包装器</td>
</tr>
<tr>
<td><code>shared_lock</code></td>
<td>C++14</td>
<td>实现可移动的共享互斥体所有权封装器</td>
</tr>
<tr>
<td><code>scoped_lock</code></td>
<td>C++17</td>
<td>用于多个互斥体的免死锁 RAII 封装器</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th>锁定策略</th>
<th>C++标准</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>defer_lock</code></td>
<td>C++11</td>
<td>类型为 defer_lock_t，不获得互斥的所有权</td>
</tr>
<tr>
<td><code>try_to_lock</code></td>
<td>C++11</td>
<td>类型为try_to_lock_t，尝试获得互斥的所有权而不阻塞</td>
</tr>
<tr>
<td><code>adopt_lock</code></td>
<td>C++11</td>
<td>类型为adopt_lock_t，假设调用方已拥有互斥的所有权</td>
</tr>
</tbody>
</table>
<p>如上一节所说，为避免死锁，我们需要同时把所有的锁锁住。假设现在我们处在用一个账户给另一个账户转钱的情境中，我们需要每个账户都有自己的锁，在转钱时，要同时锁住两个账户的锁。</p>
<pre><code class="language-c++">lock(*accountA-&gt;getLock(), *accountB-&gt;getLock());
lock_guard lockA(*accountA-&gt;getLock(), adopt_lock);
lock_guard lockB(*accountB-&gt;getLock(), adopt_lock);
</code></pre>
<p>如果使用unique_lock这三行代码还有一种等价的写法：</p>
<pre><code class="language-c++">unique_lock lockA(*accountA-&gt;getLock(), defer_lock);
unique_lock lockB(*accountB-&gt;getLock(), defer_lock);
lock(*accountA-&gt;getLock(), *accountB-&gt;getLock());
</code></pre>
<p>注意这里lock方法的调用位置。这里先定义<code>unique_lock</code>指定了<code>defer_lock</code>，因此实际没有锁定互斥体，而是到第三行才进行锁定。<br>
最后，借助scoped_lock，我们可以将三行代码合成一行，这种写法也是等价的。<br>
<code>scoped_lock lockAll(*accountA-&gt;getLock(), *accountB-&gt;getLock());</code><br>
<code>scoped_lock</code>会在其生命周期范围内锁定互斥体，销毁的时候解锁。同时，它可以锁定多个互斥体，并且避免死锁。</p>
<h2 id="condition-varible">Condition Varible</h2>
<p>Condition variable 通常和一个时间或变量联系到一起，通常来说，一个线程会</p>
<ul>
<li>改变变量然后通知其他线程</li>
<li>或者等待某个变量满足条件</li>
</ul>
<table>
<thead>
<tr>
<th>API</th>
<th>C++标准</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>condition_variable</td>
<td>C++ 11</td>
<td>提供与 std::unique_lock 关联的条件变量</td>
</tr>
<tr>
<td>condition_variable_any</td>
<td>C++ 11</td>
<td>提供与任何锁类型关联的条件变量</td>
</tr>
<tr>
<td>notify_all_at_thread_exit</td>
<td>C++ 11</td>
<td>安排到在此线程完全结束时对 notify_all 的调用</td>
</tr>
<tr>
<td>cv_status</td>
<td>C++ 11</td>
<td>列出条件变量上定时等待的可能结果</td>
</tr>
</tbody>
</table>
<h3 id="一个简单例子">一个简单例子</h3>
<pre><code class="language-c++">#include &lt;condition_variable&gt;
#include &lt;iostream&gt;
#include &lt;thread&gt;

std::mutex mutex_;
std::condition_variable condVar; 
bool dataReady{false};

void waitingForWork(){
    std::cout &lt;&lt; &quot;Waiting &quot; &lt;&lt; std::endl;
    std::unique_lock&lt;std::mutex&gt; lck(mutex_);
    condVar.wait(lck, []{ return dataReady; });   // (4)
    std::cout &lt;&lt; &quot;Running &quot; &lt;&lt; std::endl;
}

void setDataReady(){
    {
        std::lock_guard&lt;std::mutex&gt; lck(mutex_);
        dataReady = true;
    }
    std::cout &lt;&lt; &quot;Data prepared&quot; &lt;&lt; std::endl;
    condVar.notify_one();                        // (3)
}

int main(){
  std::cout &lt;&lt; std::endl;
  std::thread t1(waitingForWork);               // (1)
  std::thread t2(setDataReady);                 // (2)
  t1.join();
  t2.join();
  std::cout &lt;&lt; std::endl;
}
</code></pre>
<p>上面的程序有两个thread， 一个<code>setDataReady</code>【2】，另一个<code>waitingForWork</code>【1】。t2通过<code>lock_guard</code>上锁然后改变dataReady,通过<code>notify_one()</code>【3】通知等待这个条件变量<code>condVar</code>的另外一条线程。 线程t1通过条件变量进行等待，他会通过pred(即那个lambda表达式)来判断条件是否满足，如果满足会继续。如果<strong>不满足就解锁锁，然后当前线程陷入等待</strong>。这样其他线程才能获得锁。这里我想讨论一下<code>notify_one()</code> 和 <code>notify_all()</code>的区别，如果我没记错，他们在linux下分别对应<code>pthread_cond_signal</code>和<code>pthread_cond_broadcast</code>。一个是唤醒至少一个阻塞在当前条件变量的线程，如果有不止一个线程在等待当前条件变量，调度策略会决定哪一个线程将结束阻塞；另外一个是唤醒所有的阻塞在当前条件变量的线程，这些线程需要去竞争锁。看上去<code>notify_all()</code>是<code>notify_one()</code>的超集，但是我们需要考虑具体的业务场景，如果只需要众多线程中的一个去处理，那实在没有必要去<code>notify_all()</code>.</p>
<h4 id="运行结果">运行结果</h4>
<pre><code>Waiting
Data prepared      
Running
</code></pre>
<p>为什么我们需要在【4】有一个pred而不是直接去等待这个条件变量呢，在此之前，我们先介绍两种现象，一种是lost wakeup, 另外一种是spurious wakeup。 前者是指在接受线程进入等待状态前，发送线程就已经发送了通知，后果就是这个通知丢了，接受线程会永远等待下去。后者是指没有通知发送，但是还是有接受线程醒来。而pred就是为了避免这两种现象。</p>
<p>在上面的例子里，线程t1会先锁住mutex，然后去查看pred <code>[]{return dataReady;}</code>，如果pred返回<code>true</code>那么线程继续工作，返回<code>false</code>那么<code>condVar.wait()</code>解锁mutex，然后进入等待/阻塞状态。当condVar处于等待状态时，收到一个通知，他会从从阻塞中恢复并获取mutex锁，然后检查pred，如果pred是<code>true</code>则继续工作，<code>false</code>那么<code>condVar.wait()</code>解锁mutex，然后进入等待/阻塞状态. 如果去掉pred，那么我们可能会陷入死锁</p>
<pre><code>Data prepared      
Waiting
</code></pre>
<p>这是因为t1还没有进入等待状态时，t2就已经发送了通知，所以t1会永远等下去。 而加了pred，它对应</p>
<pre><code class="language-c++">while (!pred()) {
    wait(lock);
}
</code></pre>
<p>这样不仅避免了lost wakeup，也解决了spurious wakeup。当然，对于一些复杂情况，比如A则执行actionA,B则执行actionB,用没有pred的wait()会有更好的性能。这也是为社么cpp有不含pred的重载<br>
e.g.</p>
<pre><code class="language-c++">cond.wait(lock, []{return (A || B);});
if(A) {
    actionA();
}
else {
    actionB();
}
</code></pre>
<p>需要检测条件两次,而</p>
<pre><code class="language-c++">while(true)
{
    if(A) {
         actionA();
         break;
    }
    else if(B) {
         actionB();
         break;
    }
    cond.wait(lock);
}
</code></pre>
<p>对于每种情况只检测一次。</p>
<h2 id="reference">Reference</h2>
<ul>
<li>https://eli.thegreenplace.net/2016/c11-threads-affinity-and-hyperthreading/</li>
<li>https://paul.pub/cpp-concurrency/</li>
<li>https://www.modernescpp.com/index.php/c-core-guidelines-be-aware-of-the-traps-of-condition-variables</li>
</ul>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[c++ Multithreading programming 学习(3)]]></title>
        <id>https://wangpifu.github.io/post/c-multithreading-programming-xue-xi-3/</id>
        <link href="https://wangpifu.github.io/post/c-multithreading-programming-xue-xi-3/">
        </link>
        <updated>2020-04-29T22:04:33.000Z</updated>
        <content type="html"><![CDATA[<p>继上一篇介绍完pthead，本来想接着学习c++的thread库，但又有点犯懒，感觉自己封装一下pthread就好，因为我的业余开发环境是linux，而且c++版本还停留在c++11（很多人诟病c++11 的thread库），所以只要封装出thread, mutex, condition_variable和lock_guard (RAII. acquire resource at initialization and release at destruction) 那应该就够我自己用了。但是考虑到公司早已转到c++17, 我还是学习一下。不过在这一节，我先附上一些对我以前一些疑问的解答，在下一节再接着写 <code>&lt;thread&gt;</code>库。</p>
<blockquote>
<p>作者：Gomo Psivarh<br>
链接：https://www.zhihu.com/question/31459750/answer/52069135<br>
来源：知乎<br>
著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。<br>
C/C++多线程编程中不要使用volatile。（注：这里的意思指的是指望volatile解决多线程竞争问题是有很大风险的，除非所用的环境系统不可靠才会为了保险加上volatile，或者是从极限效率考虑来实现很底层的接口。这要求编写者对程序逻辑走向很清楚才行，不然就会出错）C++11标准中明确指出解决多线程的数据竞争问题应该使用原子操作或者互斥锁。C和C++中的volatile并不是用来解决多线程竞争问题的，而是用来修饰一些因为程序不可控因素导致变化的变量，比如访问底层硬件设备的变量，以提醒编译器不要对该变量的访问擅自进行优化。多线程场景下可以参考《Programming with POSIX threads》的作者Dave Butenhof对Why don't I need to declare shared variables VOLATILE?这个问题的解释：comp.programming.threads FAQ简单的来说，对访问共享数据的代码块加锁，已经足够保证数据访问的同步性，再加volatile完全是多此一举。如果光对共享变量使用volatile修饰而在可能存在竞争的操作中不加锁或使用原子操作对解决多线程竞争没有任何卵用，因为volatile并不能保证操作的原子性，在读取、写入变量的过程中仍然可能被其他线程打断导致意外结果发生。</p>
</blockquote>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[c++ Multithreading programming 学习(2)]]></title>
        <id>https://wangpifu.github.io/post/c-multithreading-programming-xue-xi-2/</id>
        <link href="https://wangpifu.github.io/post/c-multithreading-programming-xue-xi-2/">
        </link>
        <updated>2020-04-29T13:21:15.000Z</updated>
        <content type="html"><![CDATA[<p>继上一篇文章学习了一些基础的api后，这一章我们接着来看pthread所提供的锁,条件变量</p>
<h2 id="mutex-variable互斥锁">Mutex Variable(互斥锁)</h2>
<h3 id="overview">Overview</h3>
<p>Mutex是&quot;mutual exclusion&quot;(互斥)简称.Mutex variable 就像一把锁一样保护共享数据资.mutex的基本概念就是,在任何时候只有一个线程能 lock一个mutex 变量。所以，即使很多线程尝试去锁一个mutex，也仅仅只有一个线程能成功。</p>
<h3 id="创建销毁锁定与释放">创建，销毁，锁定与释放</h3>
<p><code>pthread_mutex_init(pthread_mutex_t * mutex, const phtread_mutexattr_t * mutexattr);</code>//动态方式创建锁，相当于new动态创建一个对象<br>
<code>pthread_mutex_t mutex = PTHREAD_MUTEX_INITIALIZER;</code>//以静态方式创建锁<br>
<code>pthread_mutex_destory(pthread_mutex_t *mutex)</code>//释放互斥锁，相当于delete<br>
<code>pthread_mutex_lock(pthread_mutex_t *mutex)</code><br>
//以阻塞方式运行的。如果之前mutex被加锁了，那么程序会阻塞在这里。<br>
<code>pthread_mutex_unlock(pthread_mutex_t *mutex)</code><br>
<code>int pthread_mutex_trylock(pthread_mutex_t * mutex);</code><br>
// 会尝试对mutex加锁。如果mutex之前已经被锁定，返回非0,；如果mutex没有被锁定，则函数返回并锁定mutex.该函数是以非阻塞方式运行。也就是说如果mutex之前已经被锁定，函数会返回非0，程序继续往下执行。<br>
典型使用mutex的顺序如下：</p>
<ol>
<li>创建和初始化 mutex 变量;</li>
<li>许多线程尝试锁住 mutex;</li>
<li>只有一个线程成功锁住 mutex,其他线程等待;</li>
<li>拥有 mutex 的线程进行自己的操作;</li>
<li>拥有线程解锁 mutex;</li>
<li>其他线程继续获取 mutex 并持续如上步骤;</li>
<li>最后 mutex 销毁.</li>
</ol>
<h3 id="互斥锁属性设置">互斥锁属性设置</h3>
<pre><code class="language-c++">int pthread_mutexattr_init(pthread_mutexattr_t *mattr);
//成功返回0，其它返回值表示出错  
int pthread_mutexattr_destroy(pthread_mutexattr_t *mattr);
//成功返回0，其它返回值表示出错
</code></pre>
<p>互斥锁具有一些属性，通过修改这些属性可以控制锁的一些行为。缺省的互斥锁属性及其值如下：</p>
<ol>
<li>pshared:          PTHREAD_PROCESS_PRIVATE</li>
<li>type:                  PTHREAD_MUTEX_DEFAULT</li>
<li>protocol:           PTHREAD_PRIO_NONE</li>
<li>prioceiling:       –</li>
<li>robustness:    PTHREAD_MUTEX_STALLED_NP<br>
可以用pthread_mutexattr_init将与互斥锁对象相关联的属性初始化为其缺省值。pthread_mutexattr_init的参数类型实际上是opaque的，其中包含一个由系统分配的属性对象。该函数执行过程中会为属性对象分配所需的内存，因而如果未通过pthread_mutexattr_destroy销毁互斥锁属性对象时就会导致内存泄漏。<br>
对于互斥锁属性对象,必须首先通过调用pthread_mutexattr_destroy将其销毁,才能重新初始化该对象。</li>
</ol>
<h4 id="作用域">作用域</h4>
<pre><code class="language-c++">int pthread_mutexattr_setpshared(pthread_mutexattr_t *mattr,int pshared);
//成功返回0，其它返回值表示出错  
int pthread_mutexattr_getpshared(pthread_mutexattr_t *mattr,int *pshared);
//成功返回0，其它返回值表示出错
</code></pre>
<p>函数<code>pthread_mutexattr_setpshared</code>用来设置互斥锁的作用域。互斥锁变量可以是进程专用的变量,也可以是跨越进程边界的变量。<br>
范围属性的取值及其含义：<br>
PTHREAD_PROCESS_SHARED：具有该属性的互斥锁可以在多个进程中的线程之间共享。<br>
PTHREAD_PROCESS_PRIVATE：只有创建本互斥锁的线程所在的进程内的线程才能够使用该互斥锁变量。该值是缺省值。<br>
函数<code>pthread_mutexattr_getpshared</code>可用来返回由<code>pthread_mutexattr_setpshared</code>设置的互斥锁变量的范围。</p>
<h4 id="类型属性">类型属性</h4>
<pre><code class="language-c++">int pthread_mutexattr_settype(pthread_mutexattr_t *attr , int type);
//成功返回0，其它返回值表示出错  
int pthread_mutexattr_gettype(pthread_mutexattr_t *attr , int *type);
//成功返回0，其它返回值表示出错  
</code></pre>
<p>pthread_mutexattr_settype用来设置指定互斥锁的类型属性。类型属性的缺省值为<code>PTHREAD_MUTEX_DEFAULT</code>。<br>
互斥锁的类型及其行为：</p>
<ul>
<li>PTHREAD_MUTEX_NORMAL：不提供死锁检测。如果一个线程试图对一个互斥锁重复锁定，将会引起这个线程的死锁。如果试图解锁一个由别的线程锁定的互斥锁会引发不可预料的结果。如果一个线程试图解锁已经被解锁的互斥锁也会引发不可预料的结果</li>
<li>PTHREAD_MUTEX_ERRORCHECK：提供错误检查。如果一个线程试图对一个互斥锁重复锁定，将会返回一个错误代码。如果试图解锁一个由别的线程锁定的互斥锁将会返回一个错误代码。如果一个线程试图解锁已经被解锁的互斥锁也将会返回一个错误代码</li>
<li>PTHREAD_MUTEX_RECURSIVE：如果一个线程对这种类型的互斥锁重复上锁，不会引起死锁，一个线程对这类互斥锁的多次重复上锁必须由这个线程来重复相同数量的解锁，这样才能解开这个互斥锁，别的线程才能得到这个互斥锁。如果试图解锁一个由别的线程锁定的互斥锁将会返回一个错误代码。如果一个线程试图解锁已经被解锁的互斥锁也将会返回一个错误代码。这种类型的互斥锁只能是进程私有的（作用域属性为PTHREAD_PROCESS_PRIVATE）</li>
<li>PTHREAD_MUTEX_DEFAULT：这种类型的互斥锁不会自动检测死锁。如果一个线程试图对一个互斥锁重复锁定，将会引起不可预料的结果。如果试图解锁一个由别的线程锁定的互斥锁会引发不可预料的结果。如果一个线程试图解锁已经被解锁的互斥锁也会引发不可预料的结果。POSIX标准规定，对于某一具体的实现，可以把这种类型的互斥锁定义为其他类型的互斥锁<br>
在linux中互斥锁的相关类型定义如下（最好的办法是检查pthread.h这个头文件）：</li>
</ul>
<pre><code class="language-c++">  #if defined __USE_UNIX98 || defined __USE_XOPEN2K8
  PTHREAD_MUTEX_NORMAL = PTHREAD_MUTEX_TIMED_NP,
  PTHREAD_MUTEX_RECURSIVE = PTHREAD_MUTEX_RECURSIVE_NP,
  PTHREAD_MUTEX_ERRORCHECK = PTHREAD_MUTEX_ERRORCHECK_NP,
  PTHREAD_MUTEX_DEFAULT = PTHREAD_MUTEX_NORMAL
  #endif
</code></pre>
<p><code>pthread_mutexattr_gettype</code>用来获取由<code>pthread_mutexattr_settype</code>设置的互斥锁的类型属性。</p>
<h4 id="协议属性">协议属性</h4>
<pre><code class="language-c++">int pthread_mutexattr_setprotocol(pthread_mutexattr_t *attr, int protocol);
//成功返回0，其它返回值表示出错  
int pthread_mutexattr_getprotocol(const pthread_mutexattr_t *attr, int *protocol); //成功返回0，其它返回值表示出错   
</code></pre>
<p><code>pthread_mutexattr_setprotocol</code>用来设置互斥锁的协议属性。<br>
互斥锁协议属性的可能值及其含义：</p>
<ul>
<li>PTHREAD_PRIO_NONE：    线程的优先级和调度不会受到互斥锁拥有权的影响.</li>
<li>PTHREAD_PRIO_INHERIT： 此协议值会影响拥有该互斥锁的线程的优先级和调度。如果更高优先级的线程因thread1所拥有的一个或多个互斥锁而被阻塞,而这些互斥锁是用 PTHREAD_PRIO_INHERIT 初始化的,则thread1的运行优先级为优先级pri1和优先级pri2中优先级较高的那一个.(其中 thread1的优先级为pri1,所有正在等待这些互斥锁的线程的最高优先级为pri2.)如果thread1因另一个线程(thread3) 拥有的互斥锁而被阻塞,则相同的优先级继承效应会以递归方式传播给thrd3。<br>
使用PTHREAD_PRIO_INHERIT可以避免优先级逆转。当低优先级的线程持有较高优先级线程所需的锁时,就会发生优先级逆转。此时只有在较低优先级的线程释放该锁之后,较高优先级的线程才能继续执行。如果没有优先级继承，低优先级的线程可能会在很长一段时间内都得不到调度，而这会导致等待低优先级线程锁持有的锁的高优先级线程也等待很长时间（因为低优先级线程无法运行，因而就无法释放锁，所以高优先级线程只能继续阻塞在锁上）。使用优先级继承可以短时间的提高低优先级线程的优先级，从而使它可以尽快得到调度，然后释放锁。低优先级线程在释放锁后就会恢复自己的优先级。</li>
<li>PTHREAD_PRIO_PROTECT：当线程拥有一个或多个使用PTHREAD_PRIO_PROTECT 初始化的互斥锁时,线程的优先级和调度会受到影响。线程将以优先级pri1和优先级pri2中优先级较高的那一个优先级来运行，其中该线程的优先级为pri1，所有该线程持有的锁的最高优先级为pri2，被该线程所持有的锁阻塞的高优先级线程对该线程的调度没有影响。</li>
</ul>
<p><code>PTHREAD_PRIO_INHERIT</code> 和 <code>PTHREAD_PRIO_PROTECT</code> 只有在采用实时调度策略<code>SCHED_FIFO</code> 或 <code>SCHED_RR</code>的优先级进程内可用。（The PTHREAD_PRIO_INHERIT and PTHREAD_PRIO_PROTECT mutex attributes are usable only by privileged processes running in the realtime (RT) scheduling class SCHED_FIFO or SCHED_RR.）<br>
一个线程可以同时拥有多个混合使用 <code>PTHREAD_PRIO_INHERIT</code> 和 <code>PTHREAD_PRIO_PROTECT</code>协议属性初始化的互斥锁。在这种情况下,该线程将以通过其中任一协议获取的最高优先级执行。<br>
pthread_mutexattr_getprotocol可用来获取互斥锁属性对象的协议属性。</p>
<h4 id="优先级上限属性">优先级上限属性</h4>
<pre><code class="language-c++">int pthread_mutexattr_setprioceiling(pthread_mutexatt_t *attr, int prioceiling, int *oldceiling); //成功返回0，其它返回值表示出错  
int pthread_mutexattr_getprioceiling(const pthread_mutexatt_t *attr, int *prioceiling); //成功返回0，其它返回值表示出错
</code></pre>
<p><code>pthread_mutex_setprioceiling</code>可更改互斥锁 mutex 的优先级上限 prioceiling。<br>
<code>pthread_mutex_setprioceiling</code>可锁定互斥锁(如果未锁定的话),或者一直处于阻塞状态,直到它成功锁定该互斥锁,更改该互斥锁的优先级上限并将该互斥锁释放为止。锁定互斥锁的过程无需遵循优先级保护协议。如果 <code>pthread_mutex_setprioceiling</code>成功,则将在 old_ceiling 中返回以前的优先级上限值。如果<code>pthread_mutex_setprioceiling</code>失败,则互斥锁的优先级上限保持不变。<br>
<code>pthread_mutex_getprioceiling</code>会返回 mutex 的优先级上限 prioceiling。</p>
<h4 id="robust-属性">Robust 属性</h4>
<p>TODO: 这个没有在工作中见过，不是特别了解，需要实验</p>
<pre><code class="language-c++">int pthread_mutexattr_setrobust_np(pthread_mutexattr_t *attr, int *robustness);  //成功返回0，其它返回值表示出错 
int pthread_mutexattr_getrobust_np(const pthread_mutexattr_t *attr, int *robustness);  //成功返回0，其它返回值表示出错
</code></pre>
<p><code>pthread_mutexattr_setrobust_np</code>用来设置互斥锁属性对象的强健属性。仅当定义了符号 <code>_POSIX_THREAD_PRIO_INHERIT</code> 时,<code>pthread_mutexattr_setrobust_np()</code>才适用。robustness 定义在互斥锁的持有者“死亡”时的行为。pthread.h 中定义的 robustness 的值为<code>PTHREAD_MUTEX_ROBUST_NP</code> 或 <code>PTHREAD_MUTEX_STALLED_NP</code>。缺省值为<code>PTHREAD_MUTEX_STALLED_NP</code>。</p>
<ul>
<li>PTHREAD_MUTEX_STALLED_NP： 如果互斥锁的持有者死亡,则以后对 pthread_mutex_lock() 的所有调用将以不确定的方式被阻塞。</li>
<li>PTHREAD_MUTEX_ROBUST_NP： 如果互斥锁的持有者“死亡”了，或者持有这样的互斥锁的进程unmap了互斥锁所在的共享内存或者持有这样的互斥锁的进程执行了exec调用，则会解除锁定该互斥锁。互斥锁的下一个持有者将获取该互斥锁,并返回错误 <code>EOWNWERDEAD</code>。如果互斥锁具有<code>PTHREAD_MUTEX_ROBUST_NP</code>的属性，则应用程序在获取该锁时必须检查 <code>pthread_mutex_lock</code> 的返回代码看获取锁时是否返回了<code>EOWNWERDEAD</code>错误。如果是，则互斥锁的新的持有者应使该互斥锁所保护的状态保持一致。因为互斥锁的上一个持有者“死亡”时互斥锁所保护的状态可能出于不一致的状态。如果互斥锁的新的持有者能够使该状态保持一致,请针对该互斥锁调用pthread_mutex_consistent_np(),并解除锁定该互斥锁。如果互斥锁的新的持有者无法使该状态保持一致,请勿针对该互斥锁调用<code>pthread_mutex_consistent_np()</code>,而是解除锁定该互斥锁。所有等待的线程都将被唤醒,以后对 <code>pthread_mutex_lock()</code> 的所有调用都将无法获取该互斥锁。返回错误为<code>ENOTRECOVERABLE</code>。<br>
如果一个线程获取了互斥锁，但是获取时得到了<code>EOWNERDEAD</code>的错误，然后它终止并且没有释放互斥锁 ,则下一个持有者获取该锁时将返回代码<code>EOWNERDEAD</code>。</li>
</ul>
<h3 id="note">Note:</h3>
<ol>
<li>互斥量需要时间来加锁和解锁。锁住较少互斥量的程序通常运行得更快。所以，互斥量应该尽量少，够用即可，每个互斥量保护的区域应则尽量大。</li>
<li>互斥量的本质是串行执行。如果很多线程需要领繁地加锁同一个互斥量，则线程的大部分时间就会在等待，这对性能是有害的。如果互斥量保护的数据(或代码)包含彼此无关的片段，则可以特大的互斥量分解为几个小的互斥量来提高性能。这样，任意时刻需要小互斥量的线程减少，线程等待时间就会减少。所以，互斥量应该足够多(到有意义的地步)，每个互斥量保护的区域则应尽量的少。</li>
</ol>
<h3 id="example">Example</h3>
<pre><code class="language-c++">#include &lt;pthread.h&gt;
#include &lt;cstdio&gt;
#include &lt;cstdlib&gt;

struct ThreadData {
  int tid;
  int data;
};

int shared_x;
pthread_mutex_t lock;

void *ThreadProc(void *param) {
  ThreadData *data = static_cast&lt;ThreadData *&gt;(param);
  printf(&quot;begin from thread id: %d\n&quot;, data-&gt;tid);
  pthread_mutex_lock(&amp;lock);
  shared_x += data-&gt;data;
  printf(&quot;thread %d: x = %d\n&quot;, data-&gt;tid, shared_x);
  pthread_mutex_unlock(&amp;lock);
  pthread_exit(NULL);
}

int main(int argc, char *argv[]) {
  const int kNumThreads = 4;
  pthread_t threads[kNumThreads];
  ThreadData threads_data[kNumThreads];
  pthread_attr_t attr;

  shared_x = 0;
  pthread_mutex_init(&amp;lock, NULL);
  pthread_attr_init(&amp;attr);
  pthread_attr_setdetachstate(&amp;attr, PTHREAD_CREATE_JOINABLE);
  for (int i = 0; i &lt; kNumThreads; ++i) {
    threads_data[i].tid = i;
    threads_data[i].data = i * i;
    int rt = pthread_create(&amp;threads[i], &amp;attr, ThreadProc,
                            static_cast&lt;void *&gt;(&amp;threads_data[i]));
    if (rt) {
      printf(&quot;ERROR: pthread_create failed, rt=%d\n&quot;, rt);
      exit(1);
    }
  }
  for (int i = 0; i &lt; kNumThreads; ++i) {
    void *status;
    pthread_join(threads[i], &amp;status);
  }
  pthread_attr_destroy(&amp;attr);
  pthread_exit(NULL);
  return 0;
}
</code></pre>
<h2 id="condition-variables条件变量">Condition Variables(条件变量)</h2>
<h3 id="overview-2">Overview</h3>
<p>Mutex 变量如锁一般防止多个线程访问共享数据资源,如果某个线程等待某个共享数据达到某个数值才进行相应的操作,那么这个线程需要不断的去 poll,查看是否满足需要的值,这样开销很大,因为线程需要一直处于忙状态.<br>
引入 Condition Variables 来完成这样的同步到某个实际数据值而不要不断 poll.<br>
Condition 变量一般与 mutex 一起使用.锁住查看的共享数据资源.<br>
使用 Condition 的一般步骤如下:</p>
<ul>
<li>声明和定义需要同步的共享数据;</li>
<li>声明和定义 condition 变量;</li>
<li>声明和定义相对应的 mutex;</li>
<li>创建线程使用 condition 变量同步.</li>
</ul>
<h3 id="条件变量创建与销毁">条件变量创建与销毁</h3>
<pre><code class="language-c++">int pthread_cond_destroy(pthread_cond_t *cond);
int pthread_cond_init(pthread_cond_t *restrict cond,
                      const pthread_condattr_t *restrict attr);
int pthread_condattr_destroy(pthread_condattr_t *attr);
int pthread_condattr_init(pthread_condattr_t *attr);
</code></pre>
<p>Condition 变量由 pthread_cond_t 声明定义,而且必须初始化在使用前.两种方法初始:<br>
静态的,当声明时.如:<br>
<code>pthread_cond_t convar = PTHREAD_COND_INITIALIZER;</code><br>
动态的, 使用 pthread_cond_init() 函数,并能设置 condition 的属性 attr.</p>
<pre><code class="language-c++">pthread_cond_t cond;
pthread_cond_init(&amp; cond, nullptr);
</code></pre>
<p>attr 用来设置 condition 变量的属性,必须是 <code>pthread_condattr_</code>t 类型.只有一种属性可选:是否进程共享,也就是允许其他进程中的线程也能看到它.</p>
<pre><code class="language-c++">pthread_condattr_t  cattr;
int ret;
/* initialize an attribute to default value */
ret = pthread_condattr_init(&amp;cattr); 
/* all processes */
ret = pthread_condattr_setpshared(&amp;cattr, PTHREAD_PROCESS_SHARED);
/* within a process */
ret = pthread_condattr_setpshared(&amp;cattr, PTHREAD_PROCESS_PRIVATE);
</code></pre>
<p>cattr is an opaque data type that contains a system-allocated attribute object. The possible values of cattr's scope are PTHREAD_PROCESS_PRIVATE (the default) and PTHREAD_PROCESS_SHARED.</p>
<h3 id="条件变量等待与信号">条件变量等待与信号</h3>
<pre><code class="language-c++">int pthread_cond_wait(pthread_cond_t *cond,
                      pthread_mutex_t *mutex);
int pthread_cond_signal(pthread_cond_t *cond);
int pthread_cond_broadcast(pthread_cond_t *cond);
</code></pre>
<p><code>pthread_cond_wait()</code> 阻塞调用它的线程直到其中 cond 被 signal.这个函数需要在占有 mutex 时被调用,而当等待时它将自动释放 mutex.等到 signal 收到,线程被唤醒, mutex 将自动被占有 .最后当线程完成 condition 的操作,要负责对 mutex 解锁.<br>
<code>pthread_cond_signal()</code> 用来 signal 其他等待这个 cond 的线程.它需要在占有 mutex 时被调用.然后必须对 mutex 解锁来完成 <code>pthread_cond_wait</code> 的等待.<br>
如果有多于一个线程处于等待 cond 而阻塞, 应该用 <code>pthread_cond_broadcast()</code> 替换 pthread_cond_signal().</p>
<h3 id="example-2">Example</h3>
<pre><code class="language-c++">#include &lt;pthread.h&gt;
#include &lt;cstdio&gt;
#include &lt;cstdlib&gt;
#include &lt;unistd.h&gt;

const int kNumThreads = 3;
const int kLoops = 10;
const int kCountLimit = 15;

int g_count;
pthread_mutex_t count_mutex;
pthread_cond_t count_cv;

void *IncreaseCount(void *param) {
  int id;
  id = *(static_cast&lt;int *&gt;(param));
  for (int i = 0; i &lt; kLoops; ++i) {
    pthread_mutex_lock(&amp;count_mutex);
    g_count++;
    if (g_count == kCountLimit) {
      pthread_cond_signal(&amp;count_cv);
      printf(&quot;increse thread %d: count = %d, signal cond\n&quot;, id, g_count);
    }
    printf(&quot;increse thread %d: count = %d, unlock mutex\n&quot;, id, g_count);
    pthread_mutex_unlock(&amp;count_mutex);
    sleep(1);
  }
  pthread_exit(NULL);
}

void *WatchCount(void *param) {
  int id;
  id = *(static_cast&lt;int *&gt;(param));
  pthread_mutex_lock(&amp;count_mutex);
  while (g_count &lt; kCountLimit) {
    pthread_cond_wait(&amp;count_cv, &amp;count_mutex);
    printf(&quot;watch thread %d: count = %d, receive signal\n&quot;, id, g_count);
  }
  pthread_mutex_unlock(&amp;count_mutex);
  pthread_exit(NULL);
}

int main(int argc, char *argv[]) {
  pthread_t threads[kNumThreads];
  int thread_ids[kNumThreads];
  pthread_attr_t attr;

  pthread_mutex_init(&amp;count_mutex, NULL);
  pthread_cond_init(&amp;count_cv, NULL);
  pthread_attr_init(&amp;attr);
  pthread_attr_setdetachstate(&amp;attr, PTHREAD_CREATE_JOINABLE);
  for (int i = 0; i &lt; kNumThreads; ++i) {
    thread_ids[i] = i;
  }
  int rt;
  rt = pthread_create(&amp;threads[0], &amp;attr, WatchCount,
                            static_cast&lt;void *&gt;(&amp;thread_ids[0]));
  if (rt) {
    printf(&quot;ERROR: pthread_create failed, rt=%d\n&quot;, rt);
    exit(1);
  }
  rt = pthread_create(&amp;threads[1], &amp;attr, IncreaseCount,
                            static_cast&lt;void *&gt;(&amp;thread_ids[1]));
  if (rt) {
    printf(&quot;ERROR: pthread_create failed, rt=%d\n&quot;, rt);
    exit(1);
  }
  rt = pthread_create(&amp;threads[2], &amp;attr, IncreaseCount,
                            static_cast&lt;void *&gt;(&amp;thread_ids[2]));
  if (rt) {
    printf(&quot;ERROR: pthread_create failed, rt=%d\n&quot;, rt);
    exit(1);
  }
  for (int i = 0; i &lt; kNumThreads; ++i) {
    pthread_join(threads[i], NULL);
  }
  pthread_attr_destroy(&amp;attr);
  pthread_cond_destroy(&amp;count_cv);
  pthread_mutex_destroy(&amp;count_mutex);
  pthread_exit(NULL);
}
</code></pre>
<h2 id="semaphore">Semaphore</h2>
<h3 id="overview-3">OverView</h3>
<p>信号量本质上是一个非负的整数计数器，它被用来控制对公共资源的访问，也被称为PV原子操作。PV原子操作，广泛用于进程或线程之间的通信的同步和互斥。其中，P是通过的意思，V是释放的意思，不可中断的过程，则由操作系统来保证P操作和V操作。PV操作时针对信号量的操作，就是对信号量进行加减的过程。P操作，即信号量sem减一的过程，如果sem小于等于0，P操作被堵塞，直到sem变量大于0为止。P操作即加锁过程。V操作，即信号量sem加一的过程。V操作即解锁过程。</p>
<h3 id="api">API</h3>
<pre><code class="language-c++">int sem_init(sem_t *sem, int pshared, unsigned int value);
int sem_wait(sem_t *sem);  // P操作，减少信号量
int sem_post(sem_t *sem);  //V操作， 增加信号量
int sem_destory(sem_t *sem);  //销毁信号量
int sem_getvalue(sem_t *sem, int *sval);  // 获取信号量的值
</code></pre>
<p><code>sem_init</code> 函数说明：sem参数是信号量指针；pshared参数为共享方式，0表示信号量只是在当前进程中使用（线程），1表示信号量在多进程中使用；value参数表示信号量的初始值，一般为1。</p>
<h2 id="barrier">Barrier</h2>
<h3 id="overview-4">Overview</h3>
<p>Barrier 就是栅栏一样,调用等待 barrier 的线程需要等待直到满足调用 barrier 的线程个数达到要求的 count.</p>
<h3 id="api-2">API</h3>
<pre><code class="language-c++">int pthread_barrier_init(pthread_barrier_t *barrier,
                const pthread_barrierattr_t *attr, unsigned count);
pthread_barrier_t barrier = PTHREAD_BARRIER_INITIALIZER(count);
int pthread_barrier_destroy(pthread_barrier_t *barrier);
int pthread_barrierattr_init(pthread_barrierattr_t *attr);
int pthread_barrierattr_destroy(pthread_barrierattr_t *attr);
int pthread_barrier_wait(pthread_barrier_t *barrier);
</code></pre>
<p>The <code>pthread_barrier_wait()</code> function shall synchronize participating threads at the barrier referenced by barrier. The calling thread shall block until the required number of threads have called <code>pthread_barrier_wait()</code> specifying the barrier.<br>
Barrier 变量由 <code>pthread_barrier_</code>t 声明定义,而且必须初始化在使用前.需要传入满足 barrier 等待的个数 count, 两种方法初始:<br>
静态的,当声明时.如:<br>
<code>pthread_barrier_t barrier = PTHREAD_BARRIER_INITIALIZER(count);</code><br>
动态的,使用 <code>pthread_barrier_init()</code> 函数,并能设置 barrier 的属性 attr.<br>
线程调用 barrier,只需要调用 <code>pthread_barrier_wait</code> 来等待 barrier 达到满足条件.</p>
<h3 id="example-3">Example</h3>
<pre><code class="language-c++">#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;
#include &lt;unistd.h&gt;
#include &lt;pthread.h&gt;
#include &lt;time.h&gt;

#define THREAD_COUNT 4

pthread_barrier_t mybarrier;

void* threadFn(void *id_ptr) {
  int thread_id = *(int*)id_ptr;
  int wait_sec = 1 + rand() % 5;
  printf(&quot;thread %d: Wait for %d seconds.\n&quot;, thread_id, wait_sec);
  sleep(wait_sec);
  printf(&quot;thread %d: I'm ready...\n&quot;, thread_id);

  pthread_barrier_wait(&amp;mybarrier);

  printf(&quot;thread %d: going!\n&quot;, thread_id);
  return NULL;
}


int main() {
  int i;
  pthread_t ids[THREAD_COUNT];
  int short_ids[THREAD_COUNT];

  srand(time(NULL));
  pthread_barrier_init(&amp;mybarrier, NULL, THREAD_COUNT + 1);

  for (i=0; i &lt; THREAD_COUNT; i++) {
    short_ids[i] = i;
    pthread_create(&amp;ids[i], NULL, threadFn, &amp;short_ids[i]);
  }

  printf(&quot;main() is ready.\n&quot;);

  pthread_barrier_wait(&amp;mybarrier);

  printf(&quot;main() is going!\n&quot;);

  for (i=0; i &lt; THREAD_COUNT; i++) {
    pthread_join(ids[i], NULL);
  }

  pthread_barrier_destroy(&amp;mybarrier);

  return 0;
}
</code></pre>
<h3 id="reference">Reference:</h3>
<p><a href="http://dreamrunner.org/blog/2014/08/07/C-multithreading-programming/">浅谈C++ Multithreading Programming</a><br>
<a href="https://www.freebsd.org/cgi/man.cgi?query=pthread&amp;apropos=0&amp;sektion=3&amp;manpath=FreeBSD+8.0-RELEASE&amp;format=html">freebsd pthreads manual page</a></p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[cpu affinity 亲和性]]></title>
        <id>https://wangpifu.github.io/post/cpu-affinity-qin-he-xing/</id>
        <link href="https://wangpifu.github.io/post/cpu-affinity-qin-he-xing/">
        </link>
        <updated>2020-04-29T12:49:24.000Z</updated>
        <content type="html"><![CDATA[<h2 id="cpu-affinity">CPU Affinity</h2>
<p>cpu affinity 就是让某个进程/线程绑定在某个cpu(core)上，使其尽量长时间的运行而不被迁移到其他core上的倾向性。 Linux kernel提供了两个api来修改或查看某个进程/线程的亲和性：<br>
<code>int sched_setaffinity(pid_t pid, size_t cpusetsize, cpu_set_t *mask);</code><br>
<code>int sched_getaffinity(pid_t pid, size_t cpusetsize, cpu_set_t *mask);</code><br>
如果pid是0，那么默认是当前thread。<br>
cpu_set_t 是一个掩码数组，共1024位，每一位对应一个core，以下宏是对这个掩码进行操作的：</p>
<pre><code>void CPU_ZERO (cpu_set_t *set)
这个宏对 CPU 集 set 进行初始化，将其设置为空集。
void CPU_SET (int cpu, cpu_set_t *set)
这个宏将 cpu 加入 CPU 集 set 中。
void CPU_CLR (int cpu, cpu_set_t *set)
这个宏将 cpu 从 CPU 集 set 中删除。
int CPU_ISSET (int cpu, const cpu_set_t *set)
如果 cpu 是 CPU 集 set 的一员，这个宏就返回一个非零值（true），否则就返回零（false）。
</code></pre>
<p>我看到很多人说对于thread我们用pthread_setaffinity_np， 对于process我们才用sched_setafinity.于是我仔细的看了一下。首先，sched_setaffinity的man page上写的是</p>
<blockquote>
<p>A thread's CPU affinity mask determines the set of CPUs on which it is eligible to run</p>
</blockquote>
<p>当然它也写了</p>
<blockquote>
<p>(If you are using the POSIX threads API, then use pthread_setaffinity_np(3) instead of sched_setaffinity().)</p>
</blockquote>
<p>当我们使用</p>
<pre><code>int pthread_setaffinity_np(pthread_t thread, size_t cpusetsize, const cpu_set_t *cpuset);
int pthread_getaffinity_np(pthread_t thread, size_t cpusetsize, cpu_set_t *cpuset);
</code></pre>
<p>我们传入的是pthread_t. 而当我们使用<code>sched_setaffinity</code>时，我们传进去的可以是pid from <code>getpid()</code>,也可以是tid from <code>gettid()</code>.（对于单线程的进程，pid等于tid，对于多线程的进程，每个线程有不同的tid，但会有相同的pid。）pid_t 和pthread_t是不同的，pthread_t是同一个进程中各个线程之间的标识号，对于这个进程内是唯一的，而不同进程中，每个线程返回的pthread_t可能是一样的。而gettid是用来系统内各个线程间的标识符，由于linux采用轻量级进程实现的，它其实返回的应该是pid号。 还有需要注意的就是当你给一个线程设置了亲和性然后pthread_create 其他线程，其他线程会继承当前这个线程的亲和性。不过在我的工作范围内，sched_setaffinity 已经足够，因为线程的创建是固定的，我们也需要在创建后设置亲和性，所以不必担心亲和性的继承问题。</p>
<p>BTW: gettid() is not implemented in glibc, 所以我们需要用syscall去获取tid</p>
<pre><code class="language-c">pid_t getThreadId()
{
    return syscall(__NR_gettid);
}
</code></pre>
<h2 id="hyperthreading-numa">Hyperthreading &amp; NUMA</h2>
<p>现代cpu会有多个core，每个core可能会支持两个线程。可以通过<code>lscpu</code> 或者<code>lstopo</code> 查看。比如这张网上的图片。<br>
<img src="https://wangpifu.github.io/post-images/1588961186982.png" alt="" loading="lazy"><br>
在一些强大的工作站上会有不止一个scoket，比如我工作的机器有两个sockets，每个socket有8个core。如果hyperthreading(HT) enabled,那就将有32个hardware thread. 他们处在不同的numa（非统一内存访问架构）下，即某些cpu之间松散连接着甚至不共享memory and bus。那么hardware thread共享什么呢，有怎么关系到我们的程序呢？看上图，每个core内的两个threads会共享L1 和 L2 cache，同一个socket下的所有核会共享L3。 对于multi-socket机器，通常来讲每个socket有自己L3cache。对于NUMA，每个processor会访问自己的DRAM,不同processor之间通过一些通信机制来互相访问（QPI?）. 可以看到HT仅仅是在物理核心上使用了两个物理任务描述符，却没有增加实际的物理计算能力。 他的好处在于如果两个程序被调度到了同一个core，他们可以共享cache和TLB来降低任务切换开销。但是如果两个程序需要抢夺物理执行资源，那么反而会增加延时。对于低延迟交易来讲，我认为disable这个更好，因为它会损害性能增高延迟。但是对于互联网来讲，这个可以提高吞吐量，所以在互联网业务中，可以依据具体业务决定是否enable。对于不同numa来说，他们访问彼此的cache要明显该与访问自己的cache， 可以通过命令<code>numactl -H</code>查看，这给我们的启发是尽量让相关的任务处在同一个numa node下。</p>
<h2 id="reference">Reference</h2>
<p>https://zhuanlan.zhihu.com/p/33324549<br>
https://zhuanlan.zhihu.com/p/33621500<br>
https://eli.thegreenplace.net/2016/c11-threads-affinity-and-hyperthreading/</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[c++ Multithreading programming 学习(1)]]></title>
        <id>https://wangpifu.github.io/post/c-multithreading-programming-xue-xi-1/</id>
        <link href="https://wangpifu.github.io/post/c-multithreading-programming-xue-xi-1/">
        </link>
        <updated>2020-04-29T11:17:05.000Z</updated>
        <content type="html"><![CDATA[<h1 id="thread-overview">Thread Overview</h1>
<p><img src="https://wangpifu.github.io/post-images/1588203959444.png" alt="" loading="lazy"><br>
Thread 是一段独立于其他代码的，由操作系统调度的指令。它能使用process的资源，但是可以独立的被OS调用。 它像是轻量级的process，但是创建比process快。 同时thread可以直接与同一process下其他thread通信。 而process之间用到PIPE,FIFO来发送短小高频的消息，适用于两个process之间。或者用共享内存以及socket来通信。</p>
<h2 id="pthread">Pthread</h2>
<h3 id="overview">Overview</h3>
<p>在c++11以前，c++没有很好的thread库支持，一般是通过系统的thread库来实现线程相关代码。Pthread即源于posix系统。代码基于c，对于其他操作系统不具有移植性。</p>
<h3 id="使用pthread">使用pthread</h3>
<p>对于posix系统，需要包含头文件<code>#include &lt;pthread.h&gt;</code> ，如果需要使用<code>semaphre</code>, 则需要<code>#include &lt;semaphore.h&gt;</code>。 在编译时，需要<code>g++ test.cpp -lpthread</code> 或者在cmake中定义<code>find_package(Threads REQUIRED)</code>。</p>
<h3 id="thread-creation">Thread Creation</h3>
<h4 id="api">API</h4>
<pre><code>int pthread_create(pthread_t *thread,
              const pthread_attr_t *attr,
              void *(*start_routine)(void*), void *arg);
void pthread_exit(void *value_ptr);
int pthread_cancel(pthread_t thread);
int pthread_attr_init(pthread_attr_t *attr);
int pthread_attr_destroy(pthread_attr_t *attr);
</code></pre>
<p><code>pthread_create</code> 创建一个新的线程并运行它.它能在代码的任何处被多次调用.<br>
<code>pthread_create</code> 的参数:<br>
<code>thread</code>:返回新 thread 的唯一标识.<br>
<code>attr</code>:设置 thread 的性质.NULL 为默认性质.<br>
<code>start_routine</code>: 新 thread 运行的函数指针.<br>
<code>arg</code>:传给 start_routine 的参数,必须强制转换成 void *.NULL 为没有参数传入.</p>
<h4 id="thread-attributes">Thread Attributes</h4>
<p><code>pthread_attr_init</code> 和 <code>pthread_attr_destroy</code> 被用来初始化/销毁 thread 性质对象. 如 detached or joinable state, scheduling policy.</p>
<h4 id="thread-binding">Thread Binding</h4>
<p>参见这篇文章<a href="https://wangpifu.github.io/post/cpu-affinity-qin-he-xing">cpu 亲和性</a></p>
<h3 id="thread-termination">Thread Termination</h3>
<p>Thread 有多种终止方式：</p>
<ul>
<li>线程从它的运行中正常放回.它的工作完成.</li>
<li>线程调用 <code>pthread_exit</code> 无论它的工作完成否.</li>
<li>线程被另外一个线程调用<code>pthread_cance</code>来取消.</li>
<li>整个<strong>进程</strong>都终止，如果任何线程调用了 <code>exec()</code> 或 <code>exit()</code>.</li>
<li><code>main()</code> 函数先完成,没有调用 <code>pthread_exit</code>.</li>
</ul>
<p><code>void pthread_exit(void * rval_ptr);</code><br>
函数说明：rval_ptr参数是线程结束时的返回值，可由其他函数如pthread_join()来获取。这个调用不关闭文件,在线程打开的任何文件在线程终止后将继续打开.</p>
<ul>
<li>如果 <code>main()</code>在它创建的 threads 之前终止,并没有显式的调用 pthread_exit(),所有创建的线程都将终止，因为<code>main()</code>结束,不再存在支持这些线程.</li>
<li>通过<code>main()</code>在最后调用 <code>pthread_exit()</code>, <code>main()</code>将阻塞并保持存活来支持它创建的线程运行直到它们完成.</li>
</ul>
<p><code>int pthread_cancel(pthread_t thread);</code><br>
函数说明：取消线程，该函数在其他线程中调用，用来强行杀死指定的线程。<br>
我从来没用过这个函数，似乎使用情况有些tricky，参见这篇<a href="https://blog.csdn.net/fozhishuiyue/article/details/98936578">博客</a>。另外我自己写了个程序试验了一下但是一直有segment fault TODO: 查明原因，深入理解一下。</p>
<h4 id="example-of-pthread-creationand-termination">Example of pthread creationand termination</h4>
<p>如果注释掉 <code>main()</code>中最后的 <code>pthread_exit(NULL);</code> ,那么它创建的线程将会完成不了所有的打印而被强制退出.</p>
<pre><code class="language-c++">#include &lt;pthread.h&gt;
#include &lt;cstdio&gt;
#include &lt;cstdlib&gt;

void *ThreadProc(void *param) {
  int id;
  id = *(static_cast&lt;int *&gt;(param));
  for (int i = 0; i &lt; 10; ++i) {
    if(id == 1 &amp;&amp; i == 8)
    { 
        // for pthread_t 1, it will only print to 7 and then terminate.
        pthread_exit(NULL);
    }
    printf(&quot;thread %d: run %d \n&quot;, id, i);
  }
  pthread_exit(NULL);
}

int main(int argc, char *argv[]) {
  const int kNumThreads = 4;
  pthread_t threads[kNumThreads];
  int thread_ids[kNumThreads];
  for (int i = 0; i &lt; kNumThreads; ++i) {
    thread_ids[i] = i;
    int rt = pthread_create(&amp;threads[i], NULL, ThreadProc,
                            static_cast&lt;void *&gt;(&amp;thread_ids[i]));
    if (rt) {
      printf(&quot;ERROR: pthread_create failed, rt=%d\n&quot;, rt);
      exit(1);
    }
  }
  pthread_exit(NULL);
}
</code></pre>
<h3 id="threads-joining-and-detaching">Threads joining and detaching</h3>
<h4 id="api-2">API</h4>
<pre><code class="language-c++">int pthread_join(pthread_t thread, void **value_ptr);
int pthread_detach(pthread_t thread);
int pthread_attr_setdetachstate(pthread_attr_t *attr, int detachstate);
int pthread_attr_getdetachstate(const pthread_attr_t *attr, int *detachstate);
//PTHREAD_CREATE_DETACHED 分离
//PTHREAD_CREATE_JOINABLE 不分离
</code></pre>
<h4 id="joining">Joining</h4>
<p><img src="https://wangpifu.github.io/post-images/1588262396632.png" alt="" loading="lazy"><br>
joining 是用来同步不同线程的方法之一</p>
<ul>
<li><code>int pthread_join(pthread_t thread, void **value_ptr);</code> 将阻塞调用它的线程直到被指定的thread线程终止。</li>
<li>调用的线程能获取目标线程终止返回的 status 如果目标线程调用 <code>pthread_exit()</code></li>
<li>当一个线程被创建,它的属性之一是它是否可以 join.只有创建的能被 join 的线程才能被 join.如果线程线程以 detached 创建,它永远都不能被 join。</li>
</ul>
<h4 id="detaching">Detaching</h4>
<ul>
<li>pthread_detach() 可以将一个线程detach，即使它原先是以join位attribute建立的</li>
</ul>
<h4 id="example">Example</h4>
<pre><code class="language-c++">#include &lt;pthread.h&gt;
#include &lt;cstdio&gt;
#include &lt;cstdlib&gt;

void *ThreadProc(void *param) {
  int id;
  id = *(static_cast&lt;int *&gt;(param));
  for (int i = 0; i &lt; 10; ++i) {
    printf(&quot;thread %d: run %d \n&quot;, id, i);
  }
  pthread_exit(param);
}

int main(int argc, char *argv[]) {
  const int kNumThreads = 4;
  pthread_t threads[kNumThreads];
  int thread_ids[kNumThreads];
  pthread_attr_t attr;

  pthread_attr_init(&amp;attr);
  pthread_attr_setdetachstate(&amp;attr, PTHREAD_CREATE_JOINABLE);

  for (int i = 0; i &lt; kNumThreads; ++i) {
    thread_ids[i] = i;
    int rt = pthread_create(&amp;threads[i], &amp;attr, ThreadProc,
                            static_cast&lt;void *&gt;(&amp;thread_ids[i]));
    if (rt) {
      printf(&quot;ERROR: pthread_create failed, rt=%d\n&quot;, rt);
      exit(1);
    }
  }
  for (int i = 0; i &lt; kNumThreads; ++i) {
    void *status;
    int rt = pthread_join(threads[i], &amp;status);
    if (rt) {
      printf(&quot;ERROR: pthread_join failed, rt=%d\n&quot;, rt);
      exit(1);
    }
    printf(&quot;completed join with thread %d having a status of %d\n&quot;
           , i, *static_cast&lt;int *&gt;(status));
  }
  pthread_exit(NULL);
}
</code></pre>
<h3 id="stack-management">Stack Management</h3>
<h4 id="api-3">API</h4>
<pre><code>int pthread_attr_getstacksize(const pthread_attr_t *restrict attr,
              size_t *restrict stacksize);
int pthread_attr_setstacksize(pthread_attr_t *attr, size_t stacksize);
int pthread_attr_getstackaddr(const pthread_attr_t *restrict attr,
              void **restrict stackaddr); // removed in POSIX.1-2008
int pthread_attr_setstackaddr(pthread_attr_t *attr, void *stackaddr); 
int pthread_attr_setstack(pthread_attr_t *attr, void *stackaddr, size_t stacksize);
int pthread_attr_getstack(const pthread_attr_t *attr,  void **stackaddr, size_t *stacksize);
int pthread_attr_setguardsize(pthread_attr_t *attr, size_t guardsize);
//功能：设置线程属性中栈尾的警戒区大小
int pthread_attr_getguardsize(pthread_attr_t *attr, size_t *guardsize);
//功能：获取线程属性中栈尾的警戒区大小
</code></pre>
<p>每个线程都有各自独立的 stack, <code>pthread_attr_getstackaddr</code> 和 <code>pthread_attr_setstackaddr</code> 分别获取和设置线程的栈底地址. 在POSIX.1-2008被删除，需要使用新的api <code>pthread_attr_setstack</code>, <code>pthread_attr_getstack</code>.<code>get/setstacksize()</code>获取和设置stack的栈空间字节数。我们通过attr在<code>pthread_create()</code>传入</p>
<h4 id="example-2">example</h4>
<pre><code class="language-c++">#include &lt;pthread.h&gt;
#include &lt;cstdio&gt;
#include &lt;cstdlib&gt;

pthread_attr_t attr;

void *ThreadProc(void *param) {
  int id;
  size_t thread_stack_size;
  id = *(static_cast&lt;int *&gt;(param));
  pthread_attr_getstacksize(&amp;attr, &amp;thread_stack_size);
  printf(&quot;thread %d: stack size = %d\n&quot;, id, thread_stack_size);
  for (int i = 0; i &lt; 10; ++i) {
    printf(&quot;thread %d: run %d \n&quot;, id, i);
  }
  pthread_exit(NULL);
}

int main(int argc, char *argv[]) {
  const int kNumThreads = 4;
  const int kThround = 1000;
  pthread_t threads[kNumThreads];
  int thread_ids[kNumThreads];
  size_t stack_size;

  pthread_attr_init(&amp;attr);
  pthread_attr_getstacksize(&amp;attr, &amp;stack_size);
  printf(&quot;Default stack size = %d\n&quot;, stack_size);
  stack_size = sizeof(double) * kThround * kThround;
  printf(&quot;Setting stack size = %d\n&quot;, stack_size);
  pthread_attr_setstacksize(&amp;attr, stack_size);
  for (int i = 0; i &lt; kNumThreads; ++i) {
    thread_ids[i] = i;
    int rt = pthread_create(&amp;threads[i], &amp;attr, ThreadProc,
                            static_cast&lt;void *&gt;(&amp;thread_ids[i]));
    if (rt) {
      printf(&quot;ERROR: pthread_create failed, rt=%d\n&quot;, rt);
      exit(1);
    }
  }
  pthread_exit(NULL);
  pthread_attr_destroy(&amp;attr);
  return 0;
}
</code></pre>
<h3 id="thread-attribute上文中未提到的">Thread Attribute(上文中未提到的)</h3>
<h4 id="api-4">API</h4>
<pre><code>typedef union
{
char __size[__SIZEOF_PTHREAD_ATTR_T];
long int __align;
}pthread_attr_t;

int pthread_attr_setscope(pthread_attr_t *attr, int scope);
//功能：设置线程属性中线程的竞争范围
//PTHREAD_SCOPE_SYSTEM(绑定)
//PTHREAD_SCOPE_PROCESS(非绑定)
int pthread_attr_getscope(pthread_attr_t *attr, int *scope);
//功能：获取线程属性中线程的竞争范围
</code></pre>
<p>关于绑定属性，涉及到另外一个概念：轻进程（Light Weight Process，LWP）。轻进程可以理解为内核进程，它位于用户层和内核层之间。系统对线程资源的分配和对线程的控制时通过轻进程来实现的，一个轻进程可以控制一个或多个线程。默认情况下，启动多少轻进程、哪些轻进程来控制哪些线程是由系统来控制的，这种状况即称为非绑定。绑定状况下，则顾名思义，即某个线程固定地绑在一个轻进程之上。被绑定的线程具有较高的响应速度，这是因为CPU时间片的调度是面向轻进程的，绑定的线程可以保证在需要的时候它总有一个轻进程可用。通过设置被绑定的轻进程的优先级和调度级可以使得绑定的线程满足诸如实时反应之类的要求。</p>
<pre><code>int pthread_attr_setinheritsched(pthread_attr_t *attr, int inheritsched);
//功能：设置线程属性中线程的调度策略来源
//PTHREAD_INHERIT_SCHED 继承创建者
//PTHREAD_EXPLICIT_SCHED 单独设置
int pthread_attr_getinheritsched(pthread_attr_t *attr, int *inheritsched);

int pthread_attr_setschedpolicy(pthread_attr_t *attr, int policy);
//功能：设置线程属性中线程的调度策略
//SCHED_FIFO 先进先出策略
//SCHED_RR 轮转策略
//SCHED_OTHER 缺省
int pthread_attr_getschedpolicy(pthread_attr_t *attr, int *policy);
//功能：获取线程属性中线程的调度策略

struct sched_param {
int sched_priority;
}；
int pthread_attr_setschedparam(pthread_attr_t *attr, const struct sched_param *param);
//功能：设置线程属性中线程的调度参数（优先级别）
//param：最高级别0
int pthread_attr_getschedparam(pthread_attr_t *attr, struct sched_param *param);
</code></pre>
<p>使用方法：</p>
<ol>
<li>定义线程属性结构体 pthread_attr_t attr;</li>
<li>初始化线程属性结构体 pthread_attr_init(&amp;attr);</li>
<li>使用pthread_attr_set系列函数对结构体变量进行设置。</li>
<li>在创建线程时（pthread_create函数的第二个参数）中使用线程属性结构变量创建线程。</li>
</ol>
<pre><code>pthread_t pthread_self(void);
int pthread_equal(pthread_t t1, pthread_t t2);
int pthread_once(pthread_once_t *once_control,
              void (*init_routine)(void));
pthread_once_t once_control = PTHREAD_ONCE_INIT;
</code></pre>
<ul>
<li><code>pthread_self</code> 返回调用线程的唯一 thread ID.</li>
<li><code>pthread_equal</code> 比较两个线程 ID 是否相等.</li>
<li><code>pthread_once</code> 本函数使用初值为PTHREAD_ONCE_INIT的once_control变量保证init_routine()函数在本进程执行序列中仅执行一次。在多线程编程环境下，尽管pthread_once()调用会出现在多个线程中，init_routine()函数仅执行一次，究竟在哪个线程中执行是不定的，是由内核调度来决定。Linux Threads使用互斥锁和条件变量保证由pthread_once()指定的函数执行且仅执行一次，而once_control表示是否执行过。如果once_control的初值不是PTHREAD_ONCE_INIT（Linux Threads定义为0），pthread_once() 的行为就会不正常。在Linux中，实际&quot;一次性函数&quot;的执行状态有三种：NEVER（0）、IN_PROGRESS（1）、DONE （2），如果once初值设为1，则由于所有pthread_once()都必须等待其中一个激发&quot;已执行一次&quot;信号，因此所有pthread_once ()都会陷入永久的等待中；如果设为2，则表示该函数已执行过一次，从而所有pthread_once()都会立即返回0</li>
</ul>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[第一篇博客]]></title>
        <id>https://wangpifu.github.io/post/first-blog/</id>
        <link href="https://wangpifu.github.io/post/first-blog/">
        </link>
        <updated>2020-04-29T09:27:05.000Z</updated>
        <content type="html"><![CDATA[<p>这是一篇建立在github pages，用Gridea构建管理的私人博客站点。目前来看Gridea是最方便的搭建管理软件，避免了安装nodejs 或者 ruby。 这对于Windows系统非常方便。坦白来讲，我并不希望在我的Windows box上安装任何和技术开发相关的软件，因为他们的使用频率很低，最终会被我遗忘在漫长的时光里。而我的开发机器（based on linux），我又希望它能只承载和开发相关的事务。另外，Gridea看起来更加直观与人性化，避免了许多与写作不相关的操作。希望Gridea可以一直被维护下去，感谢Gridea。cnblog本来是我的第一选择，但是需要手机号注册。CSDN则有太多的广告。知乎的话，我更倾向于发布仔细审视后的文章。这个站点则会更随意一些，有些想法我可以先记载下来，在日后慢慢的更改完善。</p>
<p>写博客的动力来自于一次失败的面试。我意识到很多技术的积累不能光靠工作，以及需要了解平时工作下的更深入的东西。人必须要不断地走出舒适圈，去接触自己不熟悉的东西，再能慢慢变得全能起来。我是一个不喜欢走在科技前端的人，平时更倾向于利用纸笔做笔记，但是现在意识到对于代码来讲，博客可能是个更合适的地方。对于刚开始的几篇文章，发布的频率可能比较高，内容可能不够精细，因为我希望能提纲挈领地把一些我在脑海中总结过的知识转移到这个站点上来，会在随后的日子里慢慢打磨。另外，我此时迫不及待地希望我能把一些需要学习的知识点电子化的记录下来，这也会导致初期一些文章显得杂乱。</p>
<p>希望明天会更好。<br>
--20200429 阴天 纽约</p>
]]></content>
    </entry>
</feed>