<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://wangpifu.github.io</id>
    <title>wangpifu</title>
    <updated>2020-05-23T20:32:36.201Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://wangpifu.github.io"/>
    <link rel="self" href="https://wangpifu.github.io/atom.xml"/>
    <subtitle>而今迈步从头越，去留肝胆两昆仑</subtitle>
    <logo>https://wangpifu.github.io/images/avatar.png</logo>
    <icon>https://wangpifu.github.io/favicon.ico</icon>
    <rights>All rights reserved 2020, wangpifu</rights>
    <entry>
        <title type="html"><![CDATA[unix socket 编程总结]]></title>
        <id>https://wangpifu.github.io/post/unix-socket-bian-cheng-zong-jie/</id>
        <link href="https://wangpifu.github.io/post/unix-socket-bian-cheng-zong-jie/">
        </link>
        <updated>2020-05-22T11:33:19.000Z</updated>
        <content type="html"><![CDATA[<h2 id="socket-type">socket type</h2>
<h3 id="sock_stream">SOCK_STREAM</h3>
<p>SOCK_STREAM 是一种可靠的、双向的通信数据流，数据可以准确无误地到达另一台计算机，如果损坏或丢失，可以重新发送。因为它使用了 TCP 协议.流格式套接字的内部有一个缓冲区（也就是字符数组），通过 socket 传输的数据将保存到这个缓冲区。接收端在收到数据后并不一定立即读取，只要数据不超过缓冲区的容量，接收端有可能在缓冲区被填满以后一次性地读取，也可能分成好几次读取。</p>
<h3 id="sock_dgram">SOCK_DGRAM</h3>
<p>使用 UDP 协议,是一种不可靠的、不按顺序传递的、以追求速度为目的的套接字。数据的发送和接收是同步的，换句话说，接收次数应该和发送次数相同。</p>
<h2 id="socket-creation">socket creation</h2>
<p>在 Linux 下使用 &lt;sys/socket.h&gt; 头文件中 socket() 函数来创建套接字，原型为：<br>
<code>int socket(int af, int type, int protocol);</code><br>
af 为地址族（Address Family), 常用的有 <code>AF_INET</code> 和 <code>AF_INET6</code> 对应IPv4与IPv6。<br>
type 为数据传输方式/套接字类型，常用的有 <code>SOCK_STREAM</code>（流格式套接字/面向连接的套接字） 和 <code>SOCK_DGRAM</code>（数据报套接字/无连接的套接字)。<br>
protocol 表示传输协议，常用的有 <code>IPPROTO_TCP</code> 和 <code>IPPTOTO_UDP</code>，分别表示 TCP 传输协议和 UDP 传输协议。可以设为0，会通过type推导出需要什么协议。</p>
<pre><code class="language-c++">int tcp_socket = socket(AF_INET, SOCK_STREAM, 0);
int udp_socket = socket(AF_INET, SOCK_DGRAM, 0); 
</code></pre>
<h2 id="bind">bind()</h2>
<p>bind() 函数的原型为：<br>
<code>int bind(int sock, struct sockaddr *addr, socklen_t addrlen);</code><br>
sock 为 socket 文件描述符，addr 为 sockaddr 结构体变量的指针，addrlen 为 addr 变量的大小，可由 sizeof() 计算得出。</p>
<pre><code class="language-c++">int serv_sock = socket(AF_INET, SOCK_STREAM, IPPROTO_TCP);
struct sockaddr_in serv_addr;
memset(&amp;serv_addr, 0, sizeof(serv_addr));
serv_addr.sin_family = AF_INET;  //use IPv4
serv_addr.sin_addr.s_addr = inet_addr(&quot;127.0.0.1&quot;);  //localhost
serv_addr.sin_port = htons(1234);  //port

bind(serv_sock, (struct sockaddr*)&amp;serv_addr, sizeof(serv_addr));
</code></pre>
<p>这里我们使用 <code>sockaddr_in</code> 结构体，然后再强制转换为 <code>sockaddr</code> 类型.</p>
<h3 id="sockaddr_in-vs-sockaddr">sockaddr_in vs sockaddr</h3>
<p><img src="https://wangpifu.github.io/post-images/1590204417418.jpg" alt="" loading="lazy"><br>
<code>sockaddr</code> 和 <code>sockaddr_in</code> 的长度相同，都是16字节，只是将IP地址和端口号合并到一起，用一个成员 sa_data 表示。要想给 sa_data 赋值，必须同时指明IP地址和端口号，例如”127.0.0.1:80“，遗憾的是，没有相关函数将这个字符串转换成需要的形式，也就很难给 <code>sockaddr</code> 类型的变量赋值，所以使用 <code>sockaddr_in</code> 来代替。这两个结构体的长度相同，强制转换类型时不会丢失字节，也没有多余的字节。可以认为，<code>sockaddr</code> 是一种通用的结构体，可以用来保存多种类型的IP地址和端口号，而 <code>sockaddr_in</code> 是专门用来保存 IPv4 地址的结构体。另外还有 <code>sockaddr_in6</code>，用来保存 IPv6 地址</p>
<pre><code class="language-c++">struct sockaddr_in{
    sa_family_t        sin_family;     //地址族(Address Family) / 地址类型
    uint16_t            sin_port;        //16位的端口号 0-65535
    struct in_addr   sin_addr;       //32位IP地址
    char                  sin_zero[8];    //不使用，一般用0填充
};
struct in_addr{
    // inside &lt;netinet/in.h&gt;
    // typedef uint32_t in_addr_t 
    in_addr_t          s_addr;           //32位的IP地址
};
</code></pre>
<p>s_addr 是一个整数，而IP地址是一个字符串，所以需要 inet_addr() 函数进行转换<br>
<code>unsigned long ip = inet_addr(&quot;127.0.0.1&quot;); // ip will be 16777343</code></p>
<h2 id="connect">connect()</h2>
<p>connect() 函数用来建立连接，它的原型为：<br>
<code>int connect(int sock, struct sockaddr *serv_addr, socklen_t addrlen);</code></p>
<h2 id="listen">listen()</h2>
<p>通过 listen() 函数可以让套接字进入被动监听状态，它的原型为：<br>
<code>int listen(int sock, int backlog);</code><br>
sock 为需要进入监听状态的套接字，backlog 为请求队列的最大长度。当套接字正在处理客户端请求时，如果有新的请求进来，套接字是没法处理的，只能把它放进缓冲区，待当前请求处理完毕后，再从缓冲区中读取出来处理。如果不断有新的请求进来，它们就按照先后顺序在缓冲区中排队，直到缓冲区满。这个缓冲区，就称为请求队列（Request Queue）。缓冲区的长度（能存放多少个客户端请求）可以通过 listen() 函数的 backlog 参数指定，如果将 backlog 的值设置为 SOMAXCONN,则为系统最大支持值。当请求队列满时，就不再接收新的请求，对于 Linux，客户端会收到 ECONNREFUSED 错误。注意：listen() 只是让套接字处于监听状态，并没有接收请求。接收请求需要使用 accept() 函数。</p>
<h2 id="accept">accept()</h2>
<p>当套接字处于监听状态时，可以通过 accept() 函数来接收客户端请求。它的原型为：<br>
<code>int accept(int sock, struct sockaddr *addr, socklen_t *addrlen);</code><br>
accept() 返回一个新的套接字来和客户端通信，addr 保存了客户端的IP地址和端口号，而 sock 是服务器端的套接字，要注意区分。后面和客户端通信时，要使用这个新生成的套接字，而不是原来服务器端的套接字。需要说明的是：listen() 只是让套接字进入监听状态，并没有真正接收客户端请求，listen() 后面的代码会继续执行，直到遇到 accept()。accept() 会阻塞程序执行（后面代码不能被执行），直到有新的请求到来。</p>
<h2 id="write-send-read-recv">write() send() read() recv()</h2>
<p><code>write</code> 函数原型：<br>
<code>ssize_t write(int fd, const void*buf,size_t nbytes)</code><br>
<code>write</code>函数将<code>buf</code>中的<code>nbytes</code>字节内容写入文件描述符fd.成功时返回写的字节数.失败时返回-1.并设置<code>errno</code>变量. 在网络程序中,当我们向套接字文件描述符写时有两可能：</p>
<ol>
<li><code>write</code>的返回值大于0,表示写了部分或者是全部的数据. 这样我们用一个while循环来不停的写入，但是循环过程中的buf参数和nbyte参数得由我们来更新。也就是说，网络写函数是不负责将全部数据写完之后在返回的。</li>
<li>返回的值小于0,此时出现了错误.我们要根据错误类型来处理.如果错误为<code>EINTR</code>表示在写的时候出现了中断错误.如果为<code>EPIPE</code>表示网络连接出现了问题(对方已经关闭了连接)。</li>
</ol>
<p><code>read</code> 函数原型：<br>
<code>ssize_t read(int fd,void *buf,size_t nbyte)</code><br>
<code>read</code>函数是负责从fd中读取内容。当读成功时，<code>read</code>返回实际所读的字节数,如果返回的值是0 表示已经读到文件的结束了,小于0表示出现了错误。如果错误为<code>EINTR</code>说明读是由中断引起 的, 如果是<code>ECONNREST</code>表示网络连接出了问题.</p>
<p><code>recv</code>和<code>send</code>函数提供了和read和write差不多的功能.不过它们提供了第四个参数来控制读写操作：<br>
<code>int recv(int sockfd,void *buf,int len,int flags)</code><br>
<code>int send(int sockfd,void *buf,int len,int flags)</code><br>
前面的三个参数和read,write一样,第四个参数可以是0或者是以下的组合：</p>
<ol>
<li><code>MSG_DONTROUTE</code>:是send函数使用的标志.这个标志告诉IP.目的主机在本地网络上面,没有必要查找表.这个标志一般用网络诊断和路由程序里面.</li>
<li><code>MSG_OOB</code>:表示接收和发送带外的数据</li>
</ol>
<blockquote>
<p>(有些传输层协议具有带外(Out of Band,OOB)数据的概念,用于迅速通告对方本端发生的重要事件。因此，带外数据比普通数据（也称带内数据）有更高的优先级，它应该总是立即发送，而不论发送缓冲区是否有排队等待发送的普通数据。带外数据的传输可以使用一条独立的传输层连接，也可以映射到传输普通数据的连接中，TCP采用的是后者（postscript：前者应该怎么实现，应该比较复杂和消耗性能）。在实际应用中，带外数据的使用很少见，已知的仅有telnet、ftp等远程非活跃程序。</p>
</blockquote>
<ol start="3">
<li><code>MSG_PEEK</code>:是recv函数的使用标志,表示只是从系统缓冲区中读取内容,而不清除系统缓冲区的内容.这样下次读的时候,仍然是一样的内容.一般在有多个进程读写数据时可以使用这个标志.</li>
<li><code>MSG_WAITALL</code>是recv函数的使用标志,表示等到所有的信息到达时才返回.使用这个标志的时候recv回一直阻塞,直到指定的条件满足,或者是发生了错误. 1)当读到了指定的字节时,函数正常返回.返回值等于len 2)当读到了文件的结尾时,函数正常返回.返回值小于len 3)当操作发生错误时,返回-1,且设置错误为相应的错误号(errno)。</li>
</ol>
<p>如果flags为0,则和read,write一样的操作。</p>
<h2 id="workflow">workflow</h2>
<center class="half">
TCP:
<img src="file://F:/software/Gridea_blog_resources/Gridea/post-images/1590256430475.gif">
UDP:
<img src="file://F:/software/Gridea_blog_resources/Gridea/post-images/1590256440650.png">
</center>
<h2 id="socket缓冲区">socket缓冲区</h2>
<p>每个 socket 被创建后，都会分配两个缓冲区，输入缓冲区和输出缓冲区。<code>write()</code>/<code>send()</code> 并不立即向网络中传输数据，而是先将数据写入缓冲区中，再由TCP协议将数据从缓冲区发送到目标机器。一旦将数据写入到缓冲区，函数就可以成功返回，不管它们有没有到达目标机器，也不管它们何时被发送到网络，这些都是TCP协议负责的事情。TCP协议独立于 <code>write()</code>/<code>send()</code> 函数，数据有可能刚被写入缓冲区就发送到网络，也可能在缓冲区中不断积压，多次写入的数据被一次性发送到网络，这取决于当时的网络情况、当前线程是否空闲等诸多因素，不由程序员控制。<code>read()</code>/<code>recv()</code> 函数也是如此，也从输入缓冲区中读取数据，而不是直接从网络中读取。这些I/O缓冲区特性可整理如下：</p>
<ol>
<li>I/O缓冲区在每个TCP套接字中单独存在；</li>
<li>I/O缓冲区在创建套接字时自动生成；</li>
<li>即使关闭套接字也会继续传送输出缓冲区中遗留的数据；</li>
<li>关闭套接字将丢失输入缓冲区中的数据。</li>
</ol>
<p>可以通过<code>getsockopt</code>和<code>setsockopt</code>来获取以及设置socket的某个特性。如下设置发送区buffer</p>
<pre><code class="language-c++">//SOL_SOCKET is the socket layer itself. It is used for options that are protocol independent.
getsockopt(socketFd, SOL_SOCKET, SO_SNDBUF, &amp;bufSize, &amp;bufSizeLen);
setsockopt(scoktetFd, SOL_SOCKET, SO_SNDBUF, &amp;bufSize, sizeof(bufSize));
</code></pre>
<p>对于TCP套接字（默认阻塞），当使用 write()/send() 发送数据时：</p>
<ol>
<li>首先会检查缓冲区，如果缓冲区的可用空间长度小于要发送的数据，那么 write()/send() 会被阻塞(暂停执行)，直到缓冲区中的数据被发送到目标机器，腾出足够的空间，才唤醒 write()/send() 函数继续写入数据。</li>
<li>如果TCP协议正在向网络发送数据，那么输出缓冲区会被锁定，不允许写入，write()/send() 也会被阻塞，直到数据发送完毕缓冲区解锁，write()/send() 才会被唤醒。</li>
<li>如果要写入的数据大于缓冲区的最大长度，那么将分批写入。</li>
<li>直到所有数据被写入缓冲区 write()/send() 才能返回。</li>
</ol>
<p>当使用 read()/recv() 读取数据时：</p>
<ol>
<li>首先会检查缓冲区，如果缓冲区中有数据，那么就读取，否则函数会被阻塞，直到网络上有数据到来。</li>
<li>如果要读取的数据长度小于缓冲区中的数据长度，那么就不能一次性将缓冲区中的所有数据读出，剩余数据将不断积压，直到有 read()/recv() 函数再次读取。</li>
<li>直到读取到数据后 read()/recv() 函数才会返回，否则就一直被阻塞。</li>
</ol>
<h2 id="getsockopt-setsockopt">getsockopt setsockopt</h2>
<pre><code class="language-c++">#include &lt;sys/types.h&gt;
#include &lt;sys/socket.h&gt;

int getsockopt(int sockfd, int level, int optname,void *optval, socklen_t *optlen);
int setsockopt(int sockfd, int level, int optname,const void *optval, socklen_t optlen);
</code></pre>
<p><code>sockfd</code>：指向一个打开的套接字描述符<br>
<code>level</code>：通用套接字代码<br>
<code>optname</code>：选项名字<br>
<code>optval</code>：指向某个变量的指针，setsockopt从<em>optval中取得选项待设置的新值，getsockopt把已获取的选项当前值存放在</em>optval中。<br>
<code>optlen</code>：*optval的大小由optlen指定，setsockopt是一个值参数，getsockopt是一个值-结果参数。</p>
<p>成功执行时，返回0。失败返回-1，errno被设为以下的某个值</p>
<ol>
<li><code>EBADF</code>：sock不是有效的文件描述词</li>
<li><code>EFAULT</code>：optval指向的内存并非有效的进程空间</li>
<li><code>EINVAL</code>：在调用setsockopt()时，optlen无效</li>
<li><code>ENOPROTOOPT</code>：指定的协议层不能识别选项</li>
<li><code>ENOTSOCK</code>：sock描述的不是套接字</li>
</ol>
<p>level指定控制套接字的层次.可以取三种值:</p>
<ol>
<li>SOL_SOCKET:通用套接字选项.</li>
<li>IPPROTO_IP:IP选项.</li>
<li>IPPROTO_TCP:TCP选项.</li>
</ol>
<table>
<thead>
<tr>
<th>optname</th>
<th>说明</th>
<th>数据类型</th>
</tr>
</thead>
<tbody>
<tr>
<td>SOL_SOCKET level</td>
<td></td>
<td></td>
</tr>
<tr>
<td>SO_BROADCAST</td>
<td>允许发送广播数据</td>
<td>int</td>
</tr>
<tr>
<td>SO_DEBUG</td>
<td>允许调试</td>
<td>int</td>
</tr>
<tr>
<td>SO_DONTROUTE</td>
<td>不查找路由</td>
<td>int</td>
</tr>
<tr>
<td>SO_ERROR</td>
<td>获得套接字错误</td>
<td>int</td>
</tr>
<tr>
<td>SO_KEEPALIVE</td>
<td>保持连接</td>
<td>int</td>
</tr>
<tr>
<td>SO_LINGER</td>
<td>延迟关闭连接</td>
<td>struct linger</td>
</tr>
<tr>
<td>SO_OOBINLINE</td>
<td>带外数据放入正常数据流</td>
<td>int</td>
</tr>
<tr>
<td>SO_RCVBUF</td>
<td>接收缓冲区大小</td>
<td>int</td>
</tr>
<tr>
<td>SO_SNDBUF</td>
<td>发送缓冲区大小</td>
<td>int</td>
</tr>
<tr>
<td>SO_RCVLOWAT</td>
<td>接收缓冲区下限</td>
<td>int</td>
</tr>
<tr>
<td>SO_SNDLOWAT</td>
<td>发送缓冲区下限</td>
<td>int</td>
</tr>
<tr>
<td>SO_RCVTIMEO</td>
<td>接收超时</td>
<td>struct timeval</td>
</tr>
<tr>
<td>SO_SNDTIMEO</td>
<td>发送超时</td>
<td>struct timeval</td>
</tr>
<tr>
<td>SO_REUSERADDR</td>
<td>允许重用本地地址和端口</td>
<td>int</td>
</tr>
<tr>
<td>SO_TYPE</td>
<td>获得套接字类型</td>
<td>int</td>
</tr>
<tr>
<td>SO_BSDCOMPAT</td>
<td>与BSD系统兼容</td>
<td>int</td>
</tr>
<tr>
<td>IPPROTO_IP level</td>
<td></td>
<td></td>
</tr>
<tr>
<td>IP_HDRINCL</td>
<td>在数据包中包含IP首部</td>
<td>int</td>
</tr>
<tr>
<td>IP_OPTINOS</td>
<td>IP首部选项</td>
<td>int</td>
</tr>
<tr>
<td>IP_TOS</td>
<td>服务类型</td>
<td>int</td>
</tr>
<tr>
<td>IP_TTL</td>
<td>生存时间</td>
<td>int</td>
</tr>
<tr>
<td>IPPRO_TCP level</td>
<td></td>
<td></td>
</tr>
<tr>
<td>TCP_MAXSEG</td>
<td>TCP最大数据段的大小</td>
<td>int</td>
</tr>
<tr>
<td>TCP_NODELAY</td>
<td>不使用Nagle算法</td>
<td>int</td>
</tr>
</tbody>
</table>
<p>总结到这里想起来一个知识点，即我们要disable nagle算法.因为它会合并小的网络包，对于高频来讲，我们是不希望有延迟的，希望立刻发送。</p>
<pre><code class="language-c++">int flags =1;
setsockopt(sfd, SOL_TCP, TCP_NODELAY, &amp;flags, sizeof(flags));
</code></pre>
<p>另外，交易所也需要取消delay ack，这样能快速回应客户。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[c++ Multithreading programming 学习(5)]]></title>
        <id>https://wangpifu.github.io/post/c-multithreading-programming-xue-xi-5/</id>
        <link href="https://wangpifu.github.io/post/c-multithreading-programming-xue-xi-5/">
        </link>
        <updated>2020-05-12T01:59:17.000Z</updated>
        <content type="html"><![CDATA[<p>这一节我来学习一下一些更高级的用法。首先回想一下以前我们是如何进行跨线程取值的，我们需要通过共享的变量，用condition varible来提醒其他线程取值，或者通过mutex以及共享变量来组合传递变量的更改状态。或者也可以通过future promise来完成。</p>
<table>
<thead>
<tr>
<th>API</th>
<th>C++标准</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>async</td>
<td>C++11</td>
<td>异步运行一个函数，并返回保有其结果的std::future</td>
</tr>
<tr>
<td>future</td>
<td>C++11</td>
<td>等待被异步设置的值</td>
</tr>
<tr>
<td>packaged_task</td>
<td>C++11</td>
<td>打包一个函数，存储其返回值以进行异步获取</td>
</tr>
<tr>
<td>promise</td>
<td>C++11</td>
<td>存储一个值以进行异步获取</td>
</tr>
<tr>
<td>shared_future</td>
<td>C++11</td>
<td>等待被异步设置的值（可能为其他 future 所引用）</td>
</tr>
</tbody>
</table>
<h2 id="future-promise">future &amp; promise</h2>
<ul>
<li>promise non-copyable， moveable</li>
<li>future also non-copyable but can become a shared_future, which is copyable</li>
<li>promise 只能设置value，不能读取</li>
<li>future 只能读value，不能设置<br>
他们的工作流程如图：<br>
<img src="https://wangpifu.github.io/post-images/1589391652214.jpg" alt="" loading="lazy"><br>
线程1创建<code>promise</code>对象，并从该<code>promise</code>对象中获得对应future对象。线程1将<code>promise</code>对象传递给线程2，继续自己的工作直到堵塞在<code>future::get()</code>。线程2接受传入的<code>promise</code>对象，通过<code>set_value()</code>(或其他set函数)设定特定值，然后继续自己其他的工作。一旦将结果设置到<code>promise</code>上，其相关联的<code>future</code>对象就会处于就绪状态。需要注意的是，<code>future</code>对象只要被一个线程通过get()取值，再之后就没有可获取的值了，如果从多个线程调用<code>get()</code>会导致竞争，undefined behavior。如果需要从多个线程获取future结果需要使用<code>shared_future</code>。</li>
</ul>
<h3 id="example">example</h3>
<pre><code class="language-c++">#include &lt;future&gt;
#include &lt;iostream&gt;
#include &lt;thread&gt;
#include &lt;utility&gt;

void multiplier(std::promise&lt;int&gt;&amp;&amp; intPromise, int a, int b){
  intPromise.set_value(a*b);
}

void divider() (std::promise&lt;int&gt;&amp;&amp; intPromise, int a, int b) {
    intPromise.set_value(a/b);
  }

int main(){
  int a= 20;
  int b= 10;

  std::cout &lt;&lt; std::endl;
  // define the promises
  std::promise&lt;int&gt; prodPromise;
  std::promise&lt;int&gt; divPromise;
  // get the futures
  std::future&lt;int&gt; prodFutureResult= prodPromise.get_future();
  std::future&lt;int&gt; divFutureResult= divPromise.get_future();
  // calculate the result in a separat thread
  std::thread prodThread(multiplier,std::move(prodPromise),a,b);
  std::thread divThread(divider,std::move(divPromise),a,b);
  // get the result
  std::cout &lt;&lt; &quot;20*10= &quot; &lt;&lt; prodFutureResult.get() &lt;&lt; std::endl;
  std::cout &lt;&lt; &quot;20/10= &quot; &lt;&lt; divFutureResult.get() &lt;&lt; std::endl;
  prodThread.join();
  divThread.join();
  std::cout &lt;&lt; std::endl;
}
</code></pre>
<h2 id="packaged_task">packaged_task</h2>
<p>在一些业务中，我们可能会有很多的任务需要调度。这时我们常常会设计出任务队列和线程池的结构。此时，就可以使用<code>packaged_task</code>来包装任务。<code>packaged_task</code>绑定到一个函数或者可调用对象上。当它被调用时，它就会调用其绑定的函数或者可调用对象。并且，可以通过与之相关联的<code>future</code>来获取任务的结果。调度程序只需要处理<code>packaged_task</code>，而非各个函数。<br>
<code>packaged_task</code>对象是一个可调用对象，它可以被封装成一个<code>std::fucntion</code>，或者作为线程函数传递给<code>std::thread</code>，或者直接调用。<code>packaged_task</code>中可以传入函数对象，函数指针，lambda函数等。注意，这些函数并不是在<code>package_task</code>构造时被执行，需要手动invoke，才能执行。可以在当前线程执行，也可以被move到其他线程。</p>
<h3 id="example-2">example</h3>
<pre><code class="language-c++">double concurrent_worker(int min, int max) {
  double sum = 0;
  for (int i = min; i &lt;= max; i++) {
    sum += sqrt(i);
  }
  return sum;
}

double concurrent_task(int min, int max) {
  vector&lt;future&lt;double&gt;&gt; results; // ①

  unsigned concurrent_count = thread::hardware_concurrency();
  min = 0;
  for (int i = 0; i &lt; concurrent_count; i++) { // ②
    packaged_task&lt;double(int, int)&gt; task(concurrent_worker); // ③
    results.push_back(task.get_future()); // ④

    int range = max / concurrent_count * (i + 1);
    thread t(std::move(task), min, range); // ⑤
    t.detach();

    min = range + 1;
  }

  cout &lt;&lt; &quot;threads create finish&quot; &lt;&lt; endl;
  double sum = 0;
  for (auto&amp; r : results) {
    sum += r.get(); // ⑥
  }
  return sum;
}

int main() {
  auto start_time = chrono::steady_clock::now();

  double r = concurrent_task(0, MAX);

  auto end_time = chrono::steady_clock::now();
  auto ms = chrono::duration_cast&lt;chrono::milliseconds&gt;(end_time - start_time).count();
  cout &lt;&lt; &quot;Concurrent task finish, &quot; &lt;&lt; ms &lt;&lt; &quot; ms consumed, Result: &quot; &lt;&lt; r &lt;&lt; endl;
  return 0;
}
</code></pre>
<p>在这段代码中：</p>
<ol>
<li>首先创建一个集合来存储future对象。我们将用它来获取任务的结果。</li>
<li>同样的，根据CPU的情况来创建线程的数量。</li>
<li>将任务包装成packaged_task。请注意，由于concurrent_worker被包装成了任务，我们无法直获取它的return值。而是要通过future对象来获取。</li>
<li>获取任务关联的future对象，并将其存入集合中。</li>
<li>通过一个新的线程来执行任务，并传入需要的参数。</li>
<li>通过future集合，逐个获取每个任务的计算结果，将其累加。这里r.get()获取到的就是每个任务中concurrent_worker的返回值。</li>
</ol>
<h2 id="async">async</h2>
<p>async 是更上层的封装</p>
<pre><code class="language-c++">template&lt; class Function, class... Args &gt;
std::future&lt;std::invoke_result_t&lt;std::decay_t&lt;Function&gt;, 
                                 std::decay_t&lt;Args&gt;...&gt;&gt;
    async( std::launch policy, Function&amp;&amp; f, Args&amp;&amp;... args );

template&lt; class Function, class... Args&gt;
std::future&lt;std::invoke_result_t&lt;std::decay_t&lt;Function&gt;, 
                                              std::decay_t&lt;Args&gt;...&gt;&gt;
    async( Function&amp;&amp; f, Args&amp;&amp;... args );
</code></pre>
<p><code>std::launch</code> <code>policy</code> 有两种：<code>async</code> 或 <code>deferred</code>。两者的区别在于，<code>async</code>是在新线程中异步执行，通过返回的<code>future</code>的<code>get</code>函数来取值。而<code>deferred</code> 是在当前线程中同步执行，但请注意，并不是立即执行，而是延后到<code>get</code>函数被调用的时候才执行，这种取值的行为又被称为lazy evaluation。没有std::launch的重载版本表现如同以 policy 为 <code>std::launch::async</code> | <code>std::launch::deferred</code> 调用  。换言之， f 可能执行于另一线程，或者它可能在查询产生的 <code>std::future</code> 的值时同步运行。</p>
<h3 id="example-3">example</h3>
<pre><code class="language-c++">#include &lt;iostream&gt;
#include &lt;vector&gt;
#include &lt;algorithm&gt;
#include &lt;numeric&gt;
#include &lt;future&gt;
#include &lt;string&gt;
#include &lt;mutex&gt;
 
std::mutex m;
struct X {
    void foo(int i, const std::string&amp; str) {
        std::lock_guard&lt;std::mutex&gt; lk(m);
        std::cout &lt;&lt; str &lt;&lt; ' ' &lt;&lt; i &lt;&lt; '\n';
    }
    void bar(const std::string&amp; str) {
        std::lock_guard&lt;std::mutex&gt; lk(m);
        std::cout &lt;&lt; str &lt;&lt; '\n';
    }
    int operator()(int i) {
        std::lock_guard&lt;std::mutex&gt; lk(m);
        std::cout &lt;&lt; i &lt;&lt; '\n';
        return i + 10;
    }
};
 
template &lt;typename RandomIt&gt;
int parallel_sum(RandomIt beg, RandomIt end)
{
    auto len = end - beg;
    if (len &lt; 1000)
        return std::accumulate(beg, end, 0);
 
    RandomIt mid = beg + len/2;
    auto handle = std::async(std::launch::async,
                             parallel_sum&lt;RandomIt&gt;, mid, end);
    int sum = parallel_sum(beg, mid);
    return sum + handle.get();
}
 
int main()
{
    std::vector&lt;int&gt; v(10000, 1);
    std::cout &lt;&lt; &quot;The sum is &quot; &lt;&lt; parallel_sum(v.begin(), v.end()) &lt;&lt; '\n';
 
    X x;
    // Calls (&amp;x)-&gt;foo(42, &quot;Hello&quot;) with default policy:
    // may print &quot;Hello 42&quot; concurrently or defer execution
    auto a1 = std::async(&amp;X::foo, &amp;x, 42, &quot;Hello&quot;);
    // Calls x.bar(&quot;world!&quot;) with deferred policy
    // prints &quot;world!&quot; when a2.get() or a2.wait() is called
    auto a2 = std::async(std::launch::deferred, &amp;X::bar, x, &quot;world!&quot;);
    // Calls X()(43); with async policy
    // prints &quot;43&quot; concurrently
    auto a3 = std::async(std::launch::async, X(), 43);
    a2.wait();                     // prints &quot;world!&quot;
    std::cout &lt;&lt; a3.get() &lt;&lt; '\n'; // prints &quot;53&quot;
} // if a1 is not done at this point, destructor of a1 prints &quot;Hello 42&quot; here
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[CMake 初探]]></title>
        <id>https://wangpifu.github.io/post/cmake-xue-xi-ji-yi-ci-yun-wei-shi-zhan/</id>
        <link href="https://wangpifu.github.io/post/cmake-xue-xi-ji-yi-ci-yun-wei-shi-zhan/">
        </link>
        <updated>2020-05-05T15:42:43.000Z</updated>
        <content type="html"><![CDATA[<p>今天兴致勃勃地写了一些自己的底层socket库代码，用到了uriparser<code>#include &lt;uriparser/Uri.h&gt;</code>，在<code>CmakeLists.tx</code>t里写了<code>find_package(UriParser)</code>然而在跑cmake时却说找不到这个库，我一直对cmake是怎么找链接库不太了解，刚好趁这个机会研究一下。<br>
首先我很好奇的是我以前用到了<code>boost</code>和<code>gtest</code>，都是直接<code>find_package</code>就找到了，为什么这次不行呢。原来cmake会先在自带的模块查找，这个模块路径一般是<code>/usr/share/cmake/Modules</code>。拿Gtest来说，cmake有<code>FindGtest.cmake</code>在上述路径，所以每当我们使用<code>find_package</code>时，他就会调用这个模块找到外部库。<br>
那么对于没有自带模块的外部库要如何查找呢。我们需要自己写一个<code>Findxxx.cmake</code>，或者在网上找一找看有没有人写好。我是在网上找了一份，因为自己不会</p>
<pre><code># Find the UriParser library
# Defines:

#  URIPARSER_INCLUDE_DIR - uriparser include directory
#  URIPARSER_LIBRARY     - uriparser library file
#  URIPARSER_FOUND       - TRUE if uriparser is found

if (URIPARSER_INCLUDE_DIR)
 #check cache 
  set(URIPARSER_FIND_QUIETLY TRUE)
endif ()

if (NOT URIPARSER_INCLUDE_DIR)
    find_path(URIPARSER_INCLUDE_DIR NAMES Uri.h PATH_SUFFIXES uriparser)
    set(URIPARSER_INCLUDE_DIR ${URIPARSER_INCLUDE_DIR}/uriparser CACHE PATH &quot;uriparser includes&quot;)
endif ()

find_library(URIPARSER_LIBRARY NAMES uriparser)

if (URIPARSER_INCLUDE_DIR AND URIPARSER_LIBRARY)
  set(URIPARSER_FOUND TRUE)
  set(UriParser_FOUND TRUE)
endif ()

if (URIPARSER_FOUND)
   if (NOT URIPARSER_FIND_QUIETLY)
      message(STATUS &quot;Found UriParser library: ${URIPARSER_LIBRARY}&quot;)
   endif ()
else ()
   if (NOT URIPARSER_FIND_QUIETLY)
      message(FATAL_ERROR &quot;Could NOT find UriParser library&quot;)
    else ()
      message(STATUS &quot;Could NOT find UriParser library&quot;)
    endif ()
endif ()
</code></pre>
<p>然后将这个文件放在<code>proj/cmake</code>下， 然后再CMakeLists.txt里定义</p>
<pre><code class="language-cmake">set(CMAKE_MODULE_PATH
     ${CMAKE_SOURCE_DIR}/cmake
     ${CMAKE_MODULE_PATH})
</code></pre>
<p>在需要使用uriparser的子项目CMakeLists.txt中定义<code>target_link_libraries(subproj PUBLIC ${URIPARSER_LIBRARY})</code>即可。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[c++ Multithreading programming 学习(4)]]></title>
        <id>https://wangpifu.github.io/post/c/</id>
        <link href="https://wangpifu.github.io/post/c/">
        </link>
        <updated>2020-05-02T15:25:43.000Z</updated>
        <content type="html"><![CDATA[<p>先放一张c++ 特性在不同版本的线路图：<br>
<img src="https://wangpifu.github.io/post-images/1588735714078.png" alt="" loading="lazy"></p>
<h2 id="线程创建">线程创建</h2>
<p>构造一个<code>thread</code>对象，可以传入参数，这些参数are either moved or copied by value. 如果我们要传入一个引用，需要<code>std::ref</code>。 新的线程创建之后即有可能被执行，至于是当前线程下一条语句先执行还是新线程先执行取决于操作系统的调度策略。</p>
<pre><code class="language-c++">void f1(int n)
{
    for (int i = 0; i &lt; 5; ++i) {
        std::cout &lt;&lt; &quot;Thread 1 executing\n&quot;;
        ++n;
        std::cout &lt;&lt; n &lt;&lt; std::endl;
        std::this_thread::sleep_for(std::chrono::milliseconds(10));
    }
}
int main()
{
    int n = 5
    std::thread t2(f1, n + 1); // pass by value
    t2.join();
    std::cout &lt;&lt; n &lt;&lt; std::endl;
}
</code></pre>
<h2 id="join-detach">join &amp; detach</h2>
<p><code>join</code>是等待线程完成执行，在等待过程中会阻塞当前<code>*this</code> 线程执行。  <code>detach</code>是将线程分离出去独自完成，被分配给分离线程的资源会在这个线程执行完后自动释放。我们需要在thread对象析构前决定是将它<code>join</code>还是<code>detach</code>，否则thread在析构时叫调用<code>std::terminate()</code>并导致进程异常退出. <code>joinable()</code>用来检测线程是否是活跃的线程，是则返回<code>true</code>，如果一个线程已经执行完毕但是还没有被joined，调用<code>joinable</code>也会返回<code>true</code>。</p>
<h2 id="线程管理">线程管理</h2>
<p><code>std::this_thread::get_id()</code> 返回当前线程id<br>
<code>std::this_thread::yeild()</code> 让出处理器，让其他线程可以被调用。比如说busy wait时让出。<br>
<code>std::this_thread::sleep_for()</code> 使当前线程停止一段时间。<br>
<code>std::this_thread::sleep_until()</code> 使当前线程停止到指定时间。<br>
<code>once_flag()</code> 和<code>call_once(once_flag&amp; flag, Callable&amp;&amp; f, Args&amp;&amp;... args)</code> 即便在多线程concurrent情况下，确保f只被call了一次。<br>
对于<code>get_id()</code>来说，这里返回的应该是底层所对应的thread id。 我们用<code>native_handle()</code> 来看一下， native_handle() 可以让我们直接用底层库(POSIX on Linux or Windows API on Windows)来操作线程。</p>
<pre><code class="language-c++">#include &lt;iostream&gt;
#include &lt;pthread.h&gt;
#include &lt;thread&gt;
#include &lt;mutex&gt;
int main(int argc, const char** argv) {
  std::mutex iomutex;
  std::thread t = std::thread([&amp;iomutex] {
    {
      std::lock_guard&lt;std::mutex&gt; iolock(iomutex);
      std::cout &lt;&lt; &quot;Thread: my id = &quot; &lt;&lt; std::this_thread::get_id() &lt;&lt; &quot;\n&quot;
                &lt;&lt; &quot;        my pthread id = &quot; &lt;&lt; pthread_self() &lt;&lt; &quot;\n&quot;;
    }
  });

  {
    std::lock_guard&lt;std::mutex&gt; iolock(iomutex);
    std::cout &lt;&lt; &quot;Launched t: id = &quot; &lt;&lt; t.get_id() &lt;&lt; &quot;\n&quot;
              &lt;&lt; &quot;            native_handle = &quot; &lt;&lt; t.native_handle() &lt;&lt; &quot;\n&quot;;
  }

  t.join();
  return 0;
}
</code></pre>
<p>这个程序打印出的是</p>
<pre><code>Launched t: id = 139958647310080
            native_handle = 139958647310080        
Thread: my id = 139958647310080
            my pthread id = 139958647310080
</code></pre>
<p>可以看到，在POSIX平台上，<code>native_handle()</code>所拿到的id就是<code>pthread_self()</code> 返回的<code>pthread_t</code>(注意：不是<code>pid_t</code>!!)，而<code>get_id</code>()和这个值相同。那么知道了id有什么用呢？我们可以根据thread id来设置cpu affinity。尽管我们可以通过在命令行输入 <code>taskset -c $cpuid ./program</code>来限制我们想在哪些cpu上运行程序，但是我们有时更希望可以在程序内部设定。这时我们就需要用到<code>pthread_setaffinity_np</code>了，注意这里我们不能使用<a href="https://wangpifu.github.io/post/cpu-affinity-qin-he-xing/">这篇博客</a>提到的<code>sched_setaffinity</code>因为<code>native_handle()</code>返回的是<code>pthread_t</code>而不是<code>pid_t</code>。</p>
<pre><code class="language-c++">int main(int argc, const char** argv) {
  constexpr unsigned num_threads = 4;
  // A mutex ensures orderly access to std::cout from multiple threads.
  std::mutex iomutex;
  std::vector&lt;std::thread&gt; threads(num_threads);
  for (unsigned i = 0; i &lt; num_threads; ++i) {
    threads[i] = std::thread([&amp;iomutex, i] {
      std::this_thread::sleep_for(std::chrono::milliseconds(20));
      while (1) {
        {
          // Use a lexical scope and lock_guard to safely lock the mutex only
          // for the duration of std::cout usage.
          std::lock_guard&lt;std::mutex&gt; iolock(iomutex);
          std::cout &lt;&lt; &quot;Thread #&quot; &lt;&lt; i &lt;&lt; &quot;: on CPU &quot; &lt;&lt; sched_getcpu() &lt;&lt; &quot;\n&quot;;
        }

        // Simulate important work done by the tread by sleeping for a bit...
        std::this_thread::sleep_for(std::chrono::milliseconds(900));
      }
    });

    // Create a cpu_set_t object representing a set of CPUs. Clear it and mark
    // only CPU i as set.
    cpu_set_t cpuset;
    CPU_ZERO(&amp;cpuset);
    CPU_SET(i, &amp;cpuset);
    int rc = pthread_setaffinity_np(threads[i].native_handle(),
                                    sizeof(cpu_set_t), &amp;cpuset);
    if (rc != 0) {
      std::cerr &lt;&lt; &quot;Error calling pthread_setaffinity_np: &quot; &lt;&lt; rc &lt;&lt; &quot;\n&quot;;
    }
  }

  for (auto&amp; t : threads) {
    t.join();
  }
  return 0;
}
</code></pre>
<h2 id="mutex">mutex</h2>
<p><code>mutex</code>	C++11	提供基本互斥设施<br>
<code>timed_mutex</code>	C++11	提供互斥设施，带有超时功能<br>
<code>recursive_mutex</code>	C++11	提供能被同一线程递归锁定的互斥设施<br>
<code>recursive_timed_mutex</code>	C++11	提供能被同一线程递归锁定的互斥设施，带有超时功能<br>
<code>shared_timed_mutex</code>	C++14	提供共享互斥设施并带有超时功能<br>
<code>shared_mutex</code>	C++17	提供共享互斥设施<br>
对于上面的锁，有下列方法可以操作<br>
<code>lock()</code>	锁定mutex，如果mutex不可用，则当前线程阻塞<br>
<code>try_lock()</code>	尝试锁定mutex，如果mutx不可用，直接返回<br>
<code>unlock()</code>	解锁mutex<br>
上面不同类型的锁在三个方面对基础的mutex进行了拓展</p>
<ul>
<li>超时：<code>timed_mutex</code>，<code>recursive_timed_mutex</code>，<code>shared_timed_mutex</code>的名称都带有timed，这意味着它们都支持超时功能。它们都提供了<code>try_lock_for</code>和<code>try_lock_until</code>方法，这两个方法分别可以指定超时的时间长度和时间点。如果在超时的时间范围内没有能获取到锁，则直接返回，不再继续等待。</li>
<li>可重入：<code>recursive_mutex</code>和<code>recursive_timed_mutex</code>的名称都带有recursive。可重入或者叫做可递归，是指在同一个线程中，同一把锁可以锁定多次。这就避免了一些不必要的死锁。</li>
<li>共享：<code>shared_timed_mutex</code>和<code>shared_mutex</code>提供了共享功能。对于这类互斥体，实际上是提供了两把锁：一把是共享锁，一把是互斥锁。一旦某个线程获取了互斥锁，任何其他线程都无法再获取互斥锁和共享锁；但是如果有某个线程获取到了共享锁，其他线程无法再获取到互斥锁，但是还有获取到共享锁。这里互斥锁的使用和其他的互斥体接口和功能一样。而共享锁可以同时被多个线程同时获取到（使用共享锁的接口见下面的表格）。共享锁通常用在读者写者模型上。<br>
使用共享锁的接口如下：<br>
<code>lock_shared</code>	获取互斥体的共享锁，如果无法获取则阻塞<br>
<code>try_lock_shared</code>	尝试获取共享锁，如果不可用，直接返回<br>
<code>unlock_shared</code>	解锁共享锁<br>
一个示例程序：</li>
</ul>
<pre><code class="language-c++">
void concurrent_worker(int min, int max) {
  double tmp_sum = 0;
  for (int i = min; i &lt;= max; i++) {
    tmp_sum += sqrt(i); // ①
  }
  exclusive.lock(); // ②
  sum += tmp_sum;
  exclusive.unlock();
}
void concurrent_task(int min, int max) {
  auto start_time = chrono::steady_clock::now();

  unsigned concurrent_count = thread::hardware_concurrency();
  cout &lt;&lt; &quot;hardware_concurrency: &quot; &lt;&lt; concurrent_count &lt;&lt; endl;
  vector&lt;thread&gt; threads;
  min = 0;
  sum = 0;
  for (int t = 0; t &lt; concurrent_count; t++) {
    int range = max / concurrent_count * (t + 1);
    threads.push_back(thread(concurrent_worker, min, range)); // ③
    min = range + 1;
  }
  for (int i = 0; i &lt; threads.size(); i++) {
    threads[i].join();
  }

  auto end_time = chrono::steady_clock::now();
  auto ms = chrono::duration_cast&lt;chrono::milliseconds&gt;(end_time - start_time).count();
  cout &lt;&lt; &quot;Concurrent task finish, &quot; &lt;&lt; ms &lt;&lt; &quot; ms consumed, Result: &quot; &lt;&lt; sum &lt;&lt; endl;
}
</code></pre>
<p>我们用锁的粒度（granularity）来描述锁的范围。细粒度（fine-grained）是指锁保护较小的范围，粗粒度（coarse-grained）是指锁保护较大的范围。出于性能的考虑，我们应该保证锁的粒度尽可能的细。并且，不应该在获取锁的范围内执行耗时的操作，例如执行IO。如果是耗时的运算，也应该尽可能的移到锁的外面。如上代码，如果在for loop里对每次计算都加锁，那么执行时间反而会大幅增加。</p>
<p>如过我们有多个锁，要求每个task都必须锁上全部才能执行，那就有可能陷入死锁。C++ 11标准中为我们提供了一些工具来避免因为多把锁而导致的死锁。我们只要直接调用这些接口就可以了。下面提到的两个函数，它们都支持传入多个Lockable对象。<br>
<code>template &lt;class Mutex1, class Mutex2, class... Mutexes&gt; void lock (Mutex1&amp; a, Mutex2&amp; b, Mutexes&amp;... cde);</code><br>
<code>template &lt;class Mutex1, class Mutex2, class... Mutexes&gt; int try_lock (Mutex1&amp; a, Mutex2&amp; b, Mutexes&amp;... cde);</code><br>
我们同时来获取多把锁，标准库的实现保证了不会发生死锁。</p>
<h2 id="mutex-管理">Mutex 管理</h2>
<table>
<thead>
<tr>
<th>API</th>
<th>C++标准</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>lock_guard</code></td>
<td>C++11</td>
<td>实现严格基于作用域的互斥体所有权包装器</td>
</tr>
<tr>
<td><code>unique_lock</code></td>
<td>C++11</td>
<td>实现可移动的互斥体所有权包装器</td>
</tr>
<tr>
<td><code>shared_lock</code></td>
<td>C++14</td>
<td>实现可移动的共享互斥体所有权封装器</td>
</tr>
<tr>
<td><code>scoped_lock</code></td>
<td>C++17</td>
<td>用于多个互斥体的免死锁 RAII 封装器</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th>锁定策略</th>
<th>C++标准</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>defer_lock</code></td>
<td>C++11</td>
<td>类型为 defer_lock_t，不获得互斥的所有权</td>
</tr>
<tr>
<td><code>try_to_lock</code></td>
<td>C++11</td>
<td>类型为try_to_lock_t，尝试获得互斥的所有权而不阻塞</td>
</tr>
<tr>
<td><code>adopt_lock</code></td>
<td>C++11</td>
<td>类型为adopt_lock_t，假设调用方已拥有互斥的所有权</td>
</tr>
</tbody>
</table>
<p>如上一节所说，为避免死锁，我们需要同时把所有的锁锁住。假设现在我们处在用一个账户给另一个账户转钱的情境中，我们需要每个账户都有自己的锁，在转钱时，要同时锁住两个账户的锁。</p>
<pre><code class="language-c++">lock(*accountA-&gt;getLock(), *accountB-&gt;getLock());
lock_guard lockA(*accountA-&gt;getLock(), adopt_lock);
lock_guard lockB(*accountB-&gt;getLock(), adopt_lock);
</code></pre>
<p>如果使用unique_lock这三行代码还有一种等价的写法：</p>
<pre><code class="language-c++">unique_lock lockA(*accountA-&gt;getLock(), defer_lock);
unique_lock lockB(*accountB-&gt;getLock(), defer_lock);
lock(*accountA-&gt;getLock(), *accountB-&gt;getLock());
</code></pre>
<p>注意这里lock方法的调用位置。这里先定义<code>unique_lock</code>指定了<code>defer_lock</code>，因此实际没有锁定互斥体，而是到第三行才进行锁定。<br>
最后，借助scoped_lock，我们可以将三行代码合成一行，这种写法也是等价的。<br>
<code>scoped_lock lockAll(*accountA-&gt;getLock(), *accountB-&gt;getLock());</code><br>
<code>scoped_lock</code>会在其生命周期范围内锁定互斥体，销毁的时候解锁。同时，它可以锁定多个互斥体，并且避免死锁。</p>
<h2 id="condition-varible">Condition Varible</h2>
<p>Condition variable 通常和一个时间或变量联系到一起，通常来说，一个线程会</p>
<ul>
<li>改变变量然后通知其他线程</li>
<li>或者等待某个变量满足条件</li>
</ul>
<table>
<thead>
<tr>
<th>API</th>
<th>C++标准</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>condition_variable</td>
<td>C++ 11</td>
<td>提供与 std::unique_lock 关联的条件变量</td>
</tr>
<tr>
<td>condition_variable_any</td>
<td>C++ 11</td>
<td>提供与任何锁类型关联的条件变量</td>
</tr>
<tr>
<td>notify_all_at_thread_exit</td>
<td>C++ 11</td>
<td>安排到在此线程完全结束时对 notify_all 的调用</td>
</tr>
<tr>
<td>cv_status</td>
<td>C++ 11</td>
<td>列出条件变量上定时等待的可能结果</td>
</tr>
</tbody>
</table>
<h3 id="一个简单例子">一个简单例子</h3>
<pre><code class="language-c++">#include &lt;condition_variable&gt;
#include &lt;iostream&gt;
#include &lt;thread&gt;

std::mutex mutex_;
std::condition_variable condVar; 
bool dataReady{false};

void waitingForWork(){
    std::cout &lt;&lt; &quot;Waiting &quot; &lt;&lt; std::endl;
    std::unique_lock&lt;std::mutex&gt; lck(mutex_);
    condVar.wait(lck, []{ return dataReady; });   // (4)
    std::cout &lt;&lt; &quot;Running &quot; &lt;&lt; std::endl;
}

void setDataReady(){
    {
        std::lock_guard&lt;std::mutex&gt; lck(mutex_);
        dataReady = true;
    }
    std::cout &lt;&lt; &quot;Data prepared&quot; &lt;&lt; std::endl;
    condVar.notify_one();                        // (3)
}

int main(){
  std::cout &lt;&lt; std::endl;
  std::thread t1(waitingForWork);               // (1)
  std::thread t2(setDataReady);                 // (2)
  t1.join();
  t2.join();
  std::cout &lt;&lt; std::endl;
}
</code></pre>
<p>上面的程序有两个thread， 一个<code>setDataReady</code>【2】，另一个<code>waitingForWork</code>【1】。t2通过<code>lock_guard</code>上锁然后改变dataReady,通过<code>notify_one()</code>【3】通知等待这个条件变量<code>condVar</code>的另外一条线程。 线程t1通过条件变量进行等待，他会通过pred(即那个lambda表达式)来判断条件是否满足，如果满足会继续。如果<strong>不满足就解锁锁，然后当前线程陷入等待</strong>。这样其他线程才能获得锁。这里我想讨论一下<code>notify_one()</code> 和 <code>notify_all()</code>的区别，如果我没记错，他们在linux下分别对应<code>pthread_cond_signal</code>和<code>pthread_cond_broadcast</code>。一个是唤醒至少一个阻塞在当前条件变量的线程，如果有不止一个线程在等待当前条件变量，调度策略会决定哪一个线程将结束阻塞；另外一个是唤醒所有的阻塞在当前条件变量的线程，这些线程需要去竞争锁。看上去<code>notify_all()</code>是<code>notify_one()</code>的超集，但是我们需要考虑具体的业务场景，如果只需要众多线程中的一个去处理，那实在没有必要去<code>notify_all()</code>.</p>
<h4 id="运行结果">运行结果</h4>
<pre><code>Waiting
Data prepared      
Running
</code></pre>
<p>为什么我们需要在【4】有一个pred而不是直接去等待这个条件变量呢，在此之前，我们先介绍两种现象，一种是lost wakeup, 另外一种是spurious wakeup。 前者是指在接受线程进入等待状态前，发送线程就已经发送了通知，后果就是这个通知丢了，接受线程会永远等待下去。后者是指没有通知发送，但是还是有接受线程醒来。而pred就是为了避免这两种现象。</p>
<p>在上面的例子里，线程t1会先锁住mutex，然后去查看pred <code>[]{return dataReady;}</code>，如果pred返回<code>true</code>那么线程继续工作，返回<code>false</code>那么<code>condVar.wait()</code>解锁mutex，然后进入等待/阻塞状态。当condVar处于等待状态时，收到一个通知，他会从从阻塞中恢复并获取mutex锁，然后检查pred，如果pred是<code>true</code>则继续工作，<code>false</code>那么<code>condVar.wait()</code>解锁mutex，然后进入等待/阻塞状态. 如果去掉pred，那么我们可能会陷入死锁</p>
<pre><code>Data prepared      
Waiting
</code></pre>
<p>这是因为t1还没有进入等待状态时，t2就已经发送了通知，所以t1会永远等下去。 而加了pred，它对应</p>
<pre><code class="language-c++">while (!pred()) {
    wait(lock);
}
</code></pre>
<p>这样不仅避免了lost wakeup，也解决了spurious wakeup。当然，对于一些复杂情况，比如A则执行actionA,B则执行actionB,用没有pred的wait()会有更好的性能。这也是为社么cpp有不含pred的重载<br>
e.g.</p>
<pre><code class="language-c++">cond.wait(lock, []{return (A || B);});
if(A) {
    actionA();
}
else {
    actionB();
}
</code></pre>
<p>需要检测条件两次,而</p>
<pre><code class="language-c++">while(true)
{
    if(A) {
         actionA();
         break;
    }
    else if(B) {
         actionB();
         break;
    }
    cond.wait(lock);
}
</code></pre>
<p>对于每种情况只检测一次。</p>
<h2 id="reference">Reference</h2>
<ul>
<li>https://eli.thegreenplace.net/2016/c11-threads-affinity-and-hyperthreading/</li>
<li>https://paul.pub/cpp-concurrency/</li>
<li>https://www.modernescpp.com/index.php/c-core-guidelines-be-aware-of-the-traps-of-condition-variables</li>
</ul>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[c++ Multithreading programming 学习(3)]]></title>
        <id>https://wangpifu.github.io/post/c-multithreading-programming-xue-xi-3/</id>
        <link href="https://wangpifu.github.io/post/c-multithreading-programming-xue-xi-3/">
        </link>
        <updated>2020-04-29T22:04:33.000Z</updated>
        <content type="html"><![CDATA[<p>继上一篇介绍完pthead，本来想接着学习c++的thread库，但又有点犯懒，感觉自己封装一下pthread就好，因为我的业余开发环境是linux，而且c++版本还停留在c++11（很多人诟病c++11 的thread库），所以只要封装出thread, mutex, condition_variable和lock_guard (RAII. acquire resource at initialization and release at destruction) 那应该就够我自己用了。但是考虑到公司早已转到c++17, 我还是学习一下。不过在这一节，我先附上一些对我以前一些疑问的解答，在下一节再接着写 <code>&lt;thread&gt;</code>库。</p>
<blockquote>
<p>作者：Gomo Psivarh<br>
链接：https://www.zhihu.com/question/31459750/answer/52069135<br>
来源：知乎<br>
著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。<br>
C/C++多线程编程中不要使用volatile。（注：这里的意思指的是指望volatile解决多线程竞争问题是有很大风险的，除非所用的环境系统不可靠才会为了保险加上volatile，或者是从极限效率考虑来实现很底层的接口。这要求编写者对程序逻辑走向很清楚才行，不然就会出错）C++11标准中明确指出解决多线程的数据竞争问题应该使用原子操作或者互斥锁。C和C++中的volatile并不是用来解决多线程竞争问题的，而是用来修饰一些因为程序不可控因素导致变化的变量，比如访问底层硬件设备的变量，以提醒编译器不要对该变量的访问擅自进行优化。多线程场景下可以参考《Programming with POSIX threads》的作者Dave Butenhof对Why don't I need to declare shared variables VOLATILE?这个问题的解释：comp.programming.threads FAQ简单的来说，对访问共享数据的代码块加锁，已经足够保证数据访问的同步性，再加volatile完全是多此一举。如果光对共享变量使用volatile修饰而在可能存在竞争的操作中不加锁或使用原子操作对解决多线程竞争没有任何卵用，因为volatile并不能保证操作的原子性，在读取、写入变量的过程中仍然可能被其他线程打断导致意外结果发生。</p>
</blockquote>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[c++ Multithreading programming 学习(2)]]></title>
        <id>https://wangpifu.github.io/post/c-multithreading-programming-xue-xi-2/</id>
        <link href="https://wangpifu.github.io/post/c-multithreading-programming-xue-xi-2/">
        </link>
        <updated>2020-04-29T13:21:15.000Z</updated>
        <content type="html"><![CDATA[<p>继上一篇文章学习了一些基础的api后，这一章我们接着来看pthread所提供的锁,条件变量</p>
<h2 id="mutex-variable互斥锁">Mutex Variable(互斥锁)</h2>
<h3 id="overview">Overview</h3>
<p>Mutex是&quot;mutual exclusion&quot;(互斥)简称.Mutex variable 就像一把锁一样保护共享数据资.mutex的基本概念就是,在任何时候只有一个线程能 lock一个mutex 变量。所以，即使很多线程尝试去锁一个mutex，也仅仅只有一个线程能成功。</p>
<h3 id="创建销毁锁定与释放">创建，销毁，锁定与释放</h3>
<p><code>pthread_mutex_init(pthread_mutex_t * mutex, const phtread_mutexattr_t * mutexattr);</code>//动态方式创建锁，相当于new动态创建一个对象<br>
<code>pthread_mutex_t mutex = PTHREAD_MUTEX_INITIALIZER;</code>//以静态方式创建锁<br>
<code>pthread_mutex_destory(pthread_mutex_t *mutex)</code>//释放互斥锁，相当于delete<br>
<code>pthread_mutex_lock(pthread_mutex_t *mutex)</code><br>
//以阻塞方式运行的。如果之前mutex被加锁了，那么程序会阻塞在这里。<br>
<code>pthread_mutex_unlock(pthread_mutex_t *mutex)</code><br>
<code>int pthread_mutex_trylock(pthread_mutex_t * mutex);</code><br>
// 会尝试对mutex加锁。如果mutex之前已经被锁定，返回非0,；如果mutex没有被锁定，则函数返回并锁定mutex.该函数是以非阻塞方式运行。也就是说如果mutex之前已经被锁定，函数会返回非0，程序继续往下执行。<br>
典型使用mutex的顺序如下：</p>
<ol>
<li>创建和初始化 mutex 变量;</li>
<li>许多线程尝试锁住 mutex;</li>
<li>只有一个线程成功锁住 mutex,其他线程等待;</li>
<li>拥有 mutex 的线程进行自己的操作;</li>
<li>拥有线程解锁 mutex;</li>
<li>其他线程继续获取 mutex 并持续如上步骤;</li>
<li>最后 mutex 销毁.</li>
</ol>
<h3 id="互斥锁属性设置">互斥锁属性设置</h3>
<pre><code class="language-c++">int pthread_mutexattr_init(pthread_mutexattr_t *mattr);
//成功返回0，其它返回值表示出错  
int pthread_mutexattr_destroy(pthread_mutexattr_t *mattr);
//成功返回0，其它返回值表示出错
</code></pre>
<p>互斥锁具有一些属性，通过修改这些属性可以控制锁的一些行为。缺省的互斥锁属性及其值如下：</p>
<ol>
<li>pshared:          PTHREAD_PROCESS_PRIVATE</li>
<li>type:                  PTHREAD_MUTEX_DEFAULT</li>
<li>protocol:           PTHREAD_PRIO_NONE</li>
<li>prioceiling:       –</li>
<li>robustness:    PTHREAD_MUTEX_STALLED_NP<br>
可以用pthread_mutexattr_init将与互斥锁对象相关联的属性初始化为其缺省值。pthread_mutexattr_init的参数类型实际上是opaque的，其中包含一个由系统分配的属性对象。该函数执行过程中会为属性对象分配所需的内存，因而如果未通过pthread_mutexattr_destroy销毁互斥锁属性对象时就会导致内存泄漏。<br>
对于互斥锁属性对象,必须首先通过调用pthread_mutexattr_destroy将其销毁,才能重新初始化该对象。</li>
</ol>
<h4 id="作用域">作用域</h4>
<pre><code class="language-c++">int pthread_mutexattr_setpshared(pthread_mutexattr_t *mattr,int pshared);
//成功返回0，其它返回值表示出错  
int pthread_mutexattr_getpshared(pthread_mutexattr_t *mattr,int *pshared);
//成功返回0，其它返回值表示出错
</code></pre>
<p>函数<code>pthread_mutexattr_setpshared</code>用来设置互斥锁的作用域。互斥锁变量可以是进程专用的变量,也可以是跨越进程边界的变量。<br>
范围属性的取值及其含义：<br>
PTHREAD_PROCESS_SHARED：具有该属性的互斥锁可以在多个进程中的线程之间共享。<br>
PTHREAD_PROCESS_PRIVATE：只有创建本互斥锁的线程所在的进程内的线程才能够使用该互斥锁变量。该值是缺省值。<br>
函数<code>pthread_mutexattr_getpshared</code>可用来返回由<code>pthread_mutexattr_setpshared</code>设置的互斥锁变量的范围。</p>
<h4 id="类型属性">类型属性</h4>
<pre><code class="language-c++">int pthread_mutexattr_settype(pthread_mutexattr_t *attr , int type);
//成功返回0，其它返回值表示出错  
int pthread_mutexattr_gettype(pthread_mutexattr_t *attr , int *type);
//成功返回0，其它返回值表示出错  
</code></pre>
<p>pthread_mutexattr_settype用来设置指定互斥锁的类型属性。类型属性的缺省值为<code>PTHREAD_MUTEX_DEFAULT</code>。<br>
互斥锁的类型及其行为：</p>
<ul>
<li>PTHREAD_MUTEX_NORMAL：不提供死锁检测。如果一个线程试图对一个互斥锁重复锁定，将会引起这个线程的死锁。如果试图解锁一个由别的线程锁定的互斥锁会引发不可预料的结果。如果一个线程试图解锁已经被解锁的互斥锁也会引发不可预料的结果</li>
<li>PTHREAD_MUTEX_ERRORCHECK：提供错误检查。如果一个线程试图对一个互斥锁重复锁定，将会返回一个错误代码。如果试图解锁一个由别的线程锁定的互斥锁将会返回一个错误代码。如果一个线程试图解锁已经被解锁的互斥锁也将会返回一个错误代码</li>
<li>PTHREAD_MUTEX_RECURSIVE：如果一个线程对这种类型的互斥锁重复上锁，不会引起死锁，一个线程对这类互斥锁的多次重复上锁必须由这个线程来重复相同数量的解锁，这样才能解开这个互斥锁，别的线程才能得到这个互斥锁。如果试图解锁一个由别的线程锁定的互斥锁将会返回一个错误代码。如果一个线程试图解锁已经被解锁的互斥锁也将会返回一个错误代码。这种类型的互斥锁只能是进程私有的（作用域属性为PTHREAD_PROCESS_PRIVATE）</li>
<li>PTHREAD_MUTEX_DEFAULT：这种类型的互斥锁不会自动检测死锁。如果一个线程试图对一个互斥锁重复锁定，将会引起不可预料的结果。如果试图解锁一个由别的线程锁定的互斥锁会引发不可预料的结果。如果一个线程试图解锁已经被解锁的互斥锁也会引发不可预料的结果。POSIX标准规定，对于某一具体的实现，可以把这种类型的互斥锁定义为其他类型的互斥锁<br>
在linux中互斥锁的相关类型定义如下（最好的办法是检查pthread.h这个头文件）：</li>
</ul>
<pre><code class="language-c++">  #if defined __USE_UNIX98 || defined __USE_XOPEN2K8
  PTHREAD_MUTEX_NORMAL = PTHREAD_MUTEX_TIMED_NP,
  PTHREAD_MUTEX_RECURSIVE = PTHREAD_MUTEX_RECURSIVE_NP,
  PTHREAD_MUTEX_ERRORCHECK = PTHREAD_MUTEX_ERRORCHECK_NP,
  PTHREAD_MUTEX_DEFAULT = PTHREAD_MUTEX_NORMAL
  #endif
</code></pre>
<p><code>pthread_mutexattr_gettype</code>用来获取由<code>pthread_mutexattr_settype</code>设置的互斥锁的类型属性。</p>
<h4 id="协议属性">协议属性</h4>
<pre><code class="language-c++">int pthread_mutexattr_setprotocol(pthread_mutexattr_t *attr, int protocol);
//成功返回0，其它返回值表示出错  
int pthread_mutexattr_getprotocol(const pthread_mutexattr_t *attr, int *protocol); //成功返回0，其它返回值表示出错   
</code></pre>
<p><code>pthread_mutexattr_setprotocol</code>用来设置互斥锁的协议属性。<br>
互斥锁协议属性的可能值及其含义：</p>
<ul>
<li>PTHREAD_PRIO_NONE：    线程的优先级和调度不会受到互斥锁拥有权的影响.</li>
<li>PTHREAD_PRIO_INHERIT： 此协议值会影响拥有该互斥锁的线程的优先级和调度。如果更高优先级的线程因thread1所拥有的一个或多个互斥锁而被阻塞,而这些互斥锁是用 PTHREAD_PRIO_INHERIT 初始化的,则thread1的运行优先级为优先级pri1和优先级pri2中优先级较高的那一个.(其中 thread1的优先级为pri1,所有正在等待这些互斥锁的线程的最高优先级为pri2.)如果thread1因另一个线程(thread3) 拥有的互斥锁而被阻塞,则相同的优先级继承效应会以递归方式传播给thrd3。<br>
使用PTHREAD_PRIO_INHERIT可以避免优先级逆转。当低优先级的线程持有较高优先级线程所需的锁时,就会发生优先级逆转。此时只有在较低优先级的线程释放该锁之后,较高优先级的线程才能继续执行。如果没有优先级继承，低优先级的线程可能会在很长一段时间内都得不到调度，而这会导致等待低优先级线程锁持有的锁的高优先级线程也等待很长时间（因为低优先级线程无法运行，因而就无法释放锁，所以高优先级线程只能继续阻塞在锁上）。使用优先级继承可以短时间的提高低优先级线程的优先级，从而使它可以尽快得到调度，然后释放锁。低优先级线程在释放锁后就会恢复自己的优先级。</li>
<li>PTHREAD_PRIO_PROTECT：当线程拥有一个或多个使用PTHREAD_PRIO_PROTECT 初始化的互斥锁时,线程的优先级和调度会受到影响。线程将以优先级pri1和优先级pri2中优先级较高的那一个优先级来运行，其中该线程的优先级为pri1，所有该线程持有的锁的最高优先级为pri2，被该线程所持有的锁阻塞的高优先级线程对该线程的调度没有影响。</li>
</ul>
<p><code>PTHREAD_PRIO_INHERIT</code> 和 <code>PTHREAD_PRIO_PROTECT</code> 只有在采用实时调度策略<code>SCHED_FIFO</code> 或 <code>SCHED_RR</code>的优先级进程内可用。（The PTHREAD_PRIO_INHERIT and PTHREAD_PRIO_PROTECT mutex attributes are usable only by privileged processes running in the realtime (RT) scheduling class SCHED_FIFO or SCHED_RR.）<br>
一个线程可以同时拥有多个混合使用 <code>PTHREAD_PRIO_INHERIT</code> 和 <code>PTHREAD_PRIO_PROTECT</code>协议属性初始化的互斥锁。在这种情况下,该线程将以通过其中任一协议获取的最高优先级执行。<br>
pthread_mutexattr_getprotocol可用来获取互斥锁属性对象的协议属性。</p>
<h4 id="优先级上限属性">优先级上限属性</h4>
<pre><code class="language-c++">int pthread_mutexattr_setprioceiling(pthread_mutexatt_t *attr, int prioceiling, int *oldceiling); //成功返回0，其它返回值表示出错  
int pthread_mutexattr_getprioceiling(const pthread_mutexatt_t *attr, int *prioceiling); //成功返回0，其它返回值表示出错
</code></pre>
<p><code>pthread_mutex_setprioceiling</code>可更改互斥锁 mutex 的优先级上限 prioceiling。<br>
<code>pthread_mutex_setprioceiling</code>可锁定互斥锁(如果未锁定的话),或者一直处于阻塞状态,直到它成功锁定该互斥锁,更改该互斥锁的优先级上限并将该互斥锁释放为止。锁定互斥锁的过程无需遵循优先级保护协议。如果 <code>pthread_mutex_setprioceiling</code>成功,则将在 old_ceiling 中返回以前的优先级上限值。如果<code>pthread_mutex_setprioceiling</code>失败,则互斥锁的优先级上限保持不变。<br>
<code>pthread_mutex_getprioceiling</code>会返回 mutex 的优先级上限 prioceiling。</p>
<h4 id="robust-属性">Robust 属性</h4>
<p>TODO: 这个没有在工作中见过，不是特别了解，需要实验</p>
<pre><code class="language-c++">int pthread_mutexattr_setrobust_np(pthread_mutexattr_t *attr, int *robustness);  //成功返回0，其它返回值表示出错 
int pthread_mutexattr_getrobust_np(const pthread_mutexattr_t *attr, int *robustness);  //成功返回0，其它返回值表示出错
</code></pre>
<p><code>pthread_mutexattr_setrobust_np</code>用来设置互斥锁属性对象的强健属性。仅当定义了符号 <code>_POSIX_THREAD_PRIO_INHERIT</code> 时,<code>pthread_mutexattr_setrobust_np()</code>才适用。robustness 定义在互斥锁的持有者“死亡”时的行为。pthread.h 中定义的 robustness 的值为<code>PTHREAD_MUTEX_ROBUST_NP</code> 或 <code>PTHREAD_MUTEX_STALLED_NP</code>。缺省值为<code>PTHREAD_MUTEX_STALLED_NP</code>。</p>
<ul>
<li>PTHREAD_MUTEX_STALLED_NP： 如果互斥锁的持有者死亡,则以后对 pthread_mutex_lock() 的所有调用将以不确定的方式被阻塞。</li>
<li>PTHREAD_MUTEX_ROBUST_NP： 如果互斥锁的持有者“死亡”了，或者持有这样的互斥锁的进程unmap了互斥锁所在的共享内存或者持有这样的互斥锁的进程执行了exec调用，则会解除锁定该互斥锁。互斥锁的下一个持有者将获取该互斥锁,并返回错误 <code>EOWNWERDEAD</code>。如果互斥锁具有<code>PTHREAD_MUTEX_ROBUST_NP</code>的属性，则应用程序在获取该锁时必须检查 <code>pthread_mutex_lock</code> 的返回代码看获取锁时是否返回了<code>EOWNWERDEAD</code>错误。如果是，则互斥锁的新的持有者应使该互斥锁所保护的状态保持一致。因为互斥锁的上一个持有者“死亡”时互斥锁所保护的状态可能出于不一致的状态。如果互斥锁的新的持有者能够使该状态保持一致,请针对该互斥锁调用pthread_mutex_consistent_np(),并解除锁定该互斥锁。如果互斥锁的新的持有者无法使该状态保持一致,请勿针对该互斥锁调用<code>pthread_mutex_consistent_np()</code>,而是解除锁定该互斥锁。所有等待的线程都将被唤醒,以后对 <code>pthread_mutex_lock()</code> 的所有调用都将无法获取该互斥锁。返回错误为<code>ENOTRECOVERABLE</code>。<br>
如果一个线程获取了互斥锁，但是获取时得到了<code>EOWNERDEAD</code>的错误，然后它终止并且没有释放互斥锁 ,则下一个持有者获取该锁时将返回代码<code>EOWNERDEAD</code>。</li>
</ul>
<h3 id="note">Note:</h3>
<ol>
<li>互斥量需要时间来加锁和解锁。锁住较少互斥量的程序通常运行得更快。所以，互斥量应该尽量少，够用即可，每个互斥量保护的区域应则尽量大。</li>
<li>互斥量的本质是串行执行。如果很多线程需要领繁地加锁同一个互斥量，则线程的大部分时间就会在等待，这对性能是有害的。如果互斥量保护的数据(或代码)包含彼此无关的片段，则可以特大的互斥量分解为几个小的互斥量来提高性能。这样，任意时刻需要小互斥量的线程减少，线程等待时间就会减少。所以，互斥量应该足够多(到有意义的地步)，每个互斥量保护的区域则应尽量的少。</li>
</ol>
<h3 id="example">Example</h3>
<pre><code class="language-c++">#include &lt;pthread.h&gt;
#include &lt;cstdio&gt;
#include &lt;cstdlib&gt;

struct ThreadData {
  int tid;
  int data;
};

int shared_x;
pthread_mutex_t lock;

void *ThreadProc(void *param) {
  ThreadData *data = static_cast&lt;ThreadData *&gt;(param);
  printf(&quot;begin from thread id: %d\n&quot;, data-&gt;tid);
  pthread_mutex_lock(&amp;lock);
  shared_x += data-&gt;data;
  printf(&quot;thread %d: x = %d\n&quot;, data-&gt;tid, shared_x);
  pthread_mutex_unlock(&amp;lock);
  pthread_exit(NULL);
}

int main(int argc, char *argv[]) {
  const int kNumThreads = 4;
  pthread_t threads[kNumThreads];
  ThreadData threads_data[kNumThreads];
  pthread_attr_t attr;

  shared_x = 0;
  pthread_mutex_init(&amp;lock, NULL);
  pthread_attr_init(&amp;attr);
  pthread_attr_setdetachstate(&amp;attr, PTHREAD_CREATE_JOINABLE);
  for (int i = 0; i &lt; kNumThreads; ++i) {
    threads_data[i].tid = i;
    threads_data[i].data = i * i;
    int rt = pthread_create(&amp;threads[i], &amp;attr, ThreadProc,
                            static_cast&lt;void *&gt;(&amp;threads_data[i]));
    if (rt) {
      printf(&quot;ERROR: pthread_create failed, rt=%d\n&quot;, rt);
      exit(1);
    }
  }
  for (int i = 0; i &lt; kNumThreads; ++i) {
    void *status;
    pthread_join(threads[i], &amp;status);
  }
  pthread_attr_destroy(&amp;attr);
  pthread_exit(NULL);
  return 0;
}
</code></pre>
<h2 id="condition-variables条件变量">Condition Variables(条件变量)</h2>
<h3 id="overview-2">Overview</h3>
<p>Mutex 变量如锁一般防止多个线程访问共享数据资源,如果某个线程等待某个共享数据达到某个数值才进行相应的操作,那么这个线程需要不断的去 poll,查看是否满足需要的值,这样开销很大,因为线程需要一直处于忙状态.<br>
引入 Condition Variables 来完成这样的同步到某个实际数据值而不要不断 poll.<br>
Condition 变量一般与 mutex 一起使用.锁住查看的共享数据资源.<br>
使用 Condition 的一般步骤如下:</p>
<ul>
<li>声明和定义需要同步的共享数据;</li>
<li>声明和定义 condition 变量;</li>
<li>声明和定义相对应的 mutex;</li>
<li>创建线程使用 condition 变量同步.</li>
</ul>
<h3 id="条件变量创建与销毁">条件变量创建与销毁</h3>
<pre><code class="language-c++">int pthread_cond_destroy(pthread_cond_t *cond);
int pthread_cond_init(pthread_cond_t *restrict cond,
                      const pthread_condattr_t *restrict attr);
int pthread_condattr_destroy(pthread_condattr_t *attr);
int pthread_condattr_init(pthread_condattr_t *attr);
</code></pre>
<p>Condition 变量由 pthread_cond_t 声明定义,而且必须初始化在使用前.两种方法初始:<br>
静态的,当声明时.如:<br>
<code>pthread_cond_t convar = PTHREAD_COND_INITIALIZER;</code><br>
动态的, 使用 pthread_cond_init() 函数,并能设置 condition 的属性 attr.</p>
<pre><code class="language-c++">pthread_cond_t cond;
pthread_cond_init(&amp; cond, nullptr);
</code></pre>
<p>attr 用来设置 condition 变量的属性,必须是 <code>pthread_condattr_</code>t 类型.只有一种属性可选:是否进程共享,也就是允许其他进程中的线程也能看到它.</p>
<pre><code class="language-c++">pthread_condattr_t  cattr;
int ret;
/* initialize an attribute to default value */
ret = pthread_condattr_init(&amp;cattr); 
/* all processes */
ret = pthread_condattr_setpshared(&amp;cattr, PTHREAD_PROCESS_SHARED);
/* within a process */
ret = pthread_condattr_setpshared(&amp;cattr, PTHREAD_PROCESS_PRIVATE);
</code></pre>
<p>cattr is an opaque data type that contains a system-allocated attribute object. The possible values of cattr's scope are PTHREAD_PROCESS_PRIVATE (the default) and PTHREAD_PROCESS_SHARED.</p>
<h3 id="条件变量等待与信号">条件变量等待与信号</h3>
<pre><code class="language-c++">int pthread_cond_wait(pthread_cond_t *cond,
                      pthread_mutex_t *mutex);
int pthread_cond_signal(pthread_cond_t *cond);
int pthread_cond_broadcast(pthread_cond_t *cond);
</code></pre>
<p><code>pthread_cond_wait()</code> 阻塞调用它的线程直到其中 cond 被 signal.这个函数需要在占有 mutex 时被调用,而当等待时它将自动释放 mutex.等到 signal 收到,线程被唤醒, mutex 将自动被占有 .最后当线程完成 condition 的操作,要负责对 mutex 解锁.<br>
<code>pthread_cond_signal()</code> 用来 signal 其他等待这个 cond 的线程.它需要在占有 mutex 时被调用.然后必须对 mutex 解锁来完成 <code>pthread_cond_wait</code> 的等待.<br>
如果有多于一个线程处于等待 cond 而阻塞, 应该用 <code>pthread_cond_broadcast()</code> 替换 pthread_cond_signal().</p>
<h3 id="example-2">Example</h3>
<pre><code class="language-c++">#include &lt;pthread.h&gt;
#include &lt;cstdio&gt;
#include &lt;cstdlib&gt;
#include &lt;unistd.h&gt;

const int kNumThreads = 3;
const int kLoops = 10;
const int kCountLimit = 15;

int g_count;
pthread_mutex_t count_mutex;
pthread_cond_t count_cv;

void *IncreaseCount(void *param) {
  int id;
  id = *(static_cast&lt;int *&gt;(param));
  for (int i = 0; i &lt; kLoops; ++i) {
    pthread_mutex_lock(&amp;count_mutex);
    g_count++;
    if (g_count == kCountLimit) {
      pthread_cond_signal(&amp;count_cv);
      printf(&quot;increse thread %d: count = %d, signal cond\n&quot;, id, g_count);
    }
    printf(&quot;increse thread %d: count = %d, unlock mutex\n&quot;, id, g_count);
    pthread_mutex_unlock(&amp;count_mutex);
    sleep(1);
  }
  pthread_exit(NULL);
}

void *WatchCount(void *param) {
  int id;
  id = *(static_cast&lt;int *&gt;(param));
  pthread_mutex_lock(&amp;count_mutex);
  while (g_count &lt; kCountLimit) {
    pthread_cond_wait(&amp;count_cv, &amp;count_mutex);
    printf(&quot;watch thread %d: count = %d, receive signal\n&quot;, id, g_count);
  }
  pthread_mutex_unlock(&amp;count_mutex);
  pthread_exit(NULL);
}

int main(int argc, char *argv[]) {
  pthread_t threads[kNumThreads];
  int thread_ids[kNumThreads];
  pthread_attr_t attr;

  pthread_mutex_init(&amp;count_mutex, NULL);
  pthread_cond_init(&amp;count_cv, NULL);
  pthread_attr_init(&amp;attr);
  pthread_attr_setdetachstate(&amp;attr, PTHREAD_CREATE_JOINABLE);
  for (int i = 0; i &lt; kNumThreads; ++i) {
    thread_ids[i] = i;
  }
  int rt;
  rt = pthread_create(&amp;threads[0], &amp;attr, WatchCount,
                            static_cast&lt;void *&gt;(&amp;thread_ids[0]));
  if (rt) {
    printf(&quot;ERROR: pthread_create failed, rt=%d\n&quot;, rt);
    exit(1);
  }
  rt = pthread_create(&amp;threads[1], &amp;attr, IncreaseCount,
                            static_cast&lt;void *&gt;(&amp;thread_ids[1]));
  if (rt) {
    printf(&quot;ERROR: pthread_create failed, rt=%d\n&quot;, rt);
    exit(1);
  }
  rt = pthread_create(&amp;threads[2], &amp;attr, IncreaseCount,
                            static_cast&lt;void *&gt;(&amp;thread_ids[2]));
  if (rt) {
    printf(&quot;ERROR: pthread_create failed, rt=%d\n&quot;, rt);
    exit(1);
  }
  for (int i = 0; i &lt; kNumThreads; ++i) {
    pthread_join(threads[i], NULL);
  }
  pthread_attr_destroy(&amp;attr);
  pthread_cond_destroy(&amp;count_cv);
  pthread_mutex_destroy(&amp;count_mutex);
  pthread_exit(NULL);
}
</code></pre>
<h2 id="semaphore">Semaphore</h2>
<h3 id="overview-3">OverView</h3>
<p>信号量本质上是一个非负的整数计数器，它被用来控制对公共资源的访问，也被称为PV原子操作。PV原子操作，广泛用于进程或线程之间的通信的同步和互斥。其中，P是通过的意思，V是释放的意思，不可中断的过程，则由操作系统来保证P操作和V操作。PV操作时针对信号量的操作，就是对信号量进行加减的过程。P操作，即信号量sem减一的过程，如果sem小于等于0，P操作被堵塞，直到sem变量大于0为止。P操作即加锁过程。V操作，即信号量sem加一的过程。V操作即解锁过程。</p>
<h3 id="api">API</h3>
<pre><code class="language-c++">int sem_init(sem_t *sem, int pshared, unsigned int value);
int sem_wait(sem_t *sem);  // P操作，减少信号量
int sem_post(sem_t *sem);  //V操作， 增加信号量
int sem_destory(sem_t *sem);  //销毁信号量
int sem_getvalue(sem_t *sem, int *sval);  // 获取信号量的值
</code></pre>
<p><code>sem_init</code> 函数说明：sem参数是信号量指针；pshared参数为共享方式，0表示信号量只是在当前进程中使用（线程），1表示信号量在多进程中使用；value参数表示信号量的初始值，一般为1。</p>
<h2 id="barrier">Barrier</h2>
<h3 id="overview-4">Overview</h3>
<p>Barrier 就是栅栏一样,调用等待 barrier 的线程需要等待直到满足调用 barrier 的线程个数达到要求的 count.</p>
<h3 id="api-2">API</h3>
<pre><code class="language-c++">int pthread_barrier_init(pthread_barrier_t *barrier,
                const pthread_barrierattr_t *attr, unsigned count);
pthread_barrier_t barrier = PTHREAD_BARRIER_INITIALIZER(count);
int pthread_barrier_destroy(pthread_barrier_t *barrier);
int pthread_barrierattr_init(pthread_barrierattr_t *attr);
int pthread_barrierattr_destroy(pthread_barrierattr_t *attr);
int pthread_barrier_wait(pthread_barrier_t *barrier);
</code></pre>
<p>The <code>pthread_barrier_wait()</code> function shall synchronize participating threads at the barrier referenced by barrier. The calling thread shall block until the required number of threads have called <code>pthread_barrier_wait()</code> specifying the barrier.<br>
Barrier 变量由 <code>pthread_barrier_</code>t 声明定义,而且必须初始化在使用前.需要传入满足 barrier 等待的个数 count, 两种方法初始:<br>
静态的,当声明时.如:<br>
<code>pthread_barrier_t barrier = PTHREAD_BARRIER_INITIALIZER(count);</code><br>
动态的,使用 <code>pthread_barrier_init()</code> 函数,并能设置 barrier 的属性 attr.<br>
线程调用 barrier,只需要调用 <code>pthread_barrier_wait</code> 来等待 barrier 达到满足条件.</p>
<h3 id="example-3">Example</h3>
<pre><code class="language-c++">#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;
#include &lt;unistd.h&gt;
#include &lt;pthread.h&gt;
#include &lt;time.h&gt;

#define THREAD_COUNT 4

pthread_barrier_t mybarrier;

void* threadFn(void *id_ptr) {
  int thread_id = *(int*)id_ptr;
  int wait_sec = 1 + rand() % 5;
  printf(&quot;thread %d: Wait for %d seconds.\n&quot;, thread_id, wait_sec);
  sleep(wait_sec);
  printf(&quot;thread %d: I'm ready...\n&quot;, thread_id);

  pthread_barrier_wait(&amp;mybarrier);

  printf(&quot;thread %d: going!\n&quot;, thread_id);
  return NULL;
}


int main() {
  int i;
  pthread_t ids[THREAD_COUNT];
  int short_ids[THREAD_COUNT];

  srand(time(NULL));
  pthread_barrier_init(&amp;mybarrier, NULL, THREAD_COUNT + 1);

  for (i=0; i &lt; THREAD_COUNT; i++) {
    short_ids[i] = i;
    pthread_create(&amp;ids[i], NULL, threadFn, &amp;short_ids[i]);
  }

  printf(&quot;main() is ready.\n&quot;);

  pthread_barrier_wait(&amp;mybarrier);

  printf(&quot;main() is going!\n&quot;);

  for (i=0; i &lt; THREAD_COUNT; i++) {
    pthread_join(ids[i], NULL);
  }

  pthread_barrier_destroy(&amp;mybarrier);

  return 0;
}
</code></pre>
<h3 id="reference">Reference:</h3>
<p><a href="http://dreamrunner.org/blog/2014/08/07/C-multithreading-programming/">浅谈C++ Multithreading Programming</a><br>
<a href="https://www.freebsd.org/cgi/man.cgi?query=pthread&amp;apropos=0&amp;sektion=3&amp;manpath=FreeBSD+8.0-RELEASE&amp;format=html">freebsd pthreads manual page</a></p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[cpu affinity 亲和性]]></title>
        <id>https://wangpifu.github.io/post/cpu-affinity-qin-he-xing/</id>
        <link href="https://wangpifu.github.io/post/cpu-affinity-qin-he-xing/">
        </link>
        <updated>2020-04-29T12:49:24.000Z</updated>
        <content type="html"><![CDATA[<h2 id="cpu-affinity">CPU Affinity</h2>
<p>cpu affinity 就是让某个进程/线程绑定在某个cpu(core)上，使其尽量长时间的运行而不被迁移到其他core上的倾向性。 Linux kernel提供了两个api来修改或查看某个进程/线程的亲和性：<br>
<code>int sched_setaffinity(pid_t pid, size_t cpusetsize, cpu_set_t *mask);</code><br>
<code>int sched_getaffinity(pid_t pid, size_t cpusetsize, cpu_set_t *mask);</code><br>
如果pid是0，那么默认是当前thread。<br>
cpu_set_t 是一个掩码数组，共1024位，每一位对应一个core，以下宏是对这个掩码进行操作的：</p>
<pre><code>void CPU_ZERO (cpu_set_t *set)
这个宏对 CPU 集 set 进行初始化，将其设置为空集。
void CPU_SET (int cpu, cpu_set_t *set)
这个宏将 cpu 加入 CPU 集 set 中。
void CPU_CLR (int cpu, cpu_set_t *set)
这个宏将 cpu 从 CPU 集 set 中删除。
int CPU_ISSET (int cpu, const cpu_set_t *set)
如果 cpu 是 CPU 集 set 的一员，这个宏就返回一个非零值（true），否则就返回零（false）。
</code></pre>
<p>我看到很多人说对于thread我们用pthread_setaffinity_np， 对于process我们才用sched_setafinity.于是我仔细的看了一下。首先，sched_setaffinity的man page上写的是</p>
<blockquote>
<p>A thread's CPU affinity mask determines the set of CPUs on which it is eligible to run</p>
</blockquote>
<p>当然它也写了</p>
<blockquote>
<p>(If you are using the POSIX threads API, then use pthread_setaffinity_np(3) instead of sched_setaffinity().)</p>
</blockquote>
<p>当我们使用</p>
<pre><code>int pthread_setaffinity_np(pthread_t thread, size_t cpusetsize, const cpu_set_t *cpuset);
int pthread_getaffinity_np(pthread_t thread, size_t cpusetsize, cpu_set_t *cpuset);
</code></pre>
<p>我们传入的是pthread_t. 而当我们使用<code>sched_setaffinity</code>时，我们传进去的可以是pid from <code>getpid()</code>,也可以是tid from <code>gettid()</code>.（对于单线程的进程，pid等于tid，对于多线程的进程，每个线程有不同的tid，但会有相同的pid。）pid_t 和pthread_t是不同的，pthread_t是同一个进程中各个线程之间的标识号，对于这个进程内是唯一的，而不同进程中，每个线程返回的pthread_t可能是一样的。而gettid是用来系统内各个线程间的标识符，由于linux采用轻量级进程实现的，它其实返回的应该是pid号。 还有需要注意的就是当你给一个线程设置了亲和性然后pthread_create 其他线程，其他线程会继承当前这个线程的亲和性。不过在我的工作范围内，sched_setaffinity 已经足够，因为线程的创建是固定的，我们也需要在创建后设置亲和性，所以不必担心亲和性的继承问题。</p>
<p>BTW: gettid() is not implemented in glibc, 所以我们需要用syscall去获取tid</p>
<pre><code class="language-c">pid_t getThreadId()
{
    return syscall(__NR_gettid);
}
</code></pre>
<h2 id="hyperthreading-numa">Hyperthreading &amp; NUMA</h2>
<p>现代cpu会有多个core，每个core可能会支持两个线程。可以通过<code>lscpu</code> 或者<code>lstopo</code> 查看。比如这张网上的图片。<br>
<img src="https://wangpifu.github.io/post-images/1588961186982.png" alt="" loading="lazy"><br>
在一些强大的工作站上会有不止一个scoket，比如我工作的机器有两个sockets，每个socket有8个core。如果hyperthreading(HT) enabled,那就将有32个hardware thread. 他们处在不同的numa（非统一内存访问架构）下，即某些cpu之间松散连接着甚至不共享memory and bus。那么hardware thread共享什么呢，有怎么关系到我们的程序呢？看上图，每个core内的两个threads会共享L1 和 L2 cache，同一个socket下的所有核会共享L3。 对于multi-socket机器，通常来讲每个socket有自己L3cache。对于NUMA，每个processor会访问自己的DRAM,不同processor之间通过一些通信机制来互相访问（QPI?）. 可以看到HT仅仅是在物理核心上使用了两个物理任务描述符，却没有增加实际的物理计算能力。 他的好处在于如果两个程序被调度到了同一个core，他们可以共享cache和TLB来降低任务切换开销。但是如果两个程序需要抢夺物理执行资源，那么反而会增加延时。对于低延迟交易来讲，我认为disable这个更好，因为它会损害性能增高延迟。但是对于互联网来讲，这个可以提高吞吐量，所以在互联网业务中，可以依据具体业务决定是否enable。对于不同numa来说，他们访问彼此的cache要明显该与访问自己的cache， 可以通过命令<code>numactl -H</code>查看，这给我们的启发是尽量让相关的任务处在同一个numa node下。</p>
<h3 id="查看cpu信息">查看cpu信息</h3>
<p>查看处理器核数：<code>cat /proc/cpuinfo | grep &quot;cpu cores&quot; | uniq</code> 即每个物理处理器的core的个数，例如Intel(R) Xeon(R) CPU E5-2690 @2.90GHz在每个socket上有8 cores<br>
查看逻辑处理器核数 ：<code>cat /proc/cpuinfo</code>， 如果siblings和cpu cores一致，则不支持超线程<br>
查看物理处理器封装id：<code>cat /proc/cpuinfo | grep &quot;physical id&quot; | sort | uniq | wc -l</code> 例如Intel(R) Xeon(R) CPU E5-2690 @2.90GHz 有两个&quot;物理处理器封装&quot;<br>
查看逻辑处理器ID: <code>cat /proc/cpuinfo | grep &quot;processor&quot; | wc -l</code> 例如Intel(R) Xeon(R) CPU E5-2690 @2.90GHz 没有开超线程，他有两个物理处理器封装。每个封装有8个core，则一共含有16个core/逻辑处理器（如果开了HT就是32）.其id从0 -15.</p>
<h2 id="线程独占">线程独占</h2>
<p>即使将线程绑定到了某个core，系统依然可能将其他任务调度到这个核，为了进一步减少其他任务对这个线程的影响，我们可以将这个core从内核调度系统中剥离。<br>
在 <code>/boot/grub2.cfg</code>中输入<code>isolcpu=11,12</code>或者你想剥离的cpu id，这样系统启动后将不会使用这两个core， 当然，通过taskset我们还是可以指定一些程序在这些核运行。<br>
或者换个思路，我们将init.d限制在core 0， 这样由它产生的所有进程都会运行在这个core上，而对于一些特定的进程，我们可以指定他们到其他core上。我们可以<code>default_affinity=0</code>或者<code>init=/usr/bin/numactl -m 0 -c 0 /sbin/init</code>。后者比前者好因为它同时绑定了core 0 并设置了numa policy 表明更偏爱node 0 的memory allocation。<code>taskset -pc 1</code>来看我们确实设置成功。需要注意如果一个进程有RT优先级的话会锁住，所以对于这样的进程要在其他核运行。</p>
<h2 id="reference">Reference</h2>
<p>https://zhuanlan.zhihu.com/p/33324549<br>
https://zhuanlan.zhihu.com/p/33621500<br>
https://eli.thegreenplace.net/2016/c11-threads-affinity-and-hyperthreading/</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[c++ Multithreading programming 学习(1)]]></title>
        <id>https://wangpifu.github.io/post/c-multithreading-programming-xue-xi-1/</id>
        <link href="https://wangpifu.github.io/post/c-multithreading-programming-xue-xi-1/">
        </link>
        <updated>2020-04-29T11:17:05.000Z</updated>
        <content type="html"><![CDATA[<h1 id="thread-overview">Thread Overview</h1>
<p><img src="https://wangpifu.github.io/post-images/1588203959444.png" alt="" loading="lazy"><br>
Thread 是一段独立于其他代码的，由操作系统调度的指令。它能使用process的资源，但是可以独立的被OS调用。 它像是轻量级的process，但是创建比process快。 同时thread可以直接与同一process下其他thread通信。 而process之间用到PIPE,FIFO来发送短小高频的消息，适用于两个process之间。或者用共享内存以及socket来通信。</p>
<h2 id="pthread">Pthread</h2>
<h3 id="overview">Overview</h3>
<p>在c++11以前，c++没有很好的thread库支持，一般是通过系统的thread库来实现线程相关代码。Pthread即源于posix系统。代码基于c，对于其他操作系统不具有移植性。</p>
<h3 id="使用pthread">使用pthread</h3>
<p>对于posix系统，需要包含头文件<code>#include &lt;pthread.h&gt;</code> ，如果需要使用<code>semaphre</code>, 则需要<code>#include &lt;semaphore.h&gt;</code>。 在编译时，需要<code>g++ test.cpp -lpthread</code> 或者在cmake中定义<code>find_package(Threads REQUIRED)</code>。</p>
<h3 id="thread-creation">Thread Creation</h3>
<h4 id="api">API</h4>
<pre><code>int pthread_create(pthread_t *thread,
              const pthread_attr_t *attr,
              void *(*start_routine)(void*), void *arg);
void pthread_exit(void *value_ptr);
int pthread_cancel(pthread_t thread);
int pthread_attr_init(pthread_attr_t *attr);
int pthread_attr_destroy(pthread_attr_t *attr);
</code></pre>
<p><code>pthread_create</code> 创建一个新的线程并运行它.它能在代码的任何处被多次调用.<br>
<code>pthread_create</code> 的参数:<br>
<code>thread</code>:返回新 thread 的唯一标识.<br>
<code>attr</code>:设置 thread 的性质.NULL 为默认性质.<br>
<code>start_routine</code>: 新 thread 运行的函数指针.<br>
<code>arg</code>:传给 start_routine 的参数,必须强制转换成 void *.NULL 为没有参数传入.</p>
<h4 id="thread-attributes">Thread Attributes</h4>
<p><code>pthread_attr_init</code> 和 <code>pthread_attr_destroy</code> 被用来初始化/销毁 thread 性质对象. 如 detached or joinable state, scheduling policy.</p>
<h4 id="thread-binding">Thread Binding</h4>
<p>参见这篇文章<a href="https://wangpifu.github.io/post/cpu-affinity-qin-he-xing">cpu 亲和性</a></p>
<h3 id="thread-termination">Thread Termination</h3>
<p>Thread 有多种终止方式：</p>
<ul>
<li>线程从它的运行中正常放回.它的工作完成.</li>
<li>线程调用 <code>pthread_exit</code> 无论它的工作完成否.</li>
<li>线程被另外一个线程调用<code>pthread_cance</code>来取消.</li>
<li>整个<strong>进程</strong>都终止，如果任何线程调用了 <code>exec()</code> 或 <code>exit()</code>.</li>
<li><code>main()</code> 函数先完成,没有调用 <code>pthread_exit</code>.</li>
</ul>
<p><code>void pthread_exit(void * rval_ptr);</code><br>
函数说明：rval_ptr参数是线程结束时的返回值，可由其他函数如pthread_join()来获取。这个调用不关闭文件,在线程打开的任何文件在线程终止后将继续打开.</p>
<ul>
<li>如果 <code>main()</code>在它创建的 threads 之前终止,并没有显式的调用 pthread_exit(),所有创建的线程都将终止，因为<code>main()</code>结束,不再存在支持这些线程.</li>
<li>通过<code>main()</code>在最后调用 <code>pthread_exit()</code>, <code>main()</code>将阻塞并保持存活来支持它创建的线程运行直到它们完成.</li>
</ul>
<p><code>int pthread_cancel(pthread_t thread);</code><br>
函数说明：取消线程，该函数在其他线程中调用，用来强行杀死指定的线程。<br>
我从来没用过这个函数，似乎使用情况有些tricky，参见这篇<a href="https://blog.csdn.net/fozhishuiyue/article/details/98936578">博客</a>。另外我自己写了个程序试验了一下但是一直有segment fault TODO: 查明原因，深入理解一下。</p>
<h4 id="example-of-pthread-creationand-termination">Example of pthread creationand termination</h4>
<p>如果注释掉 <code>main()</code>中最后的 <code>pthread_exit(NULL);</code> ,那么它创建的线程将会完成不了所有的打印而被强制退出.</p>
<pre><code class="language-c++">#include &lt;pthread.h&gt;
#include &lt;cstdio&gt;
#include &lt;cstdlib&gt;

void *ThreadProc(void *param) {
  int id;
  id = *(static_cast&lt;int *&gt;(param));
  for (int i = 0; i &lt; 10; ++i) {
    if(id == 1 &amp;&amp; i == 8)
    { 
        // for pthread_t 1, it will only print to 7 and then terminate.
        pthread_exit(NULL);
    }
    printf(&quot;thread %d: run %d \n&quot;, id, i);
  }
  pthread_exit(NULL);
}

int main(int argc, char *argv[]) {
  const int kNumThreads = 4;
  pthread_t threads[kNumThreads];
  int thread_ids[kNumThreads];
  for (int i = 0; i &lt; kNumThreads; ++i) {
    thread_ids[i] = i;
    int rt = pthread_create(&amp;threads[i], NULL, ThreadProc,
                            static_cast&lt;void *&gt;(&amp;thread_ids[i]));
    if (rt) {
      printf(&quot;ERROR: pthread_create failed, rt=%d\n&quot;, rt);
      exit(1);
    }
  }
  pthread_exit(NULL);
}
</code></pre>
<h3 id="threads-joining-and-detaching">Threads joining and detaching</h3>
<h4 id="api-2">API</h4>
<pre><code class="language-c++">int pthread_join(pthread_t thread, void **value_ptr);
int pthread_detach(pthread_t thread);
int pthread_attr_setdetachstate(pthread_attr_t *attr, int detachstate);
int pthread_attr_getdetachstate(const pthread_attr_t *attr, int *detachstate);
//PTHREAD_CREATE_DETACHED 分离
//PTHREAD_CREATE_JOINABLE 不分离
</code></pre>
<h4 id="joining">Joining</h4>
<p><img src="https://wangpifu.github.io/post-images/1588262396632.png" alt="" loading="lazy"><br>
joining 是用来同步不同线程的方法之一</p>
<ul>
<li><code>int pthread_join(pthread_t thread, void **value_ptr);</code> 将阻塞调用它的线程直到被指定的thread线程终止。</li>
<li>调用的线程能获取目标线程终止返回的 status 如果目标线程调用 <code>pthread_exit()</code></li>
<li>当一个线程被创建,它的属性之一是它是否可以 join.只有创建的能被 join 的线程才能被 join.如果线程线程以 detached 创建,它永远都不能被 join。</li>
</ul>
<h4 id="detaching">Detaching</h4>
<ul>
<li>pthread_detach() 可以将一个线程detach，即使它原先是以join位attribute建立的</li>
</ul>
<h4 id="example">Example</h4>
<pre><code class="language-c++">#include &lt;pthread.h&gt;
#include &lt;cstdio&gt;
#include &lt;cstdlib&gt;

void *ThreadProc(void *param) {
  int id;
  id = *(static_cast&lt;int *&gt;(param));
  for (int i = 0; i &lt; 10; ++i) {
    printf(&quot;thread %d: run %d \n&quot;, id, i);
  }
  pthread_exit(param);
}

int main(int argc, char *argv[]) {
  const int kNumThreads = 4;
  pthread_t threads[kNumThreads];
  int thread_ids[kNumThreads];
  pthread_attr_t attr;

  pthread_attr_init(&amp;attr);
  pthread_attr_setdetachstate(&amp;attr, PTHREAD_CREATE_JOINABLE);

  for (int i = 0; i &lt; kNumThreads; ++i) {
    thread_ids[i] = i;
    int rt = pthread_create(&amp;threads[i], &amp;attr, ThreadProc,
                            static_cast&lt;void *&gt;(&amp;thread_ids[i]));
    if (rt) {
      printf(&quot;ERROR: pthread_create failed, rt=%d\n&quot;, rt);
      exit(1);
    }
  }
  for (int i = 0; i &lt; kNumThreads; ++i) {
    void *status;
    int rt = pthread_join(threads[i], &amp;status);
    if (rt) {
      printf(&quot;ERROR: pthread_join failed, rt=%d\n&quot;, rt);
      exit(1);
    }
    printf(&quot;completed join with thread %d having a status of %d\n&quot;
           , i, *static_cast&lt;int *&gt;(status));
  }
  pthread_exit(NULL);
}
</code></pre>
<h3 id="stack-management">Stack Management</h3>
<h4 id="api-3">API</h4>
<pre><code>int pthread_attr_getstacksize(const pthread_attr_t *restrict attr,
              size_t *restrict stacksize);
int pthread_attr_setstacksize(pthread_attr_t *attr, size_t stacksize);
int pthread_attr_getstackaddr(const pthread_attr_t *restrict attr,
              void **restrict stackaddr); // removed in POSIX.1-2008
int pthread_attr_setstackaddr(pthread_attr_t *attr, void *stackaddr); 
int pthread_attr_setstack(pthread_attr_t *attr, void *stackaddr, size_t stacksize);
int pthread_attr_getstack(const pthread_attr_t *attr,  void **stackaddr, size_t *stacksize);
int pthread_attr_setguardsize(pthread_attr_t *attr, size_t guardsize);
//功能：设置线程属性中栈尾的警戒区大小
int pthread_attr_getguardsize(pthread_attr_t *attr, size_t *guardsize);
//功能：获取线程属性中栈尾的警戒区大小
</code></pre>
<p>每个线程都有各自独立的 stack, <code>pthread_attr_getstackaddr</code> 和 <code>pthread_attr_setstackaddr</code> 分别获取和设置线程的栈底地址. 在POSIX.1-2008被删除，需要使用新的api <code>pthread_attr_setstack</code>, <code>pthread_attr_getstack</code>.<code>get/setstacksize()</code>获取和设置stack的栈空间字节数。我们通过attr在<code>pthread_create()</code>传入</p>
<h4 id="example-2">example</h4>
<pre><code class="language-c++">#include &lt;pthread.h&gt;
#include &lt;cstdio&gt;
#include &lt;cstdlib&gt;

pthread_attr_t attr;

void *ThreadProc(void *param) {
  int id;
  size_t thread_stack_size;
  id = *(static_cast&lt;int *&gt;(param));
  pthread_attr_getstacksize(&amp;attr, &amp;thread_stack_size);
  printf(&quot;thread %d: stack size = %d\n&quot;, id, thread_stack_size);
  for (int i = 0; i &lt; 10; ++i) {
    printf(&quot;thread %d: run %d \n&quot;, id, i);
  }
  pthread_exit(NULL);
}

int main(int argc, char *argv[]) {
  const int kNumThreads = 4;
  const int kThround = 1000;
  pthread_t threads[kNumThreads];
  int thread_ids[kNumThreads];
  size_t stack_size;

  pthread_attr_init(&amp;attr);
  pthread_attr_getstacksize(&amp;attr, &amp;stack_size);
  printf(&quot;Default stack size = %d\n&quot;, stack_size);
  stack_size = sizeof(double) * kThround * kThround;
  printf(&quot;Setting stack size = %d\n&quot;, stack_size);
  pthread_attr_setstacksize(&amp;attr, stack_size);
  for (int i = 0; i &lt; kNumThreads; ++i) {
    thread_ids[i] = i;
    int rt = pthread_create(&amp;threads[i], &amp;attr, ThreadProc,
                            static_cast&lt;void *&gt;(&amp;thread_ids[i]));
    if (rt) {
      printf(&quot;ERROR: pthread_create failed, rt=%d\n&quot;, rt);
      exit(1);
    }
  }
  pthread_exit(NULL);
  pthread_attr_destroy(&amp;attr);
  return 0;
}
</code></pre>
<h3 id="thread-attribute上文中未提到的">Thread Attribute(上文中未提到的)</h3>
<h4 id="api-4">API</h4>
<pre><code>typedef union
{
char __size[__SIZEOF_PTHREAD_ATTR_T];
long int __align;
}pthread_attr_t;

int pthread_attr_setscope(pthread_attr_t *attr, int scope);
//功能：设置线程属性中线程的竞争范围
//PTHREAD_SCOPE_SYSTEM(绑定)
//PTHREAD_SCOPE_PROCESS(非绑定)
int pthread_attr_getscope(pthread_attr_t *attr, int *scope);
//功能：获取线程属性中线程的竞争范围
</code></pre>
<p>关于绑定属性，涉及到另外一个概念：轻进程（Light Weight Process，LWP）。轻进程可以理解为内核进程，它位于用户层和内核层之间。系统对线程资源的分配和对线程的控制时通过轻进程来实现的，一个轻进程可以控制一个或多个线程。默认情况下，启动多少轻进程、哪些轻进程来控制哪些线程是由系统来控制的，这种状况即称为非绑定。绑定状况下，则顾名思义，即某个线程固定地绑在一个轻进程之上。被绑定的线程具有较高的响应速度，这是因为CPU时间片的调度是面向轻进程的，绑定的线程可以保证在需要的时候它总有一个轻进程可用。通过设置被绑定的轻进程的优先级和调度级可以使得绑定的线程满足诸如实时反应之类的要求。</p>
<pre><code>int pthread_attr_setinheritsched(pthread_attr_t *attr, int inheritsched);
//功能：设置线程属性中线程的调度策略来源
//PTHREAD_INHERIT_SCHED 继承创建者
//PTHREAD_EXPLICIT_SCHED 单独设置
int pthread_attr_getinheritsched(pthread_attr_t *attr, int *inheritsched);

int pthread_attr_setschedpolicy(pthread_attr_t *attr, int policy);
//功能：设置线程属性中线程的调度策略
//SCHED_FIFO 先进先出策略
//SCHED_RR 轮转策略
//SCHED_OTHER 缺省
int pthread_attr_getschedpolicy(pthread_attr_t *attr, int *policy);
//功能：获取线程属性中线程的调度策略

struct sched_param {
int sched_priority;
}；
int pthread_attr_setschedparam(pthread_attr_t *attr, const struct sched_param *param);
//功能：设置线程属性中线程的调度参数（优先级别）
//param：最高级别0
int pthread_attr_getschedparam(pthread_attr_t *attr, struct sched_param *param);
</code></pre>
<p>使用方法：</p>
<ol>
<li>定义线程属性结构体 pthread_attr_t attr;</li>
<li>初始化线程属性结构体 pthread_attr_init(&amp;attr);</li>
<li>使用pthread_attr_set系列函数对结构体变量进行设置。</li>
<li>在创建线程时（pthread_create函数的第二个参数）中使用线程属性结构变量创建线程。</li>
</ol>
<pre><code>pthread_t pthread_self(void);
int pthread_equal(pthread_t t1, pthread_t t2);
int pthread_once(pthread_once_t *once_control,
              void (*init_routine)(void));
pthread_once_t once_control = PTHREAD_ONCE_INIT;
</code></pre>
<ul>
<li><code>pthread_self</code> 返回调用线程的唯一 thread ID.</li>
<li><code>pthread_equal</code> 比较两个线程 ID 是否相等.</li>
<li><code>pthread_once</code> 本函数使用初值为PTHREAD_ONCE_INIT的once_control变量保证init_routine()函数在本进程执行序列中仅执行一次。在多线程编程环境下，尽管pthread_once()调用会出现在多个线程中，init_routine()函数仅执行一次，究竟在哪个线程中执行是不定的，是由内核调度来决定。Linux Threads使用互斥锁和条件变量保证由pthread_once()指定的函数执行且仅执行一次，而once_control表示是否执行过。如果once_control的初值不是PTHREAD_ONCE_INIT（Linux Threads定义为0），pthread_once() 的行为就会不正常。在Linux中，实际&quot;一次性函数&quot;的执行状态有三种：NEVER（0）、IN_PROGRESS（1）、DONE （2），如果once初值设为1，则由于所有pthread_once()都必须等待其中一个激发&quot;已执行一次&quot;信号，因此所有pthread_once ()都会陷入永久的等待中；如果设为2，则表示该函数已执行过一次，从而所有pthread_once()都会立即返回0</li>
</ul>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[第一篇博客]]></title>
        <id>https://wangpifu.github.io/post/first-blog/</id>
        <link href="https://wangpifu.github.io/post/first-blog/">
        </link>
        <updated>2020-04-29T09:27:05.000Z</updated>
        <content type="html"><![CDATA[<p>这是一篇建立在github pages，用Gridea构建管理的私人博客站点。目前来看Gridea是最方便的搭建管理软件，避免了安装nodejs 或者 ruby。 这对于Windows系统非常方便。坦白来讲，我并不希望在我的Windows box上安装任何和技术开发相关的软件，因为他们的使用频率很低，最终会被我遗忘在漫长的时光里。而我的开发机器（based on linux），我又希望它能只承载和开发相关的事务。另外，Gridea看起来更加直观与人性化，避免了许多与写作不相关的操作。希望Gridea可以一直被维护下去，感谢Gridea。cnblog本来是我的第一选择，但是需要手机号注册。CSDN则有太多的广告。知乎的话，我更倾向于发布仔细审视后的文章。这个站点则会更随意一些，有些想法我可以先记载下来，在日后慢慢的更改完善。</p>
<p>写博客的动力来自于一次失败的面试。我意识到很多技术的积累不能光靠工作，以及需要了解平时工作下的更深入的东西。人必须要不断地走出舒适圈，去接触自己不熟悉的东西，再能慢慢变得全能起来。我是一个不喜欢走在科技前端的人，平时更倾向于利用纸笔做笔记，但是现在意识到对于代码来讲，博客可能是个更合适的地方。对于刚开始的几篇文章，发布的频率可能比较高，内容可能不够精细，因为我希望能提纲挈领地把一些我在脑海中总结过的知识转移到这个站点上来，会在随后的日子里慢慢打磨。另外，我此时迫不及待地希望我能把一些需要学习的知识点电子化的记录下来，这也会导致初期一些文章显得杂乱。</p>
<p>希望明天会更好。<br>
--20200429 阴天 纽约</p>
]]></content>
    </entry>
</feed>